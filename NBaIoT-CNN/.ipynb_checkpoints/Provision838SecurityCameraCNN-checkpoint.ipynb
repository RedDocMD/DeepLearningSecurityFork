{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b17c252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/andressa.amaral/.local/lib/python3.7/site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.31.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: typing-extensions in /home/andressa.amaral/.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.7/site-packages (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.44.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (60.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.24.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (13.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: cached-property in /home/andressa.amaral/.local/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.6.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from packaging->tensorflow-gpu) (3.0.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.11.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bayesian-optimization in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:08:11.320191: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-21 14:08:11.320213: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install seaborn\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "!pip3 install bayesian-optimization\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling1D, BatchNormalization\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, mean_squared_error, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64862836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:08:12.331722: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 14:08:13.171718: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-21 14:08:13.171813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-21 14:08:13.171894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-21 14:08:13.174403: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-21 14:08:13.174487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-21 14:08:13.174579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-05-21 14:08:13.174590: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.compat.v1.Session(config = tf.compat.v1.ConfigProto(gpu_options = gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76368e",
   "metadata": {},
   "source": [
    "# P838 Security Camera Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771d9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign traffic\n",
    "\n",
    "p8_benign = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/benign_traffic.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_benign = p8_benign.copy(deep=True)\n",
    "\n",
    "columns = list(df_p8_benign.columns)\n",
    "chosen_columns = []\n",
    "for column in columns:\n",
    "    if column.find('L5') != -1:\n",
    "        chosen_columns.append(column)\n",
    "\n",
    "df_p8_benign = pd.DataFrame(df_p8_benign, columns = chosen_columns)\n",
    "\n",
    "# Mirai\n",
    "\n",
    "p8_mirai_ack = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/ack.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_ack = p8_mirai_ack.copy(deep=True)\n",
    "df_p8_mirai_ack = pd.DataFrame(df_p8_mirai_ack, columns = chosen_columns)\n",
    "df_p8_mirai_ack = df_p8_mirai_ack.sample(frac=1)\n",
    "\n",
    "p8_mirai_scan = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/scan.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_scan = p8_mirai_scan.copy(deep=True)\n",
    "df_p8_mirai_scan = pd.DataFrame(df_p8_mirai_scan, columns = chosen_columns)\n",
    "df_p8_mirai_scan = df_p8_mirai_scan.sample(frac=1)\n",
    "\n",
    "p8_mirai_syn = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/syn.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_syn = p8_mirai_syn.copy(deep=True)\n",
    "df_p8_mirai_syn = pd.DataFrame(df_p8_mirai_syn, columns = chosen_columns)\n",
    "df_p8_mirai_syn = df_p8_mirai_syn.sample(frac=1)\n",
    "\n",
    "p8_mirai_udp = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/udp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_udp = p8_mirai_udp.copy(deep=True)\n",
    "df_p8_mirai_udp = pd.DataFrame(df_p8_mirai_udp, columns = chosen_columns)\n",
    "df_p8_mirai_udp = df_p8_mirai_udp.sample(frac=1)\n",
    "\n",
    "p8_mirai_udpplain = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/mirai/udpplain.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_mirai_udpplain = p8_mirai_udpplain.copy(deep=True)\n",
    "df_p8_mirai_udpplain = pd.DataFrame(df_p8_mirai_udpplain, columns = chosen_columns)\n",
    "df_p8_mirai_udpplain = df_p8_mirai_udpplain.sample(frac=1)\n",
    "\n",
    "# Bashlite\n",
    "\n",
    "p8_bashlite_combo = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/combo.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_combo = p8_bashlite_combo.copy(deep=True)\n",
    "df_p8_bashlite_combo = pd.DataFrame(df_p8_bashlite_combo, columns = chosen_columns)\n",
    "df_p8_bashlite_combo = df_p8_bashlite_combo.sample(frac=1)\n",
    "\n",
    "p8_bashlite_junk = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/junk.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_junk = p8_bashlite_junk.copy(deep=True)\n",
    "df_p8_bashlite_junk = pd.DataFrame(df_p8_bashlite_junk, columns = chosen_columns)\n",
    "df_p8_bashlite_junk = df_p8_bashlite_junk.sample(frac=1)\n",
    "\n",
    "p8_bashlite_scan = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/scan.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_scan = p8_bashlite_scan.copy(deep=True)\n",
    "df_p8_bashlite_scan = pd.DataFrame(df_p8_bashlite_scan, columns = chosen_columns)\n",
    "df_p8_bashlite_scan = df_p8_bashlite_scan.sample(frac=1)\n",
    "\n",
    "p8_bashlite_udp = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/udp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_udp = p8_bashlite_udp.copy(deep=True)\n",
    "df_p8_bashlite_udp = pd.DataFrame(df_p8_bashlite_udp, columns = chosen_columns)\n",
    "df_p8_bashlite_udp = df_p8_bashlite_udp.sample(frac=1)\n",
    "\n",
    "p8_bashlite_tcp = pd.read_csv('../nbaiot/Provision_PT_838_Security_Camera/gafgyt/tcp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p8_bashlite_tcp = p8_bashlite_tcp.copy(deep=True)\n",
    "df_p8_bashlite_tcp = pd.DataFrame(df_p8_bashlite_tcp, columns = chosen_columns)\n",
    "df_p8_bashlite_tcp = df_p8_bashlite_tcp.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fe73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing information\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_p8_miraiack_norm = scaler.fit_transform(df_p8_mirai_ack)\n",
    "df_p8_miraiscan_norm = scaler.fit_transform(df_p8_mirai_scan)\n",
    "df_p8_miraisyn_norm = scaler.fit_transform(df_p8_mirai_syn)\n",
    "df_p8_miraiudp_norm = scaler.fit_transform(df_p8_mirai_udp)\n",
    "df_p8_miraiudpplain_norm = scaler.fit_transform(df_p8_mirai_udpplain)\n",
    "\n",
    "df_p8_bashlitecombo_norm = scaler.fit_transform(df_p8_bashlite_combo)\n",
    "df_p8_bashlitejunk_norm = scaler.fit_transform(df_p8_bashlite_junk)\n",
    "df_p8_bashlitescan_norm = scaler.fit_transform(df_p8_bashlite_scan)\n",
    "df_p8_bashliteudp_norm = scaler.fit_transform(df_p8_bashlite_udp)\n",
    "df_p8_bashlitetcp_norm = scaler.fit_transform(df_p8_bashlite_tcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bc756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirai attack labelization\n",
    "\n",
    "label_mirai_ack = list(np.full(df_p8_miraiack_norm.shape[0], 0))\n",
    "miraiack_norm = pd.DataFrame(df_p8_miraiack_norm)\n",
    "miraiack_norm['Label'] = label_mirai_ack\n",
    "\n",
    "label_mirai_scan = list(np.full(df_p8_miraiscan_norm.shape[0], 1))\n",
    "miraiscan_norm = pd.DataFrame(df_p8_miraiscan_norm)\n",
    "miraiscan_norm['Label'] = label_mirai_scan\n",
    "\n",
    "label_mirai_syn = list(np.full(df_p8_miraisyn_norm.shape[0], 2))\n",
    "miraisyn_norm = pd.DataFrame(df_p8_miraisyn_norm)\n",
    "miraisyn_norm['Label'] = label_mirai_syn\n",
    "\n",
    "label_mirai_udp = list(np.full(df_p8_miraiudp_norm.shape[0], 3))\n",
    "miraiudp_norm = pd.DataFrame(df_p8_miraiudp_norm)\n",
    "miraiudp_norm['Label'] = label_mirai_udp\n",
    "\n",
    "label_mirai_udpplain = list(np.full(df_p8_miraiudpplain_norm.shape[0], 4))\n",
    "miraiudpplain_norm = pd.DataFrame(df_p8_miraiudpplain_norm)\n",
    "miraiudpplain_norm['Label'] = label_mirai_udpplain\n",
    "\n",
    "# Bashlite attack labelization\n",
    "\n",
    "label_bashlite_combo = list(np.full(df_p8_bashlitecombo_norm.shape[0], 5))\n",
    "bashlitecombo_norm = pd.DataFrame(df_p8_bashlitecombo_norm)\n",
    "bashlitecombo_norm['Label'] = label_bashlite_combo\n",
    "\n",
    "label_bashlite_junk = list(np.full(df_p8_bashlitejunk_norm.shape[0], 6))\n",
    "bashlitejunk_norm = pd.DataFrame(df_p8_bashlitejunk_norm)\n",
    "bashlitejunk_norm['Label'] = label_bashlite_junk\n",
    "\n",
    "label_bashlite_scan = list(np.full(df_p8_bashlitescan_norm.shape[0], 7))\n",
    "bashlitescan_norm = pd.DataFrame(df_p8_bashlitescan_norm)\n",
    "bashlitescan_norm['Label'] = label_bashlite_scan\n",
    "\n",
    "label_bashlite_udp = list(np.full(df_p8_bashliteudp_norm.shape[0], 8))\n",
    "bashliteudp_norm = pd.DataFrame(df_p8_bashliteudp_norm)\n",
    "bashliteudp_norm['Label'] = label_bashlite_udp\n",
    "\n",
    "label_bashlite_tcp = list(np.full(df_p8_bashlitetcp_norm.shape[0], 9))\n",
    "bashlitetcp_norm = pd.DataFrame(df_p8_bashlitetcp_norm)\n",
    "bashlitetcp_norm['Label'] = label_bashlite_tcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755fbe7",
   "metadata": {},
   "source": [
    "# CNN - Attack Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8be374",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b13a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 43\n",
    "number_features = 23\n",
    "learning_rate = 0.05\n",
    "epochs = 50\n",
    "\n",
    "dict_params = { 'learning_rate': learning_rate, 'batch_size': int(32 * batch_size), 'epochs': int(epochs) }\n",
    "pbounds = { 'learning_rate': (0.000001, 0.1), 'batch_size': (1, 4.001), 'epochs': (1, 100) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce8adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858\n"
     ]
    }
   ],
   "source": [
    "# Train set\n",
    "\n",
    "len_mirai_ack_train = int(0.7 * len(miraiack_norm))\n",
    "X_train_mirai_ack = miraiack_norm[:len_mirai_ack_train]\n",
    "\n",
    "len_mirai_scan_train = int(0.7 * len(miraiscan_norm))\n",
    "X_train_mirai_scan = miraiscan_norm[:len_mirai_scan_train]\n",
    "\n",
    "len_mirai_syn_train = int(0.7 * len(miraisyn_norm))\n",
    "X_train_mirai_syn = miraisyn_norm[:len_mirai_syn_train]\n",
    "\n",
    "len_mirai_udp_train = int(0.7 * len(miraiudp_norm))\n",
    "X_train_mirai_udp = miraiudp_norm[:len_mirai_udp_train]\n",
    "\n",
    "len_mirai_udpplain_train = int(0.7 * len(miraiudpplain_norm))\n",
    "X_train_mirai_udpplain = miraiudpplain_norm[:len_mirai_udpplain_train]\n",
    "\n",
    "len_bashlite_combo_train = int(0.7 * len(bashlitecombo_norm))\n",
    "X_train_bashlite_combo = bashlitecombo_norm[:len_bashlite_combo_train]\n",
    "\n",
    "len_bashlite_junk_train = int(0.7 * len(bashlitejunk_norm))\n",
    "X_train_bashlite_junk = bashlitejunk_norm[:len_bashlite_junk_train]\n",
    "\n",
    "len_bashlite_scan_train = int(0.7 * len(bashlitescan_norm))\n",
    "X_train_bashlite_scan = bashlitescan_norm[:len_bashlite_scan_train]\n",
    "\n",
    "len_bashlite_udp_train = int(0.7 * len(bashliteudp_norm))\n",
    "X_train_bashlite_udp = bashliteudp_norm[:len_bashlite_udp_train]\n",
    "\n",
    "len_bashlite_tcp_train = int(0.7 * len(bashlitetcp_norm))\n",
    "X_train_bashlite_tcp = bashlitetcp_norm[:len_bashlite_tcp_train]\n",
    "\n",
    "np_train = np.concatenate([X_train_mirai_ack, X_train_mirai_scan, X_train_mirai_syn, X_train_mirai_udp, X_train_mirai_udpplain,\n",
    "                          X_train_bashlite_combo, X_train_bashlite_junk, X_train_bashlite_scan, X_train_bashlite_udp,\n",
    "                          X_train_bashlite_tcp])\n",
    "\n",
    "df_train = pd.DataFrame(np_train)\n",
    "label_train = df_train.pop(number_features)\n",
    "\n",
    "X_train = df_train.to_numpy()\n",
    "Y_train = label_train.to_numpy()\n",
    "\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16726f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110752\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "\n",
    "len_mirai_ack_test = len_mirai_ack_train + int(0.15 * len(miraiack_norm))\n",
    "X_test_mirai_ack = miraiack_norm[len_mirai_ack_train : len_mirai_ack_test]\n",
    "\n",
    "len_mirai_scan_test = len_mirai_scan_train + int(0.15 * len(miraiscan_norm))\n",
    "X_test_mirai_scan = miraiscan_norm[len_mirai_scan_train : len_mirai_scan_test]\n",
    "\n",
    "len_mirai_syn_test = len_mirai_syn_train + int(0.15 * len(miraisyn_norm))\n",
    "X_test_mirai_syn = miraisyn_norm[len_mirai_syn_train : len_mirai_syn_test]\n",
    "\n",
    "len_mirai_udp_test = len_mirai_udp_train + int(0.15 * len(miraiudp_norm))\n",
    "X_test_mirai_udp = miraiudp_norm[len_mirai_udp_train : len_mirai_udp_test]\n",
    "\n",
    "len_mirai_udpplain_test = len_mirai_udpplain_train + int(0.15 * len(miraiudpplain_norm))\n",
    "X_test_mirai_udpplain = miraiudpplain_norm[len_mirai_udpplain_train : len_mirai_udpplain_test]\n",
    "\n",
    "len_bashlite_combo_test = len_bashlite_combo_train + int(0.15 * len(bashlitecombo_norm))\n",
    "X_test_bashlite_combo = bashlitecombo_norm[len_bashlite_combo_train : len_bashlite_combo_test]\n",
    "\n",
    "len_bashlite_junk_test = len_bashlite_junk_train + int(0.15 * len(bashlitejunk_norm))\n",
    "X_test_bashlite_junk = bashlitejunk_norm[len_bashlite_junk_train : len_bashlite_junk_test]\n",
    "\n",
    "len_bashlite_scan_test = len_bashlite_scan_train + int(0.15 * len(bashlitescan_norm))\n",
    "X_test_bashlite_scan = bashlitescan_norm[len_bashlite_scan_train : len_bashlite_scan_test]\n",
    "\n",
    "len_bashlite_udp_test = len_bashlite_udp_train + int(0.15 * len(bashliteudp_norm))\n",
    "X_test_bashlite_udp = bashliteudp_norm[len_bashlite_udp_train : len_bashlite_udp_test]\n",
    "\n",
    "len_bashlite_tcp_test = len_bashlite_tcp_train + int(0.15 * len(bashlitetcp_norm))\n",
    "X_test_bashlite_tcp = bashlitetcp_norm[len_bashlite_tcp_train : len_bashlite_tcp_test]\n",
    "\n",
    "np_test = np.concatenate([X_test_mirai_ack, X_test_mirai_scan, X_test_mirai_syn, X_test_mirai_udp, X_test_mirai_udpplain,\n",
    "                          X_test_bashlite_combo, X_test_bashlite_junk, X_test_bashlite_scan, X_test_bashlite_udp,\n",
    "                          X_test_bashlite_tcp])\n",
    "\n",
    "df_test = pd.DataFrame(np_test)\n",
    "label_test = df_test.pop(number_features)\n",
    "\n",
    "X_test = df_test.to_numpy()\n",
    "Y_test = label_test.to_numpy()\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5735be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "\n",
    "X_val_mirai_ack = miraiack_norm[len_mirai_ack_test:]\n",
    "X_val_mirai_scan = miraiscan_norm[len_mirai_scan_test:]\n",
    "X_val_mirai_syn = miraisyn_norm[len_mirai_syn_test:]\n",
    "X_val_mirai_udp = miraiudp_norm[len_mirai_udp_test:]\n",
    "X_val_mirai_udpplain = miraiudpplain_norm[len_mirai_udpplain_test:]\n",
    "\n",
    "X_val_bashlite_combo = bashlitecombo_norm[len_bashlite_combo_test:]\n",
    "X_val_bashlite_junk = bashlitejunk_norm[len_bashlite_junk_test:]\n",
    "X_val_bashlite_scan = bashlitescan_norm[len_bashlite_scan_test:]\n",
    "X_val_bashlite_udp = bashlitetcp_norm[len_bashlite_udp_test:]\n",
    "X_val_bashlite_tcp = bashlitetcp_norm[len_bashlite_tcp_test:]\n",
    "\n",
    "np_val = np.concatenate([X_val_mirai_ack, X_val_mirai_scan, X_val_mirai_syn, X_val_mirai_udp, X_val_mirai_udpplain,\n",
    "                          X_val_bashlite_combo, X_val_bashlite_junk, X_val_bashlite_scan, X_val_bashlite_udp,\n",
    "                          X_val_bashlite_tcp])\n",
    "\n",
    "df_val = pd.DataFrame(np_test)\n",
    "label_test = df_val.pop(number_features)\n",
    "\n",
    "X_val = df_val.to_numpy()\n",
    "Y_val = label_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3bb7211",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CNN = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_CNN = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_val_CNN = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "Y_train_CNN = Y_train\n",
    "Y_test_CNN = Y_test\n",
    "Y_val_CNN = Y_val\n",
    "\n",
    "samples, feature, depth = X_train_CNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6cf8937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with 1D convolutional layer\n",
    "\n",
    "def CNN():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform', input_shape=(feature, depth)))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84cde696",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(moniter = 'val_loss', factor = 0.1, patience = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda2e43",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf65980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step with Bayesian optimization\n",
    "\n",
    "def training(X_train = X_train_CNN,\n",
    "             Y_train = Y_train_CNN, \n",
    "             X_val = X_val_CNN, \n",
    "             Y_val = Y_val_CNN, \n",
    "             X_test = X_test_CNN, \n",
    "             Y_test = Y_test_CNN, \n",
    "             learning_rate = learning_rate, \n",
    "             epochs = epochs, \n",
    "             batch_size = batch_size,\n",
    "             reduce_lr = reduce_lr):\n",
    "    \n",
    "    nadam = optimizers.Nadam(learning_rate = dict_params['learning_rate'], beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.004)\n",
    "    \n",
    "    model = CNN()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, \n",
    "                        epochs = dict_params['epochs'], \n",
    "                        batch_size = dict_params['batch_size'], \n",
    "                        validation_data = (X_val, Y_val),\n",
    "                        callbacks = [reduce_lr])\n",
    "    \n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    print('loss:', scores[0])\n",
    "    print('accuracy:', scores[1])\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17af310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |  epochs   | learni... |\n",
      "-------------------------------------------------------------\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:08:22.920167: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-21 14:08:22.933263: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516000/516858 [============================>.] - ETA: 0s - loss: 0.4492 - accuracy: 0.8398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.4489 - accuracy: 0.8399 - val_loss: 0.3078 - val_accuracy: 0.8816 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.3018 - accuracy: 0.8809 - val_loss: 0.2880 - val_accuracy: 0.8852 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 6s 12us/sample - loss: 0.2879 - accuracy: 0.8850 - val_loss: 0.2831 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 6s 13us/sample - loss: 0.3135 - accuracy: 0.8825 - val_loss: 0.3412 - val_accuracy: 0.8774 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 6s 12us/sample - loss: 0.2911 - accuracy: 0.8853 - val_loss: 0.2831 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.2781 - accuracy: 0.8882 - val_loss: 0.2780 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.2747 - accuracy: 0.8888 - val_loss: 0.2750 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.2733 - accuracy: 0.8890 - val_loss: 0.2772 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.2736 - accuracy: 0.8894 - val_loss: 0.2753 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.2703 - accuracy: 0.8899 - val_loss: 0.2697 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2691 - accuracy: 0.8902 - val_loss: 0.2699 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2682 - accuracy: 0.8906 - val_loss: 0.2694 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2675 - accuracy: 0.8906 - val_loss: 0.2754 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2665 - accuracy: 0.8909 - val_loss: 0.2693 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2658 - accuracy: 0.8910 - val_loss: 0.2675 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2664 - accuracy: 0.8911 - val_loss: 0.2665 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2642 - accuracy: 0.8916 - val_loss: 0.2684 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2635 - accuracy: 0.8916 - val_loss: 0.2643 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2629 - accuracy: 0.8918 - val_loss: 0.2637 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2623 - accuracy: 0.8923 - val_loss: 0.2635 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2614 - accuracy: 0.8925 - val_loss: 0.2672 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2608 - accuracy: 0.8926 - val_loss: 0.2624 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2604 - accuracy: 0.8926 - val_loss: 0.2596 - val_accuracy: 0.8928 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2590 - accuracy: 0.8933 - val_loss: 0.2619 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2586 - accuracy: 0.8935 - val_loss: 0.2572 - val_accuracy: 0.8936 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2576 - accuracy: 0.8938 - val_loss: 0.2599 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2571 - accuracy: 0.8940 - val_loss: 0.2621 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2561 - accuracy: 0.8947 - val_loss: 0.2555 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2556 - accuracy: 0.8948 - val_loss: 0.2609 - val_accuracy: 0.8948 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2547 - accuracy: 0.8953 - val_loss: 0.2553 - val_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2536 - accuracy: 0.8957 - val_loss: 0.2552 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2527 - accuracy: 0.8964 - val_loss: 0.2689 - val_accuracy: 0.8916 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2527 - accuracy: 0.8961 - val_loss: 0.2516 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2509 - accuracy: 0.8972 - val_loss: 0.2524 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2504 - accuracy: 0.8976 - val_loss: 0.2494 - val_accuracy: 0.8983 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2497 - accuracy: 0.8978 - val_loss: 0.2562 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2480 - accuracy: 0.8984 - val_loss: 0.2599 - val_accuracy: 0.8922 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2480 - accuracy: 0.8984 - val_loss: 0.2425 - val_accuracy: 0.8992 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2456 - accuracy: 0.8995 - val_loss: 0.2417 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2458 - accuracy: 0.8995 - val_loss: 0.2415 - val_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2441 - accuracy: 0.9003 - val_loss: 0.2532 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2438 - accuracy: 0.9004 - val_loss: 0.2582 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2424 - accuracy: 0.9013 - val_loss: 0.2373 - val_accuracy: 0.9033 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2416 - accuracy: 0.9015 - val_loss: 0.2398 - val_accuracy: 0.9088 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2402 - accuracy: 0.9024 - val_loss: 0.2359 - val_accuracy: 0.9026 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2403 - accuracy: 0.9022 - val_loss: 0.2527 - val_accuracy: 0.8968 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2383 - accuracy: 0.9033 - val_loss: 0.2354 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2376 - accuracy: 0.9037 - val_loss: 0.2349 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2365 - accuracy: 0.9040 - val_loss: 0.2543 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2367 - accuracy: 0.9037 - val_loss: 0.2284 - val_accuracy: 0.9079 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.22839655379989907\n",
      "accuracy: 0.90787524\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9079  \u001b[0m | \u001b[0m 2.251   \u001b[0m | \u001b[0m 72.31   \u001b[0m | \u001b[0m 1.244e-0\u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "516858/516858 [==============================] - 5s 11us/sample - loss: 0.4465 - accuracy: 0.8383 - val_loss: 0.3188 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3003 - accuracy: 0.8815 - val_loss: 0.2914 - val_accuracy: 0.8834 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2865 - accuracy: 0.8851 - val_loss: 0.2811 - val_accuracy: 0.8874 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2791 - accuracy: 0.8872 - val_loss: 0.2747 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2769 - accuracy: 0.8880 - val_loss: 0.2883 - val_accuracy: 0.8796 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2728 - accuracy: 0.8889 - val_loss: 0.2747 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3097 - accuracy: 0.8820 - val_loss: 0.2863 - val_accuracy: 0.8840 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2756 - accuracy: 0.8882 - val_loss: 0.2909 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2720 - accuracy: 0.8892 - val_loss: 0.2736 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2701 - accuracy: 0.8895 - val_loss: 0.2712 - val_accuracy: 0.8896 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2761 - accuracy: 0.8885 - val_loss: 0.2730 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2685 - accuracy: 0.8901 - val_loss: 0.2691 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2671 - accuracy: 0.8904 - val_loss: 0.2687 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2660 - accuracy: 0.8909 - val_loss: 0.2735 - val_accuracy: 0.8876 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2653 - accuracy: 0.8910 - val_loss: 0.2670 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2651 - accuracy: 0.8910 - val_loss: 0.2667 - val_accuracy: 0.8896 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2633 - accuracy: 0.8914 - val_loss: 0.2646 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2628 - accuracy: 0.8914 - val_loss: 0.2743 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2621 - accuracy: 0.8918 - val_loss: 0.2628 - val_accuracy: 0.8916 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2616 - accuracy: 0.8920 - val_loss: 0.2633 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2607 - accuracy: 0.8922 - val_loss: 0.2653 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2601 - accuracy: 0.8925 - val_loss: 0.2614 - val_accuracy: 0.8924 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2592 - accuracy: 0.8927 - val_loss: 0.2653 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2585 - accuracy: 0.8931 - val_loss: 0.2591 - val_accuracy: 0.8934 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2573 - accuracy: 0.8937 - val_loss: 0.2627 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2575 - accuracy: 0.8932 - val_loss: 0.2606 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2563 - accuracy: 0.8940 - val_loss: 0.2640 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2556 - accuracy: 0.8943 - val_loss: 0.2548 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2549 - accuracy: 0.8945 - val_loss: 0.2599 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2540 - accuracy: 0.8949 - val_loss: 0.2534 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2529 - accuracy: 0.8956 - val_loss: 0.2555 - val_accuracy: 0.8982 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2517 - accuracy: 0.8962 - val_loss: 0.2648 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2515 - accuracy: 0.8964 - val_loss: 0.2501 - val_accuracy: 0.8985 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2508 - accuracy: 0.8965 - val_loss: 0.2499 - val_accuracy: 0.8992 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2494 - accuracy: 0.8975 - val_loss: 0.2467 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2481 - accuracy: 0.8978 - val_loss: 0.2455 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2476 - accuracy: 0.8981 - val_loss: 0.2446 - val_accuracy: 0.9010 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2466 - accuracy: 0.8987 - val_loss: 0.2437 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2451 - accuracy: 0.8995 - val_loss: 0.2415 - val_accuracy: 0.9026 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2445 - accuracy: 0.8996 - val_loss: 0.2496 - val_accuracy: 0.8946 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2432 - accuracy: 0.9004 - val_loss: 0.2473 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2424 - accuracy: 0.9006 - val_loss: 0.2409 - val_accuracy: 0.9042 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2412 - accuracy: 0.9011 - val_loss: 0.2603 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2395 - accuracy: 0.9018 - val_loss: 0.2811 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2399 - accuracy: 0.9017 - val_loss: 0.2587 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2369 - accuracy: 0.9031 - val_loss: 0.2331 - val_accuracy: 0.9045 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2368 - accuracy: 0.9034 - val_loss: 0.2320 - val_accuracy: 0.9063 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2365 - accuracy: 0.9031 - val_loss: 0.2345 - val_accuracy: 0.9032 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2340 - accuracy: 0.9045 - val_loss: 0.2295 - val_accuracy: 0.9059 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2339 - accuracy: 0.9047 - val_loss: 0.2655 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "loss: 0.26549420706559224\n",
      "accuracy: 0.8740068\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.874   \u001b[0m | \u001b[0m 1.907   \u001b[0m | \u001b[0m 15.53   \u001b[0m | \u001b[0m 0.009235\u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.4594 - accuracy: 0.8355 - val_loss: 0.3176 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3028 - accuracy: 0.8804 - val_loss: 0.2930 - val_accuracy: 0.8828 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2869 - accuracy: 0.8849 - val_loss: 0.3045 - val_accuracy: 0.8834 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2819 - accuracy: 0.8866 - val_loss: 0.2798 - val_accuracy: 0.8866 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2791 - accuracy: 0.8873 - val_loss: 0.2776 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2748 - accuracy: 0.8881 - val_loss: 0.2788 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2731 - accuracy: 0.8886 - val_loss: 0.2728 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2724 - accuracy: 0.8889 - val_loss: 0.2703 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2807 - accuracy: 0.8876 - val_loss: 0.2717 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2696 - accuracy: 0.8894 - val_loss: 0.2701 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2681 - accuracy: 0.8898 - val_loss: 0.2688 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2671 - accuracy: 0.8902 - val_loss: 0.2750 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2663 - accuracy: 0.8905 - val_loss: 0.2688 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2658 - accuracy: 0.8907 - val_loss: 0.2652 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2646 - accuracy: 0.8909 - val_loss: 0.2666 - val_accuracy: 0.8896 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2639 - accuracy: 0.8911 - val_loss: 0.2714 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2634 - accuracy: 0.8912 - val_loss: 0.2733 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2627 - accuracy: 0.8916 - val_loss: 0.2616 - val_accuracy: 0.8906 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2620 - accuracy: 0.8918 - val_loss: 0.2646 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2612 - accuracy: 0.8919 - val_loss: 0.2637 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2609 - accuracy: 0.8921 - val_loss: 0.2621 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2599 - accuracy: 0.8927 - val_loss: 0.2606 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2594 - accuracy: 0.8924 - val_loss: 0.2595 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2589 - accuracy: 0.8929 - val_loss: 0.2590 - val_accuracy: 0.8926 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2581 - accuracy: 0.8930 - val_loss: 0.2691 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2575 - accuracy: 0.8934 - val_loss: 0.2609 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2571 - accuracy: 0.8934 - val_loss: 0.2566 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2559 - accuracy: 0.8944 - val_loss: 0.2550 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2556 - accuracy: 0.8944 - val_loss: 0.2675 - val_accuracy: 0.8876 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2547 - accuracy: 0.8949 - val_loss: 0.2560 - val_accuracy: 0.8948 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2537 - accuracy: 0.8949 - val_loss: 0.2550 - val_accuracy: 0.8954 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2532 - accuracy: 0.8956 - val_loss: 0.2615 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2521 - accuracy: 0.8957 - val_loss: 0.2488 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2510 - accuracy: 0.8965 - val_loss: 0.2833 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2509 - accuracy: 0.8968 - val_loss: 0.2517 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2492 - accuracy: 0.8971 - val_loss: 0.2641 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2488 - accuracy: 0.8974 - val_loss: 0.2475 - val_accuracy: 0.8966 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2476 - accuracy: 0.8983 - val_loss: 0.2468 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2467 - accuracy: 0.8986 - val_loss: 0.2745 - val_accuracy: 0.8682 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2456 - accuracy: 0.8993 - val_loss: 0.2792 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2451 - accuracy: 0.8995 - val_loss: 0.2543 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2435 - accuracy: 0.9001 - val_loss: 0.2565 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2432 - accuracy: 0.9001 - val_loss: 0.2401 - val_accuracy: 0.8999 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2419 - accuracy: 0.9008 - val_loss: 0.2381 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2416 - accuracy: 0.9008 - val_loss: 0.2398 - val_accuracy: 0.8994 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2402 - accuracy: 0.9017 - val_loss: 0.2378 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2390 - accuracy: 0.9023 - val_loss: 0.2388 - val_accuracy: 0.9013 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2376 - accuracy: 0.9029 - val_loss: 0.2651 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2378 - accuracy: 0.9025 - val_loss: 0.2433 - val_accuracy: 0.8982 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2365 - accuracy: 0.9036 - val_loss: 0.2468 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "loss: 0.2468325690376603\n",
      "accuracy: 0.89512604\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 1.559   \u001b[0m | \u001b[0m 35.21   \u001b[0m | \u001b[0m 0.03968 \u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.4474 - accuracy: 0.8383 - val_loss: 0.3165 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2992 - accuracy: 0.8817 - val_loss: 0.2873 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2866 - accuracy: 0.8856 - val_loss: 0.2846 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2882 - accuracy: 0.8856 - val_loss: 0.3012 - val_accuracy: 0.8830 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2787 - accuracy: 0.8877 - val_loss: 0.2773 - val_accuracy: 0.8874 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2737 - accuracy: 0.8886 - val_loss: 0.2740 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2928 - accuracy: 0.8856 - val_loss: 0.2741 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2717 - accuracy: 0.8892 - val_loss: 0.2749 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2699 - accuracy: 0.8899 - val_loss: 0.2695 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2684 - accuracy: 0.8903 - val_loss: 0.2698 - val_accuracy: 0.8884 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2679 - accuracy: 0.8903 - val_loss: 0.7314 - val_accuracy: 0.8505 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2694 - accuracy: 0.8904 - val_loss: 0.2700 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2657 - accuracy: 0.8909 - val_loss: 0.2663 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2650 - accuracy: 0.8910 - val_loss: 0.2707 - val_accuracy: 0.8896 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2643 - accuracy: 0.8912 - val_loss: 0.2650 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2635 - accuracy: 0.8914 - val_loss: 0.2686 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2627 - accuracy: 0.8918 - val_loss: 0.2635 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2625 - accuracy: 0.8918 - val_loss: 0.2679 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2614 - accuracy: 0.8921 - val_loss: 0.2638 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2607 - accuracy: 0.8923 - val_loss: 0.2646 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2598 - accuracy: 0.8928 - val_loss: 0.2615 - val_accuracy: 0.8928 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2592 - accuracy: 0.8929 - val_loss: 0.2601 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2587 - accuracy: 0.8931 - val_loss: 0.2584 - val_accuracy: 0.8938 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2580 - accuracy: 0.8936 - val_loss: 0.2595 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2569 - accuracy: 0.8940 - val_loss: 0.2564 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2564 - accuracy: 0.8942 - val_loss: 0.2542 - val_accuracy: 0.8946 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2557 - accuracy: 0.8943 - val_loss: 0.2564 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2543 - accuracy: 0.8951 - val_loss: 0.2544 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2539 - accuracy: 0.8955 - val_loss: 0.2517 - val_accuracy: 0.8968 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2536 - accuracy: 0.8952 - val_loss: 0.2687 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2520 - accuracy: 0.8963 - val_loss: 0.2492 - val_accuracy: 0.8990 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2515 - accuracy: 0.8966 - val_loss: 0.2503 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2500 - accuracy: 0.8970 - val_loss: 0.2488 - val_accuracy: 0.8958 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2491 - accuracy: 0.8976 - val_loss: 0.2478 - val_accuracy: 0.8984 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2480 - accuracy: 0.8984 - val_loss: 0.2566 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2468 - accuracy: 0.8987 - val_loss: 0.2546 - val_accuracy: 0.8924 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2464 - accuracy: 0.8992 - val_loss: 0.2438 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2450 - accuracy: 0.8997 - val_loss: 0.2476 - val_accuracy: 0.9009 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2441 - accuracy: 0.9003 - val_loss: 0.2408 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2432 - accuracy: 0.9005 - val_loss: 0.2456 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2413 - accuracy: 0.9014 - val_loss: 0.2482 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2416 - accuracy: 0.9012 - val_loss: 0.2363 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2402 - accuracy: 0.9017 - val_loss: 0.2335 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2389 - accuracy: 0.9026 - val_loss: 0.2340 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2378 - accuracy: 0.9030 - val_loss: 0.2359 - val_accuracy: 0.9080 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2368 - accuracy: 0.9034 - val_loss: 0.2547 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2360 - accuracy: 0.9042 - val_loss: 0.2343 - val_accuracy: 0.9043 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2344 - accuracy: 0.9046 - val_loss: 0.2298 - val_accuracy: 0.9059 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2336 - accuracy: 0.9049 - val_loss: 0.2273 - val_accuracy: 0.9067 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 5s 11us/sample - loss: 0.2333 - accuracy: 0.9052 - val_loss: 0.2269 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "loss: 0.22685057591652616\n",
      "accuracy: 0.9078301\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 2.617   \u001b[0m | \u001b[0m 42.5    \u001b[0m | \u001b[0m 0.06852 \u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.4588 - accuracy: 0.8373 - val_loss: 0.3331 - val_accuracy: 0.8674 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3056 - accuracy: 0.8802 - val_loss: 0.2905 - val_accuracy: 0.8852 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2896 - accuracy: 0.8848 - val_loss: 0.2846 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2834 - accuracy: 0.8863 - val_loss: 0.2864 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2853 - accuracy: 0.8861 - val_loss: 0.2824 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2770 - accuracy: 0.8881 - val_loss: 0.2853 - val_accuracy: 0.8844 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2742 - accuracy: 0.8886 - val_loss: 0.2725 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2739 - accuracy: 0.8885 - val_loss: 0.2756 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2714 - accuracy: 0.8893 - val_loss: 0.2691 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2692 - accuracy: 0.8896 - val_loss: 0.2725 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2682 - accuracy: 0.8898 - val_loss: 0.2900 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2930 - accuracy: 0.8862 - val_loss: 0.2723 - val_accuracy: 0.8876 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2699 - accuracy: 0.8894 - val_loss: 0.2710 - val_accuracy: 0.8876 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2680 - accuracy: 0.8898 - val_loss: 0.2689 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2668 - accuracy: 0.8903 - val_loss: 0.2693 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2657 - accuracy: 0.8905 - val_loss: 0.2677 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2649 - accuracy: 0.8907 - val_loss: 0.2687 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2642 - accuracy: 0.8911 - val_loss: 0.2715 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2636 - accuracy: 0.8910 - val_loss: 0.2642 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2629 - accuracy: 0.8913 - val_loss: 0.2634 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2621 - accuracy: 0.8914 - val_loss: 0.2667 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2613 - accuracy: 0.8918 - val_loss: 0.2608 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2608 - accuracy: 0.8920 - val_loss: 0.2608 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2600 - accuracy: 0.8923 - val_loss: 0.2587 - val_accuracy: 0.8922 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2592 - accuracy: 0.8927 - val_loss: 0.2641 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2589 - accuracy: 0.8927 - val_loss: 0.2577 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2581 - accuracy: 0.8933 - val_loss: 0.2632 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2576 - accuracy: 0.8934 - val_loss: 0.2579 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2568 - accuracy: 0.8937 - val_loss: 0.2571 - val_accuracy: 0.8946 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2558 - accuracy: 0.8941 - val_loss: 0.2542 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 5s 11us/sample - loss: 0.2552 - accuracy: 0.8943 - val_loss: 0.2557 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2546 - accuracy: 0.8945 - val_loss: 0.2535 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2540 - accuracy: 0.8951 - val_loss: 0.2729 - val_accuracy: 0.8842 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2532 - accuracy: 0.8952 - val_loss: 0.2505 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2520 - accuracy: 0.8956 - val_loss: 0.2585 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2512 - accuracy: 0.8962 - val_loss: 0.2559 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2509 - accuracy: 0.8961 - val_loss: 0.2534 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2496 - accuracy: 0.8967 - val_loss: 0.2536 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2486 - accuracy: 0.8975 - val_loss: 0.2454 - val_accuracy: 0.8987 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2477 - accuracy: 0.8977 - val_loss: 0.2446 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2469 - accuracy: 0.8986 - val_loss: 0.2488 - val_accuracy: 0.8978 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2456 - accuracy: 0.8992 - val_loss: 0.2557 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2450 - accuracy: 0.8993 - val_loss: 0.2409 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2438 - accuracy: 0.9000 - val_loss: 0.2438 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2430 - accuracy: 0.9000 - val_loss: 0.2501 - val_accuracy: 0.8977 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2424 - accuracy: 0.9003 - val_loss: 0.2397 - val_accuracy: 0.9031 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2406 - accuracy: 0.9011 - val_loss: 0.2554 - val_accuracy: 0.8876 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2401 - accuracy: 0.9013 - val_loss: 0.2379 - val_accuracy: 0.9030 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2380 - accuracy: 0.9023 - val_loss: 0.2369 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2383 - accuracy: 0.9022 - val_loss: 0.2427 - val_accuracy: 0.9045 - lr: 0.0010\n",
      "loss: 0.2426630384485968\n",
      "accuracy: 0.90453446\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9045  \u001b[0m | \u001b[0m 1.614   \u001b[0m | \u001b[0m 87.93   \u001b[0m | \u001b[0m 0.00274 \u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "516000/516858 [============================>.] - ETA: 0s - loss: 0.4585 - accuracy: 0.8345"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.4583 - accuracy: 0.8346 - val_loss: 0.3227 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3068 - accuracy: 0.8793 - val_loss: 0.2925 - val_accuracy: 0.8848 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2869 - accuracy: 0.8850 - val_loss: 0.2965 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3249 - accuracy: 0.8793 - val_loss: 0.2929 - val_accuracy: 0.8856 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2827 - accuracy: 0.8867 - val_loss: 0.2812 - val_accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2772 - accuracy: 0.8880 - val_loss: 0.2778 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2749 - accuracy: 0.8884 - val_loss: 0.2779 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2731 - accuracy: 0.8887 - val_loss: 0.2739 - val_accuracy: 0.8884 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2727 - accuracy: 0.8888 - val_loss: 0.2745 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2717 - accuracy: 0.8892 - val_loss: 0.2721 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2692 - accuracy: 0.8896 - val_loss: 0.2718 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2694 - accuracy: 0.8896 - val_loss: 0.2708 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 11us/sample - loss: 0.2676 - accuracy: 0.8901 - val_loss: 0.2681 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2687 - accuracy: 0.8901 - val_loss: 0.2695 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2663 - accuracy: 0.8905 - val_loss: 0.2730 - val_accuracy: 0.8866 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2658 - accuracy: 0.8906 - val_loss: 0.2672 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2652 - accuracy: 0.8906 - val_loss: 0.2664 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2645 - accuracy: 0.8910 - val_loss: 0.2677 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2639 - accuracy: 0.8913 - val_loss: 0.2648 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2634 - accuracy: 0.8914 - val_loss: 0.2642 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2629 - accuracy: 0.8915 - val_loss: 0.2696 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2624 - accuracy: 0.8918 - val_loss: 0.2669 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2617 - accuracy: 0.8921 - val_loss: 0.2633 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2614 - accuracy: 0.8923 - val_loss: 0.2626 - val_accuracy: 0.8916 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2606 - accuracy: 0.8924 - val_loss: 0.2661 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2600 - accuracy: 0.8927 - val_loss: 0.2620 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2596 - accuracy: 0.8927 - val_loss: 0.2629 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2592 - accuracy: 0.8928 - val_loss: 0.2595 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2583 - accuracy: 0.8933 - val_loss: 0.2611 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2580 - accuracy: 0.8936 - val_loss: 0.2577 - val_accuracy: 0.8923 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2573 - accuracy: 0.8937 - val_loss: 0.2575 - val_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2566 - accuracy: 0.8939 - val_loss: 0.2613 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2561 - accuracy: 0.8943 - val_loss: 0.2544 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2550 - accuracy: 0.8948 - val_loss: 0.2530 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2548 - accuracy: 0.8946 - val_loss: 0.2581 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2534 - accuracy: 0.8951 - val_loss: 0.2587 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2532 - accuracy: 0.8955 - val_loss: 0.2505 - val_accuracy: 0.8976 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2517 - accuracy: 0.8965 - val_loss: 0.2501 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2517 - accuracy: 0.8961 - val_loss: 0.2511 - val_accuracy: 0.8953 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2508 - accuracy: 0.8970 - val_loss: 0.2518 - val_accuracy: 0.8998 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2500 - accuracy: 0.8973 - val_loss: 0.2460 - val_accuracy: 0.9021 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2492 - accuracy: 0.8975 - val_loss: 0.2564 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2482 - accuracy: 0.8984 - val_loss: 0.2864 - val_accuracy: 0.8809 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 5s 11us/sample - loss: 0.2479 - accuracy: 0.8982 - val_loss: 0.2609 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.2469 - accuracy: 0.8989 - val_loss: 0.2432 - val_accuracy: 0.8990 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2457 - accuracy: 0.8992 - val_loss: 0.2675 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2446 - accuracy: 0.8999 - val_loss: 0.2437 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2444 - accuracy: 0.8996 - val_loss: 0.2485 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2428 - accuracy: 0.9009 - val_loss: 0.2511 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 5s 11us/sample - loss: 0.2424 - accuracy: 0.9010 - val_loss: 0.2348 - val_accuracy: 0.9070 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.23476348025803065\n",
      "accuracy: 0.9069994\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.907   \u001b[0m | \u001b[0m 2.431   \u001b[0m | \u001b[0m 72.42   \u001b[0m | \u001b[0m 0.01222 \u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "516000/516858 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.8343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.4581 - accuracy: 0.8344 - val_loss: 0.3179 - val_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3021 - accuracy: 0.8808 - val_loss: 0.3035 - val_accuracy: 0.8755 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2870 - accuracy: 0.8854 - val_loss: 0.2863 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2813 - accuracy: 0.8868 - val_loss: 0.2796 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2784 - accuracy: 0.8875 - val_loss: 0.2783 - val_accuracy: 0.8874 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2744 - accuracy: 0.8889 - val_loss: 0.2835 - val_accuracy: 0.8874 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2728 - accuracy: 0.8891 - val_loss: 0.2752 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2714 - accuracy: 0.8896 - val_loss: 0.2713 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2693 - accuracy: 0.8897 - val_loss: 0.2708 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3011 - accuracy: 0.8856 - val_loss: 0.2784 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2736 - accuracy: 0.8887 - val_loss: 0.2760 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2702 - accuracy: 0.8895 - val_loss: 0.2705 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2687 - accuracy: 0.8901 - val_loss: 0.2693 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2675 - accuracy: 0.8902 - val_loss: 0.2680 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2667 - accuracy: 0.8903 - val_loss: 0.2687 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2660 - accuracy: 0.8906 - val_loss: 0.2668 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2650 - accuracy: 0.8909 - val_loss: 0.2662 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2647 - accuracy: 0.8908 - val_loss: 0.2670 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2642 - accuracy: 0.8908 - val_loss: 0.2678 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2639 - accuracy: 0.8911 - val_loss: 0.2657 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2631 - accuracy: 0.8912 - val_loss: 0.2656 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2625 - accuracy: 0.8915 - val_loss: 0.2626 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2617 - accuracy: 0.8917 - val_loss: 0.2669 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 11us/sample - loss: 0.2617 - accuracy: 0.8918 - val_loss: 0.2673 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 5s 11us/sample - loss: 0.2607 - accuracy: 0.8922 - val_loss: 0.2615 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.2600 - accuracy: 0.8924 - val_loss: 0.2610 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2595 - accuracy: 0.8926 - val_loss: 0.2648 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2590 - accuracy: 0.8930 - val_loss: 0.2609 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2583 - accuracy: 0.8928 - val_loss: 0.2584 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2574 - accuracy: 0.8936 - val_loss: 0.2709 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2570 - accuracy: 0.8936 - val_loss: 0.2611 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2559 - accuracy: 0.8941 - val_loss: 0.2560 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2556 - accuracy: 0.8945 - val_loss: 0.2542 - val_accuracy: 0.8946 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2542 - accuracy: 0.8951 - val_loss: 0.2533 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2537 - accuracy: 0.8954 - val_loss: 0.2585 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2528 - accuracy: 0.8957 - val_loss: 0.2511 - val_accuracy: 0.8965 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2516 - accuracy: 0.8964 - val_loss: 0.2492 - val_accuracy: 0.8966 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2511 - accuracy: 0.8965 - val_loss: 0.2582 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2501 - accuracy: 0.8971 - val_loss: 0.2478 - val_accuracy: 0.8972 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2499 - accuracy: 0.8969 - val_loss: 0.2592 - val_accuracy: 0.8928 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2485 - accuracy: 0.8977 - val_loss: 0.2483 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2473 - accuracy: 0.8981 - val_loss: 0.2542 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2462 - accuracy: 0.8987 - val_loss: 0.2433 - val_accuracy: 0.8992 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2457 - accuracy: 0.8992 - val_loss: 0.2531 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2442 - accuracy: 0.8997 - val_loss: 0.2879 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2435 - accuracy: 0.9000 - val_loss: 0.2424 - val_accuracy: 0.8996 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2423 - accuracy: 0.9008 - val_loss: 0.2407 - val_accuracy: 0.9007 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2417 - accuracy: 0.9009 - val_loss: 0.2444 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2401 - accuracy: 0.9018 - val_loss: 0.2540 - val_accuracy: 0.8976 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2400 - accuracy: 0.9016 - val_loss: 0.2390 - val_accuracy: 0.9034 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.23895660345496483\n",
      "accuracy: 0.90336967\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9034  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 67.42   \u001b[0m | \u001b[0m 1e-06   \u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "514624/516858 [============================>.] - ETA: 0s - loss: 0.4489 - accuracy: 0.8384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.4485 - accuracy: 0.8385 - val_loss: 0.3214 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3043 - accuracy: 0.8805 - val_loss: 0.3007 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2884 - accuracy: 0.8848 - val_loss: 0.2817 - val_accuracy: 0.8863 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2815 - accuracy: 0.8864 - val_loss: 0.2825 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2799 - accuracy: 0.8868 - val_loss: 0.2844 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2767 - accuracy: 0.8874 - val_loss: 0.2756 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2734 - accuracy: 0.8884 - val_loss: 0.2734 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2746 - accuracy: 0.8885 - val_loss: 0.2711 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2703 - accuracy: 0.8894 - val_loss: 0.2728 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2737 - accuracy: 0.8887 - val_loss: 0.2721 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2684 - accuracy: 0.8899 - val_loss: 0.2684 - val_accuracy: 0.8896 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2675 - accuracy: 0.8901 - val_loss: 0.2671 - val_accuracy: 0.8897 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2661 - accuracy: 0.8904 - val_loss: 0.2749 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2850 - accuracy: 0.8873 - val_loss: 0.2802 - val_accuracy: 0.8868 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2728 - accuracy: 0.8893 - val_loss: 0.2743 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2681 - accuracy: 0.8902 - val_loss: 0.2707 - val_accuracy: 0.8895 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2660 - accuracy: 0.8908 - val_loss: 0.2686 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2650 - accuracy: 0.8907 - val_loss: 0.2652 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2642 - accuracy: 0.8913 - val_loss: 0.2642 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2638 - accuracy: 0.8913 - val_loss: 0.2669 - val_accuracy: 0.8906 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2628 - accuracy: 0.8916 - val_loss: 0.2655 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2619 - accuracy: 0.8918 - val_loss: 0.2628 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2612 - accuracy: 0.8919 - val_loss: 0.2640 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2607 - accuracy: 0.8922 - val_loss: 0.2604 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2600 - accuracy: 0.8924 - val_loss: 0.2593 - val_accuracy: 0.8926 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2593 - accuracy: 0.8927 - val_loss: 0.2599 - val_accuracy: 0.8918 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2589 - accuracy: 0.8929 - val_loss: 0.2602 - val_accuracy: 0.8922 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2579 - accuracy: 0.8934 - val_loss: 0.2600 - val_accuracy: 0.8926 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2572 - accuracy: 0.8937 - val_loss: 0.2621 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2570 - accuracy: 0.8935 - val_loss: 0.2573 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2558 - accuracy: 0.8942 - val_loss: 0.2540 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2554 - accuracy: 0.8943 - val_loss: 0.2539 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2544 - accuracy: 0.8947 - val_loss: 0.2530 - val_accuracy: 0.8946 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2537 - accuracy: 0.8952 - val_loss: 0.2526 - val_accuracy: 0.8943 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2530 - accuracy: 0.8955 - val_loss: 0.2551 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2519 - accuracy: 0.8961 - val_loss: 0.2501 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2514 - accuracy: 0.8964 - val_loss: 0.2626 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2501 - accuracy: 0.8973 - val_loss: 0.2642 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2495 - accuracy: 0.8975 - val_loss: 0.2490 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2489 - accuracy: 0.8979 - val_loss: 0.2492 - val_accuracy: 0.8981 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2476 - accuracy: 0.8983 - val_loss: 0.2477 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2469 - accuracy: 0.8987 - val_loss: 0.2470 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2455 - accuracy: 0.8993 - val_loss: 0.2621 - val_accuracy: 0.8874 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2451 - accuracy: 0.8997 - val_loss: 0.2434 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2443 - accuracy: 0.9003 - val_loss: 0.2504 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2426 - accuracy: 0.9006 - val_loss: 0.2416 - val_accuracy: 0.8995 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2415 - accuracy: 0.9014 - val_loss: 0.2365 - val_accuracy: 0.9037 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2412 - accuracy: 0.9017 - val_loss: 0.2412 - val_accuracy: 0.8993 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2399 - accuracy: 0.9022 - val_loss: 0.2345 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2391 - accuracy: 0.9025 - val_loss: 0.2359 - val_accuracy: 0.9045 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.23585755396293098\n",
      "accuracy: 0.90454346\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9045  \u001b[0m | \u001b[0m 3.396   \u001b[0m | \u001b[0m 47.88   \u001b[0m | \u001b[0m 0.01658 \u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "513248/516858 [============================>.] - ETA: 0s - loss: 0.4705 - accuracy: 0.8317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.4695 - accuracy: 0.8320 - val_loss: 0.3234 - val_accuracy: 0.8771 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3073 - accuracy: 0.8790 - val_loss: 0.2950 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2899 - accuracy: 0.8843 - val_loss: 0.2928 - val_accuracy: 0.8825 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2834 - accuracy: 0.8863 - val_loss: 0.2943 - val_accuracy: 0.8797 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2781 - accuracy: 0.8873 - val_loss: 0.2787 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.3103 - accuracy: 0.8824 - val_loss: 0.2834 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2779 - accuracy: 0.8879 - val_loss: 0.2766 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2738 - accuracy: 0.8888 - val_loss: 0.2754 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2718 - accuracy: 0.8893 - val_loss: 0.2717 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2703 - accuracy: 0.8897 - val_loss: 0.2717 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2692 - accuracy: 0.8898 - val_loss: 0.2689 - val_accuracy: 0.8894 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2682 - accuracy: 0.8899 - val_loss: 0.2697 - val_accuracy: 0.8896 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2675 - accuracy: 0.8902 - val_loss: 0.2685 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2664 - accuracy: 0.8906 - val_loss: 0.2681 - val_accuracy: 0.8898 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2657 - accuracy: 0.8906 - val_loss: 0.2710 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2650 - accuracy: 0.8905 - val_loss: 0.2726 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2646 - accuracy: 0.8909 - val_loss: 0.2658 - val_accuracy: 0.8898 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2637 - accuracy: 0.8911 - val_loss: 0.2639 - val_accuracy: 0.8908 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2632 - accuracy: 0.8913 - val_loss: 0.2645 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2627 - accuracy: 0.8914 - val_loss: 0.2634 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2617 - accuracy: 0.8917 - val_loss: 0.2625 - val_accuracy: 0.8909 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2614 - accuracy: 0.8919 - val_loss: 0.2674 - val_accuracy: 0.8902 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2606 - accuracy: 0.8922 - val_loss: 0.2630 - val_accuracy: 0.8919 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 5s 10us/sample - loss: 0.2598 - accuracy: 0.8924 - val_loss: 0.2609 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 6s 11us/sample - loss: 0.2595 - accuracy: 0.8926 - val_loss: 0.2679 - val_accuracy: 0.8898 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2585 - accuracy: 0.8926 - val_loss: 0.2609 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2583 - accuracy: 0.8928 - val_loss: 0.2592 - val_accuracy: 0.8911 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2574 - accuracy: 0.8934 - val_loss: 0.2565 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2570 - accuracy: 0.8934 - val_loss: 0.2600 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2559 - accuracy: 0.8939 - val_loss: 0.2558 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2554 - accuracy: 0.8944 - val_loss: 0.2567 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2548 - accuracy: 0.8945 - val_loss: 0.2555 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2543 - accuracy: 0.8947 - val_loss: 0.2590 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2532 - accuracy: 0.8954 - val_loss: 0.2517 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2522 - accuracy: 0.8958 - val_loss: 0.2500 - val_accuracy: 0.8962 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2514 - accuracy: 0.8960 - val_loss: 0.2512 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2507 - accuracy: 0.8964 - val_loss: 0.2487 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2499 - accuracy: 0.8969 - val_loss: 0.2487 - val_accuracy: 0.8975 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2493 - accuracy: 0.8973 - val_loss: 0.2513 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2484 - accuracy: 0.8977 - val_loss: 0.2552 - val_accuracy: 0.8936 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2478 - accuracy: 0.8979 - val_loss: 0.2440 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2459 - accuracy: 0.8989 - val_loss: 0.2572 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2454 - accuracy: 0.8990 - val_loss: 0.2408 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2446 - accuracy: 0.8993 - val_loss: 0.2590 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2432 - accuracy: 0.9002 - val_loss: 0.2398 - val_accuracy: 0.8998 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2432 - accuracy: 0.9001 - val_loss: 0.2487 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2421 - accuracy: 0.9007 - val_loss: 0.2391 - val_accuracy: 0.9020 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2415 - accuracy: 0.9007 - val_loss: 0.2363 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2396 - accuracy: 0.9019 - val_loss: 0.2817 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2392 - accuracy: 0.9015 - val_loss: 0.2346 - val_accuracy: 0.9039 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2345600338965505\n",
      "accuracy: 0.9039115\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9039  \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m 80.82   \u001b[0m | \u001b[0m 0.04588 \u001b[0m |\n",
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/50\n",
      "514624/516858 [============================>.] - ETA: 0s - loss: 0.4578 - accuracy: 0.8384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.4574 - accuracy: 0.8385 - val_loss: 0.3556 - val_accuracy: 0.8556 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.3034 - accuracy: 0.8809 - val_loss: 0.3083 - val_accuracy: 0.8821 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2874 - accuracy: 0.8854 - val_loss: 0.2818 - val_accuracy: 0.8868 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2823 - accuracy: 0.8868 - val_loss: 0.2989 - val_accuracy: 0.8830 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2766 - accuracy: 0.8881 - val_loss: 0.2754 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.3034 - accuracy: 0.8837 - val_loss: 0.2898 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2775 - accuracy: 0.8881 - val_loss: 0.2778 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2731 - accuracy: 0.8892 - val_loss: 0.2734 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2708 - accuracy: 0.8897 - val_loss: 0.2709 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2710 - accuracy: 0.8896 - val_loss: 0.2717 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2681 - accuracy: 0.8902 - val_loss: 0.2695 - val_accuracy: 0.8899 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2951 - accuracy: 0.8864 - val_loss: 0.2831 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2739 - accuracy: 0.8887 - val_loss: 0.2730 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2690 - accuracy: 0.8900 - val_loss: 0.2700 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2671 - accuracy: 0.8905 - val_loss: 0.2733 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2659 - accuracy: 0.8908 - val_loss: 0.2660 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2648 - accuracy: 0.8910 - val_loss: 0.2654 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2643 - accuracy: 0.8913 - val_loss: 0.2713 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2635 - accuracy: 0.8913 - val_loss: 0.2645 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2628 - accuracy: 0.8915 - val_loss: 0.2635 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2622 - accuracy: 0.8918 - val_loss: 0.2649 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2617 - accuracy: 0.8919 - val_loss: 0.2616 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2610 - accuracy: 0.8922 - val_loss: 0.2655 - val_accuracy: 0.8904 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2606 - accuracy: 0.8922 - val_loss: 0.2605 - val_accuracy: 0.8918 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2598 - accuracy: 0.8926 - val_loss: 0.2610 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2593 - accuracy: 0.8928 - val_loss: 0.2663 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2588 - accuracy: 0.8930 - val_loss: 0.2584 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2578 - accuracy: 0.8934 - val_loss: 0.2616 - val_accuracy: 0.8918 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2576 - accuracy: 0.8934 - val_loss: 0.2573 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2565 - accuracy: 0.8937 - val_loss: 0.2705 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2560 - accuracy: 0.8938 - val_loss: 0.2544 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2554 - accuracy: 0.8943 - val_loss: 0.2653 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2548 - accuracy: 0.8945 - val_loss: 0.2606 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2539 - accuracy: 0.8948 - val_loss: 0.2579 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2531 - accuracy: 0.8951 - val_loss: 0.2717 - val_accuracy: 0.8849 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2528 - accuracy: 0.8954 - val_loss: 0.2551 - val_accuracy: 0.8935 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2518 - accuracy: 0.8958 - val_loss: 0.2601 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2513 - accuracy: 0.8961 - val_loss: 0.2489 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2504 - accuracy: 0.8965 - val_loss: 0.2566 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2495 - accuracy: 0.8966 - val_loss: 0.2542 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2484 - accuracy: 0.8973 - val_loss: 0.2457 - val_accuracy: 0.8972 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2479 - accuracy: 0.8974 - val_loss: 0.2874 - val_accuracy: 0.8679 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2471 - accuracy: 0.8978 - val_loss: 0.2436 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2464 - accuracy: 0.8982 - val_loss: 0.2456 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2457 - accuracy: 0.8986 - val_loss: 0.2465 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2444 - accuracy: 0.8992 - val_loss: 0.2424 - val_accuracy: 0.9021 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2434 - accuracy: 0.8995 - val_loss: 0.2434 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "516858/516858 [==============================] - 7s 13us/sample - loss: 0.2428 - accuracy: 0.9000 - val_loss: 0.2439 - val_accuracy: 0.8996 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2412 - accuracy: 0.9005 - val_loss: 0.2389 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "516858/516858 [==============================] - 7s 14us/sample - loss: 0.2414 - accuracy: 0.9008 - val_loss: 0.2428 - val_accuracy: 0.9030 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2427897588580215\n",
      "accuracy: 0.9030085\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.903   \u001b[0m | \u001b[0m 4.001   \u001b[0m | \u001b[0m 94.8    \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "=============================================================\n",
      "Training time: 2806.4361855983734\n",
      "{'target': 0.9078752398490906, 'params': {'batch_size': 2.2514830361124245, 'epochs': 72.31212485077366, 'learning_rate': 1.243736735967132e-05}}\n"
     ]
    }
   ],
   "source": [
    "# Bayesian optimization to choose the best hyperparameters\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f = training,\n",
    "    pbounds = pbounds,\n",
    "    verbose = 2, \n",
    "    random_state = 1,\n",
    ")\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 5)\n",
    "\n",
    "train_end = time.time()\n",
    "train_time = train_end - train_start\n",
    "print(\"Training time:\", train_time)\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0a990c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 516858 samples, validate on 110752 samples\n",
      "Epoch 1/72\n",
      "516858/516858 [==============================] - 54s 104us/sample - loss: 0.3029 - accuracy: 0.8795 - val_loss: 0.2799 - val_accuracy: 0.8874 - lr: 0.0010\n",
      "Epoch 2/72\n",
      "516858/516858 [==============================] - 53s 103us/sample - loss: 0.2743 - accuracy: 0.8880 - val_loss: 0.2732 - val_accuracy: 0.8884 - lr: 0.0010\n",
      "Epoch 3/72\n",
      "516858/516858 [==============================] - 53s 103us/sample - loss: 0.2702 - accuracy: 0.8892 - val_loss: 0.2679 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 4/72\n",
      "516858/516858 [==============================] - 53s 103us/sample - loss: 0.2675 - accuracy: 0.8899 - val_loss: 0.2705 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 5/72\n",
      "516858/516858 [==============================] - 53s 102us/sample - loss: 0.2659 - accuracy: 0.8904 - val_loss: 0.2721 - val_accuracy: 0.8862 - lr: 0.0010\n",
      "Epoch 6/72\n",
      "516858/516858 [==============================] - 53s 103us/sample - loss: 0.2641 - accuracy: 0.8908 - val_loss: 0.2627 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 7/72\n",
      "516858/516858 [==============================] - 53s 102us/sample - loss: 0.2626 - accuracy: 0.8915 - val_loss: 0.2646 - val_accuracy: 0.8901 - lr: 0.0010\n",
      "Epoch 8/72\n",
      "516858/516858 [==============================] - 49s 94us/sample - loss: 0.2609 - accuracy: 0.8920 - val_loss: 0.2591 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Epoch 9/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2588 - accuracy: 0.8927 - val_loss: 0.2546 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 10/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2529 - accuracy: 0.8955 - val_loss: 0.2650 - val_accuracy: 0.8816 - lr: 0.0010\n",
      "Epoch 11/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2392 - accuracy: 0.9017 - val_loss: 0.2351 - val_accuracy: 0.9046 - lr: 0.0010\n",
      "Epoch 12/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2300 - accuracy: 0.9052 - val_loss: 0.2257 - val_accuracy: 0.9082 - lr: 0.0010\n",
      "Epoch 13/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2266 - accuracy: 0.9069 - val_loss: 0.2330 - val_accuracy: 0.9027 - lr: 0.0010\n",
      "Epoch 14/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2238 - accuracy: 0.9078 - val_loss: 0.2265 - val_accuracy: 0.9073 - lr: 0.0010\n",
      "Epoch 15/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2209 - accuracy: 0.9088 - val_loss: 0.2261 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 16/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2191 - accuracy: 0.9093 - val_loss: 0.2163 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 17/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2177 - accuracy: 0.9100 - val_loss: 0.2174 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 18/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2151 - accuracy: 0.9112 - val_loss: 0.2063 - val_accuracy: 0.9143 - lr: 0.0010\n",
      "Epoch 19/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2137 - accuracy: 0.9117 - val_loss: 0.2135 - val_accuracy: 0.9115 - lr: 0.0010\n",
      "Epoch 20/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2135 - accuracy: 0.9120 - val_loss: 0.2755 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Epoch 21/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2127 - accuracy: 0.9121 - val_loss: 0.2073 - val_accuracy: 0.9142 - lr: 0.0010\n",
      "Epoch 22/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2116 - accuracy: 0.9126 - val_loss: 0.2157 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 23/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2108 - accuracy: 0.9129 - val_loss: 0.2243 - val_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 24/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2086 - accuracy: 0.9138 - val_loss: 0.2256 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 25/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2084 - accuracy: 0.9139 - val_loss: 0.2015 - val_accuracy: 0.9177 - lr: 0.0010\n",
      "Epoch 26/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2071 - accuracy: 0.9143 - val_loss: 0.2055 - val_accuracy: 0.9151 - lr: 0.0010\n",
      "Epoch 27/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2067 - accuracy: 0.9147 - val_loss: 0.2025 - val_accuracy: 0.9159 - lr: 0.0010\n",
      "Epoch 28/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2055 - accuracy: 0.9152 - val_loss: 0.2103 - val_accuracy: 0.9161 - lr: 0.0010\n",
      "Epoch 29/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2049 - accuracy: 0.9154 - val_loss: 0.2049 - val_accuracy: 0.9151 - lr: 0.0010\n",
      "Epoch 30/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2042 - accuracy: 0.9153 - val_loss: 0.2106 - val_accuracy: 0.9117 - lr: 0.0010\n",
      "Epoch 31/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2037 - accuracy: 0.9159 - val_loss: 0.1980 - val_accuracy: 0.9189 - lr: 0.0010\n",
      "Epoch 32/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2029 - accuracy: 0.9162 - val_loss: 0.1975 - val_accuracy: 0.9182 - lr: 0.0010\n",
      "Epoch 33/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2029 - accuracy: 0.9163 - val_loss: 0.2148 - val_accuracy: 0.9123 - lr: 0.0010\n",
      "Epoch 34/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2021 - accuracy: 0.9164 - val_loss: 0.2173 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 35/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2022 - accuracy: 0.9166 - val_loss: 0.2023 - val_accuracy: 0.9163 - lr: 0.0010\n",
      "Epoch 36/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2005 - accuracy: 0.9170 - val_loss: 0.1978 - val_accuracy: 0.9181 - lr: 0.0010\n",
      "Epoch 37/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2011 - accuracy: 0.9168 - val_loss: 0.2035 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 38/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.2006 - accuracy: 0.9174 - val_loss: 0.2026 - val_accuracy: 0.9159 - lr: 0.0010\n",
      "Epoch 39/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1992 - accuracy: 0.9175 - val_loss: 0.2288 - val_accuracy: 0.9033 - lr: 0.0010\n",
      "Epoch 40/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1994 - accuracy: 0.9174 - val_loss: 0.1961 - val_accuracy: 0.9186 - lr: 0.0010\n",
      "Epoch 41/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1989 - accuracy: 0.9178 - val_loss: 0.1918 - val_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 42/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1985 - accuracy: 0.9178 - val_loss: 0.1947 - val_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 43/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1977 - accuracy: 0.9183 - val_loss: 0.2015 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Epoch 44/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1977 - accuracy: 0.9183 - val_loss: 0.1919 - val_accuracy: 0.9211 - lr: 0.0010\n",
      "Epoch 45/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1978 - accuracy: 0.9182 - val_loss: 0.1927 - val_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 46/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1975 - accuracy: 0.9184 - val_loss: 0.2001 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Epoch 47/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1973 - accuracy: 0.9184 - val_loss: 0.1984 - val_accuracy: 0.9186 - lr: 0.0010\n",
      "Epoch 48/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1965 - accuracy: 0.9188 - val_loss: 0.1966 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 49/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1963 - accuracy: 0.9188 - val_loss: 0.1979 - val_accuracy: 0.9182 - lr: 0.0010\n",
      "Epoch 50/72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1964 - accuracy: 0.9187 - val_loss: 0.1975 - val_accuracy: 0.9193 - lr: 0.0010\n",
      "Epoch 51/72\n",
      "516858/516858 [==============================] - 49s 94us/sample - loss: 0.1961 - accuracy: 0.9190 - val_loss: 0.2442 - val_accuracy: 0.8995 - lr: 0.0010\n",
      "Epoch 52/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1779 - accuracy: 0.9260 - val_loss: 0.1799 - val_accuracy: 0.9263 - lr: 1.0000e-04\n",
      "Epoch 53/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1753 - accuracy: 0.9270 - val_loss: 0.1802 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 54/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1743 - accuracy: 0.9274 - val_loss: 0.1798 - val_accuracy: 0.9260 - lr: 1.0000e-04\n",
      "Epoch 55/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1736 - accuracy: 0.9277 - val_loss: 0.1780 - val_accuracy: 0.9269 - lr: 1.0000e-04\n",
      "Epoch 56/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1730 - accuracy: 0.9277 - val_loss: 0.1769 - val_accuracy: 0.9270 - lr: 1.0000e-04\n",
      "Epoch 57/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1726 - accuracy: 0.9279 - val_loss: 0.1765 - val_accuracy: 0.9276 - lr: 1.0000e-04\n",
      "Epoch 58/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1721 - accuracy: 0.9280 - val_loss: 0.1762 - val_accuracy: 0.9278 - lr: 1.0000e-04\n",
      "Epoch 59/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1717 - accuracy: 0.9282 - val_loss: 0.1777 - val_accuracy: 0.9270 - lr: 1.0000e-04\n",
      "Epoch 60/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1713 - accuracy: 0.9283 - val_loss: 0.1779 - val_accuracy: 0.9272 - lr: 1.0000e-04\n",
      "Epoch 61/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1711 - accuracy: 0.9287 - val_loss: 0.1766 - val_accuracy: 0.9279 - lr: 1.0000e-04\n",
      "Epoch 62/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1707 - accuracy: 0.9287 - val_loss: 0.1848 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Epoch 63/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1705 - accuracy: 0.9286 - val_loss: 0.1755 - val_accuracy: 0.9282 - lr: 1.0000e-04\n",
      "Epoch 64/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1702 - accuracy: 0.9287 - val_loss: 0.1752 - val_accuracy: 0.9283 - lr: 1.0000e-04\n",
      "Epoch 65/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1700 - accuracy: 0.9290 - val_loss: 0.1812 - val_accuracy: 0.9254 - lr: 1.0000e-04\n",
      "Epoch 66/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1696 - accuracy: 0.9290 - val_loss: 0.1750 - val_accuracy: 0.9281 - lr: 1.0000e-04\n",
      "Epoch 67/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1694 - accuracy: 0.9292 - val_loss: 0.1756 - val_accuracy: 0.9277 - lr: 1.0000e-04\n",
      "Epoch 68/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1692 - accuracy: 0.9293 - val_loss: 0.1763 - val_accuracy: 0.9283 - lr: 1.0000e-04\n",
      "Epoch 69/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1691 - accuracy: 0.9292 - val_loss: 0.1746 - val_accuracy: 0.9279 - lr: 1.0000e-04\n",
      "Epoch 70/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1689 - accuracy: 0.9292 - val_loss: 0.1739 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 71/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1687 - accuracy: 0.9294 - val_loss: 0.1739 - val_accuracy: 0.9284 - lr: 1.0000e-04\n",
      "Epoch 72/72\n",
      "516858/516858 [==============================] - 48s 94us/sample - loss: 0.1685 - accuracy: 0.9295 - val_loss: 0.1739 - val_accuracy: 0.9288 - lr: 1.0000e-04\n",
      "Training time: 3520.346385240555\n"
     ]
    }
   ],
   "source": [
    "# Training step with the best hyperparameters\n",
    "\n",
    "nadam = optimizers.Nadam(learning_rate = optimizer.max['params']['learning_rate'], beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.004)\n",
    "\n",
    "model = CNN()\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "history = model.fit(X_train_CNN, Y_train_CNN, \n",
    "                    epochs = int(optimizer.max['params']['epochs']), \n",
    "                    batch_size = int(32 * optimizer.max['params']['batch_size']), \n",
    "                    validation_data = (X_val_CNN, Y_val_CNN),\n",
    "                    callbacks = [reduce_lr])\n",
    "\n",
    "train_end = time.time()\n",
    "train_time = train_end - train_start\n",
    "print(\"Training time:\", train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc1826",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a12f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time: 6.4987523555755615\n"
     ]
    }
   ],
   "source": [
    "# Testing step\n",
    "\n",
    "test_start = time.time()\n",
    "\n",
    "Y_pred = model.predict(X_test_CNN)\n",
    "\n",
    "test_end = time.time()\n",
    "test_time = test_end - test_start\n",
    "print(\"Testing time:\", test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b4a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_CNN = np.argmax(Y_pred, axis = 1)\n",
    "Y_true_CNN = Y_test_CNN.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97909195",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eebde8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Mirai_Ack','Mirai_Scan','Mirai_Syn','Mirai_Udp','Mirai_Udpplain',\n",
    "          'Bashlite_Combo','Bashlite_Junk','Bashlite_Scan','Bashlite_Udp', 'Bashlite_Tcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0f94382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi classification metrics\n",
    "\n",
    "acc = accuracy_score(Y_true_CNN, Y_pred_CNN) \n",
    "f1 = f1_score(Y_true_CNN, Y_pred_CNN, average = 'weighted')\n",
    "pre = precision_score(Y_true_CNN, Y_pred_CNN, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall = recall_score(Y_true_CNN, Y_pred_CNN, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fd99081",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open(\"../Results/P838_camera_cnn.txt\", \"a\")\n",
    "\n",
    "print(\" ==== Test \" + str(number_features) + \" features \" + str(learning_rate) + \"====\")\n",
    "print(\"Training time:\" + str(train_time))\n",
    "print(\"Testing time:\" + str(test_time))\n",
    "print(\"Accuracy:\" + str(acc))\n",
    "print(\"F1-score:\" + str(f1))\n",
    "print(\"Precision:\" + str(pre))\n",
    "print(\"Recall:\" + str(recall))\n",
    "print(classification_report(Y_true_CNN,Y_pred_CNN, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80dcf5",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6446d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train\n",
    "train_nb_start = time.time()\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "train_nb_end = time.time()\n",
    "train_nb_time = train_nb_end - train_nb_start\n",
    "\n",
    "# Test\n",
    "test_nb_start = time.time()\n",
    "\n",
    "Y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "test_nb_end = time.time()\n",
    "test_nb_time = test_nb_end - test_nb_start\n",
    "\n",
    "# Metrics\n",
    "acc_nb = accuracy_score(Y_test, Y_pred_nb) \n",
    "f1_nb = f1_score(Y_test, Y_pred_nb, average = 'weighted')\n",
    "pre_nb = precision_score(Y_test, Y_pred_nb, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall_nb = recall_score(Y_test, Y_pred_nb, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)\n",
    "\n",
    "print()\n",
    "print(\" ==== Naive Bayes \" + str(number_features) + \" features ====\")\n",
    "print(\"Training time:\" + str(train_nb_time))\n",
    "print(\"Testing time:\" + str(test_nb_time))\n",
    "print(\"Accuracy:\" + str(acc_nb))\n",
    "print(\"F1-score:\" + str(f1_nb))\n",
    "print(\"Precision:\" + str(pre_nb))\n",
    "print(\"Recall:\" + str(recall_nb))\n",
    "print(classification_report(Y_test,Y_pred_nb, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b997f8f",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70d67978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "knn = KNeighborsClassifier(n_neighbors = 50)\n",
    "\n",
    "# Train\n",
    "train_knn_start = time.time()\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "train_knn_end = time.time()\n",
    "train_knn_time = train_knn_end - train_knn_start\n",
    "\n",
    "# Test\n",
    "test_knn_start = time.time()\n",
    "\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "test_knn_end = time.time()\n",
    "test_knn_time = test_knn_end - test_knn_start\n",
    "\n",
    "# Metrics\n",
    "acc_knn = accuracy_score(Y_test, Y_pred_knn) \n",
    "f1_knn = f1_score(Y_test, Y_pred_knn, average = 'weighted')\n",
    "pre_knn = precision_score(Y_test, Y_pred_knn, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall_knn = recall_score(Y_test, Y_pred_knn, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)\n",
    "\n",
    "print()\n",
    "print(\" ==== KNN \" + str(number_features) + \" features ====\")\n",
    "print(\"Training time:\" + str(train_knn_time))\n",
    "print(\"Testing time:\" + str(test_knn_time))\n",
    "print(\"Accuracy:\" + str(acc_knn))\n",
    "print(\"F1-score:\" + str(f1_knn))\n",
    "print(\"Precision:\" + str(pre_knn))\n",
    "print(\"Recall:\" + str(recall_knn))\n",
    "print(classification_report(Y_test,Y_pred_knn, target_names = labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
