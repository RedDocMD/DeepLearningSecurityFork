{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbbffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/andressa.amaral/.local/lib/python3.7/site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.31.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: typing-extensions in /home/andressa.amaral/.local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.7/site-packages (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.44.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.24.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (13.0.0)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (60.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: cached-property in /home/andressa.amaral/.local/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from packaging->tensorflow-gpu) (3.0.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.11.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bayesian-optimization in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.0.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from bayesian-optimization) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 19:39:51.567743: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-18 19:39:51.567765: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install seaborn\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "!pip3 install bayesian-optimization\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, GlobalAveragePooling1D, BatchNormalization\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, mean_squared_error, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58caf092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 19:39:52.557754: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-18 19:39:53.394038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-18 19:39:53.394157: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-18 19:39:53.394252: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-18 19:39:53.396994: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-18 19:39:53.397090: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-05-18 19:39:53.397188: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-05-18 19:39:53.397201: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.compat.v1.Session(config = tf.compat.v1.ConfigProto(gpu_options = gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b395c4",
   "metadata": {},
   "source": [
    "# P737 Security Camera Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37bb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign traffic\n",
    "\n",
    "p7_benign = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/benign_traffic.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_benign = p7_benign.copy(deep=True)\n",
    "\n",
    "columns = list(df_p7_benign.columns)\n",
    "chosen_columns = []\n",
    "for column in columns:\n",
    "    if column.find('L5') != -1:\n",
    "        chosen_columns.append(column)\n",
    "\n",
    "df_p7_benign = pd.DataFrame(df_p7_benign, columns = chosen_columns)\n",
    "\n",
    "# Mirai\n",
    "\n",
    "p7_mirai_ack = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/mirai/ack.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_mirai_ack = p7_mirai_ack.copy(deep=True)\n",
    "df_p7_mirai_ack = pd.DataFrame(df_p7_mirai_ack, columns = chosen_columns)\n",
    "df_p7_mirai_ack = df_p7_mirai_ack.sample(frac=1)\n",
    "\n",
    "p7_mirai_scan = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/mirai/scan.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_mirai_scan = p7_mirai_scan.copy(deep=True)\n",
    "df_p7_mirai_scan = pd.DataFrame(df_p7_mirai_scan, columns = chosen_columns)\n",
    "df_p7_mirai_scan = df_p7_mirai_scan.sample(frac=1)\n",
    "\n",
    "p7_mirai_syn = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/mirai/syn.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_mirai_syn = p7_mirai_syn.copy(deep=True)\n",
    "df_p7_mirai_syn = pd.DataFrame(df_p7_mirai_syn, columns = chosen_columns)\n",
    "df_p7_mirai_syn = df_p7_mirai_syn.sample(frac=1)\n",
    "\n",
    "p7_mirai_udp = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/mirai/udp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_mirai_udp = p7_mirai_udp.copy(deep=True)\n",
    "df_p7_mirai_udp = pd.DataFrame(df_p7_mirai_udp, columns = chosen_columns)\n",
    "df_p7_mirai_udp = df_p7_mirai_udp.sample(frac=1)\n",
    "\n",
    "p7_mirai_udpplain = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/mirai/udpplain.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_mirai_udpplain = p7_mirai_udpplain.copy(deep=True)\n",
    "df_p7_mirai_udpplain = pd.DataFrame(df_p7_mirai_udpplain, columns = chosen_columns)\n",
    "df_p7_mirai_udpplain = df_p7_mirai_udpplain.sample(frac=1)\n",
    "\n",
    "# Bashlite\n",
    "\n",
    "p7_bashlite_combo = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/gafgyt/combo.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_bashlite_combo = p7_bashlite_combo.copy(deep=True)\n",
    "df_p7_bashlite_combo = pd.DataFrame(df_p7_bashlite_combo, columns = chosen_columns)\n",
    "df_p7_bashlite_combo = df_p7_bashlite_combo.sample(frac=1)\n",
    "\n",
    "p7_bashlite_junk = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/gafgyt/junk.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_bashlite_junk = p7_bashlite_junk.copy(deep=True)\n",
    "df_p7_bashlite_junk = pd.DataFrame(df_p7_bashlite_junk, columns = chosen_columns)\n",
    "df_p7_bashlite_junk = df_p7_bashlite_junk.sample(frac=1)\n",
    "\n",
    "p7_bashlite_scan = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/gafgyt/scan.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_bashlite_scan = p7_bashlite_scan.copy(deep=True)\n",
    "df_p7_bashlite_scan = pd.DataFrame(df_p7_bashlite_scan, columns = chosen_columns)\n",
    "df_p7_bashlite_scan = df_p7_bashlite_scan.sample(frac=1)\n",
    "\n",
    "p7_bashlite_udp = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/gafgyt/udp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_bashlite_udp = p7_bashlite_udp.copy(deep=True)\n",
    "df_p7_bashlite_udp = pd.DataFrame(df_p7_bashlite_udp, columns = chosen_columns)\n",
    "df_p7_bashlite_udp = df_p7_bashlite_udp.sample(frac=1)\n",
    "\n",
    "p7_bashlite_tcp = pd.read_csv('../nbaiot/Provision_PT_737E_Security_Camera/gafgyt/tcp.csv', encoding = \"utf-8\", sep = ',' ) \n",
    "df_p7_bashlite_tcp = p7_bashlite_tcp.copy(deep=True)\n",
    "df_p7_bashlite_tcp = pd.DataFrame(df_p7_bashlite_tcp, columns = chosen_columns)\n",
    "df_p7_bashlite_tcp = df_p7_bashlite_tcp.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163ff1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing information\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_p7_miraiack_norm = scaler.fit_transform(df_p7_mirai_ack)\n",
    "df_p7_miraiscan_norm = scaler.fit_transform(df_p7_mirai_scan)\n",
    "df_p7_miraisyn_norm = scaler.fit_transform(df_p7_mirai_syn)\n",
    "df_p7_miraiudp_norm = scaler.fit_transform(df_p7_mirai_udp)\n",
    "df_p7_miraiudpplain_norm = scaler.fit_transform(df_p7_mirai_udpplain)\n",
    "\n",
    "df_p7_bashlitecombo_norm = scaler.fit_transform(df_p7_bashlite_combo)\n",
    "df_p7_bashlitejunk_norm = scaler.fit_transform(df_p7_bashlite_junk)\n",
    "df_p7_bashlitescan_norm = scaler.fit_transform(df_p7_bashlite_scan)\n",
    "df_p7_bashliteudp_norm = scaler.fit_transform(df_p7_bashlite_udp)\n",
    "df_p7_bashlitetcp_norm = scaler.fit_transform(df_p7_bashlite_tcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637cf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirai attack labelization\n",
    "\n",
    "label_mirai_ack = list(np.full(df_p7_miraiack_norm.shape[0], 0))\n",
    "miraiack_norm = pd.DataFrame(df_p7_miraiack_norm)\n",
    "miraiack_norm['Label'] = label_mirai_ack\n",
    "\n",
    "label_mirai_scan = list(np.full(df_p7_miraiscan_norm.shape[0], 1))\n",
    "miraiscan_norm = pd.DataFrame(df_p7_miraiscan_norm)\n",
    "miraiscan_norm['Label'] = label_mirai_scan\n",
    "\n",
    "label_mirai_syn = list(np.full(df_p7_miraisyn_norm.shape[0], 2))\n",
    "miraisyn_norm = pd.DataFrame(df_p7_miraisyn_norm)\n",
    "miraisyn_norm['Label'] = label_mirai_syn\n",
    "\n",
    "label_mirai_udp = list(np.full(df_p7_miraiudp_norm.shape[0], 3))\n",
    "miraiudp_norm = pd.DataFrame(df_p7_miraiudp_norm)\n",
    "miraiudp_norm['Label'] = label_mirai_udp\n",
    "\n",
    "label_mirai_udpplain = list(np.full(df_p7_miraiudpplain_norm.shape[0], 4))\n",
    "miraiudpplain_norm = pd.DataFrame(df_p7_miraiudpplain_norm)\n",
    "miraiudpplain_norm['Label'] = label_mirai_udpplain\n",
    "\n",
    "# Bashlite attack labelization\n",
    "\n",
    "label_bashlite_combo = list(np.full(df_p7_bashlitecombo_norm.shape[0], 5))\n",
    "bashlitecombo_norm = pd.DataFrame(df_p7_bashlitecombo_norm)\n",
    "bashlitecombo_norm['Label'] = label_bashlite_combo\n",
    "\n",
    "label_bashlite_junk = list(np.full(df_p7_bashlitejunk_norm.shape[0], 6))\n",
    "bashlitejunk_norm = pd.DataFrame(df_p7_bashlitejunk_norm)\n",
    "bashlitejunk_norm['Label'] = label_bashlite_junk\n",
    "\n",
    "label_bashlite_scan = list(np.full(df_p7_bashlitescan_norm.shape[0], 7))\n",
    "bashlitescan_norm = pd.DataFrame(df_p7_bashlitescan_norm)\n",
    "bashlitescan_norm['Label'] = label_bashlite_scan\n",
    "\n",
    "label_bashlite_udp = list(np.full(df_p7_bashliteudp_norm.shape[0], 8))\n",
    "bashliteudp_norm = pd.DataFrame(df_p7_bashliteudp_norm)\n",
    "bashliteudp_norm['Label'] = label_bashlite_udp\n",
    "\n",
    "label_bashlite_tcp = list(np.full(df_p7_bashlitetcp_norm.shape[0], 9))\n",
    "bashlitetcp_norm = pd.DataFrame(df_p7_bashlitetcp_norm)\n",
    "bashlitetcp_norm['Label'] = label_bashlite_tcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734d752",
   "metadata": {},
   "source": [
    "# CNN - Attack Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30489bd3",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417aa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "number_features = 23\n",
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "\n",
    "dict_params = { 'learning_rate': learning_rate, 'batch_size': int(32 * batch_size), 'epochs': int(epochs) }\n",
    "pbounds = { 'learning_rate': (0.000001, 0.1), 'batch_size': (1, 4.001), 'epochs': (1, 100) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794890bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269\n"
     ]
    }
   ],
   "source": [
    "# Train set\n",
    "\n",
    "len_mirai_ack_train = int(0.7 * len(miraiack_norm))\n",
    "X_train_mirai_ack = miraiack_norm[:len_mirai_ack_train]\n",
    "\n",
    "len_mirai_scan_train = int(0.7 * len(miraiscan_norm))\n",
    "X_train_mirai_scan = miraiscan_norm[:len_mirai_scan_train]\n",
    "\n",
    "len_mirai_syn_train = int(0.7 * len(miraisyn_norm))\n",
    "X_train_mirai_syn = miraisyn_norm[:len_mirai_syn_train]\n",
    "\n",
    "len_mirai_udp_train = int(0.7 * len(miraiudp_norm))\n",
    "X_train_mirai_udp = miraiudp_norm[:len_mirai_udp_train]\n",
    "\n",
    "len_mirai_udpplain_train = int(0.7 * len(miraiudpplain_norm))\n",
    "X_train_mirai_udpplain = miraiudpplain_norm[:len_mirai_udpplain_train]\n",
    "\n",
    "len_bashlite_combo_train = int(0.7 * len(bashlitecombo_norm))\n",
    "X_train_bashlite_combo = bashlitecombo_norm[:len_bashlite_combo_train]\n",
    "\n",
    "len_bashlite_junk_train = int(0.7 * len(bashlitejunk_norm))\n",
    "X_train_bashlite_junk = bashlitejunk_norm[:len_bashlite_junk_train]\n",
    "\n",
    "len_bashlite_scan_train = int(0.7 * len(bashlitescan_norm))\n",
    "X_train_bashlite_scan = bashlitescan_norm[:len_bashlite_scan_train]\n",
    "\n",
    "len_bashlite_udp_train = int(0.7 * len(bashliteudp_norm))\n",
    "X_train_bashlite_udp = bashliteudp_norm[:len_bashlite_udp_train]\n",
    "\n",
    "len_bashlite_tcp_train = int(0.7 * len(bashlitetcp_norm))\n",
    "X_train_bashlite_tcp = bashlitetcp_norm[:len_bashlite_tcp_train]\n",
    "\n",
    "np_train = np.concatenate([X_train_mirai_ack, X_train_mirai_scan, X_train_mirai_syn, X_train_mirai_udp, X_train_mirai_udpplain,\n",
    "                          X_train_bashlite_combo, X_train_bashlite_junk, X_train_bashlite_scan, X_train_bashlite_udp,\n",
    "                          X_train_bashlite_tcp])\n",
    "\n",
    "df_train = pd.DataFrame(np_train)\n",
    "label_train = df_train.pop(number_features)\n",
    "\n",
    "X_train = df_train.to_numpy()\n",
    "Y_train = label_train.to_numpy()\n",
    "\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb416951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114912\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "\n",
    "len_mirai_ack_test = len_mirai_ack_train + int(0.15 * len(miraiack_norm))\n",
    "X_test_mirai_ack = miraiack_norm[len_mirai_ack_train : len_mirai_ack_test]\n",
    "\n",
    "len_mirai_scan_test = len_mirai_scan_train + int(0.15 * len(miraiscan_norm))\n",
    "X_test_mirai_scan = miraiscan_norm[len_mirai_scan_train : len_mirai_scan_test]\n",
    "\n",
    "len_mirai_syn_test = len_mirai_syn_train + int(0.15 * len(miraisyn_norm))\n",
    "X_test_mirai_syn = miraisyn_norm[len_mirai_syn_train : len_mirai_syn_test]\n",
    "\n",
    "len_mirai_udp_test = len_mirai_udp_train + int(0.15 * len(miraiudp_norm))\n",
    "X_test_mirai_udp = miraiudp_norm[len_mirai_udp_train : len_mirai_udp_test]\n",
    "\n",
    "len_mirai_udpplain_test = len_mirai_udpplain_train + int(0.15 * len(miraiudpplain_norm))\n",
    "X_test_mirai_udpplain = miraiudpplain_norm[len_mirai_udpplain_train : len_mirai_udpplain_test]\n",
    "\n",
    "len_bashlite_combo_test = len_bashlite_combo_train + int(0.15 * len(bashlitecombo_norm))\n",
    "X_test_bashlite_combo = bashlitecombo_norm[len_bashlite_combo_train : len_bashlite_combo_test]\n",
    "\n",
    "len_bashlite_junk_test = len_bashlite_junk_train + int(0.15 * len(bashlitejunk_norm))\n",
    "X_test_bashlite_junk = bashlitejunk_norm[len_bashlite_junk_train : len_bashlite_junk_test]\n",
    "\n",
    "len_bashlite_scan_test = len_bashlite_scan_train + int(0.15 * len(bashlitescan_norm))\n",
    "X_test_bashlite_scan = bashlitescan_norm[len_bashlite_scan_train : len_bashlite_scan_test]\n",
    "\n",
    "len_bashlite_udp_test = len_bashlite_udp_train + int(0.15 * len(bashliteudp_norm))\n",
    "X_test_bashlite_udp = bashliteudp_norm[len_bashlite_udp_train : len_bashlite_udp_test]\n",
    "\n",
    "len_bashlite_tcp_test = len_bashlite_tcp_train + int(0.15 * len(bashlitetcp_norm))\n",
    "X_test_bashlite_tcp = bashlitetcp_norm[len_bashlite_tcp_train : len_bashlite_tcp_test]\n",
    "\n",
    "np_test = np.concatenate([X_test_mirai_ack, X_test_mirai_scan, X_test_mirai_syn, X_test_mirai_udp, X_test_mirai_udpplain,\n",
    "                          X_test_bashlite_combo, X_test_bashlite_junk, X_test_bashlite_scan, X_test_bashlite_udp,\n",
    "                          X_test_bashlite_tcp])\n",
    "\n",
    "df_test = pd.DataFrame(np_test)\n",
    "label_test = df_test.pop(number_features)\n",
    "\n",
    "X_test = df_test.to_numpy()\n",
    "Y_test = label_test.to_numpy()\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c07d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "\n",
    "X_val_mirai_ack = miraiack_norm[len_mirai_ack_test:]\n",
    "X_val_mirai_scan = miraiscan_norm[len_mirai_scan_test:]\n",
    "X_val_mirai_syn = miraisyn_norm[len_mirai_syn_test:]\n",
    "X_val_mirai_udp = miraiudp_norm[len_mirai_udp_test:]\n",
    "X_val_mirai_udpplain = miraiudpplain_norm[len_mirai_udpplain_test:]\n",
    "\n",
    "X_val_bashlite_combo = bashlitecombo_norm[len_bashlite_combo_test:]\n",
    "X_val_bashlite_junk = bashlitejunk_norm[len_bashlite_junk_test:]\n",
    "X_val_bashlite_scan = bashlitescan_norm[len_bashlite_scan_test:]\n",
    "X_val_bashlite_udp = bashlitetcp_norm[len_bashlite_udp_test:]\n",
    "X_val_bashlite_tcp = bashlitetcp_norm[len_bashlite_tcp_test:]\n",
    "\n",
    "np_val = np.concatenate([X_val_mirai_ack, X_val_mirai_scan, X_val_mirai_syn, X_val_mirai_udp, X_val_mirai_udpplain,\n",
    "                          X_val_bashlite_combo, X_val_bashlite_junk, X_val_bashlite_scan, X_val_bashlite_udp,\n",
    "                          X_val_bashlite_tcp])\n",
    "\n",
    "df_val = pd.DataFrame(np_test)\n",
    "label_test = df_val.pop(number_features)\n",
    "\n",
    "X_val = df_val.to_numpy()\n",
    "Y_val = label_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b160bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CNN = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_CNN = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_val_CNN = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "Y_train_CNN = Y_train\n",
    "Y_test_CNN = Y_test\n",
    "Y_val_CNN = Y_val\n",
    "\n",
    "samples, feature, depth = X_train_CNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb23327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with 1D convolutional layer\n",
    "\n",
    "def CNN():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform', input_shape=(feature, depth)))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "328333ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(moniter = 'val_loss', factor = 0.1, patience = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cbc860",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20b0d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step with Bayesian optimization\n",
    "\n",
    "def training(X_train = X_train_CNN,\n",
    "             Y_train = Y_train_CNN, \n",
    "             X_val = X_val_CNN, \n",
    "             Y_val = Y_val_CNN, \n",
    "             X_test = X_test_CNN, \n",
    "             Y_test = Y_test_CNN, \n",
    "             learning_rate = learning_rate, \n",
    "             epochs = epochs, \n",
    "             batch_size = batch_size,\n",
    "             reduce_lr = reduce_lr):\n",
    "    \n",
    "    nadam = optimizers.Nadam(learning_rate = dict_params['learning_rate'], beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.004)\n",
    "    \n",
    "    model = CNN()\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, \n",
    "                        epochs = dict_params['epochs'], \n",
    "                        batch_size = dict_params['batch_size'], \n",
    "                        validation_data = (X_val, Y_val),\n",
    "                        callbacks = [reduce_lr])\n",
    "    \n",
    "    scores = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    print('loss:', scores[0])\n",
    "    print('accuracy:', scores[1])\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e91d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |  epochs   | learni... |\n",
      "-------------------------------------------------------------\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 19:40:03.180959: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-18 19:40:03.211438: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.4243 - accuracy: 0.8439 - val_loss: 0.3001 - val_accuracy: 0.8828 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2886 - accuracy: 0.8853 - val_loss: 0.2670 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2600 - accuracy: 0.8993 - val_loss: 0.2505 - val_accuracy: 0.8906 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2279 - accuracy: 0.9131 - val_loss: 0.2040 - val_accuracy: 0.9234 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2077 - accuracy: 0.9207 - val_loss: 0.1946 - val_accuracy: 0.9241 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1980 - accuracy: 0.9229 - val_loss: 0.1974 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2033 - accuracy: 0.9217 - val_loss: 0.1953 - val_accuracy: 0.9242 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1915 - accuracy: 0.9245 - val_loss: 0.1894 - val_accuracy: 0.9248 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1899 - accuracy: 0.9245 - val_loss: 0.1908 - val_accuracy: 0.9251 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2140 - accuracy: 0.9210 - val_loss: 0.2118 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1974 - accuracy: 0.9233 - val_loss: 0.1880 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1887 - accuracy: 0.9251 - val_loss: 0.1928 - val_accuracy: 0.9225 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1966 - accuracy: 0.9242 - val_loss: 0.1882 - val_accuracy: 0.9262 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1865 - accuracy: 0.9255 - val_loss: 0.1850 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1852 - accuracy: 0.9259 - val_loss: 0.1832 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1846 - accuracy: 0.9258 - val_loss: 0.1901 - val_accuracy: 0.9238 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1895 - accuracy: 0.9255 - val_loss: 0.1816 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1831 - accuracy: 0.9263 - val_loss: 0.1843 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1824 - accuracy: 0.9265 - val_loss: 0.1914 - val_accuracy: 0.9241 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1927 - accuracy: 0.9257 - val_loss: 0.1816 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1809 - accuracy: 0.9270 - val_loss: 0.1795 - val_accuracy: 0.9287 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1803 - accuracy: 0.9273 - val_loss: 0.1883 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1799 - accuracy: 0.9274 - val_loss: 0.1796 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1790 - accuracy: 0.9276 - val_loss: 0.1843 - val_accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1782 - accuracy: 0.9280 - val_loss: 0.1765 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1776 - accuracy: 0.9281 - val_loss: 0.1772 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1767 - accuracy: 0.9289 - val_loss: 0.1741 - val_accuracy: 0.9311 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1763 - accuracy: 0.9288 - val_loss: 0.1726 - val_accuracy: 0.9313 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1752 - accuracy: 0.9293 - val_loss: 0.1742 - val_accuracy: 0.9299 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1743 - accuracy: 0.9300 - val_loss: 0.1724 - val_accuracy: 0.9307 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1732 - accuracy: 0.9303 - val_loss: 0.1926 - val_accuracy: 0.9163 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1726 - accuracy: 0.9305 - val_loss: 0.1677 - val_accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1716 - accuracy: 0.9309 - val_loss: 0.1861 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1703 - accuracy: 0.9318 - val_loss: 0.1676 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1695 - accuracy: 0.9320 - val_loss: 0.1823 - val_accuracy: 0.9258 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1686 - accuracy: 0.9323 - val_loss: 0.1674 - val_accuracy: 0.9348 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1676 - accuracy: 0.9327 - val_loss: 0.1617 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1663 - accuracy: 0.9332 - val_loss: 0.1644 - val_accuracy: 0.9380 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1657 - accuracy: 0.9338 - val_loss: 0.1653 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1646 - accuracy: 0.9344 - val_loss: 0.1614 - val_accuracy: 0.9372 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1641 - accuracy: 0.9342 - val_loss: 0.1705 - val_accuracy: 0.9291 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1627 - accuracy: 0.9348 - val_loss: 0.1796 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1612 - accuracy: 0.9357 - val_loss: 0.1559 - val_accuracy: 0.9377 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1599 - accuracy: 0.9358 - val_loss: 0.1717 - val_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1593 - accuracy: 0.9363 - val_loss: 0.1530 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1587 - accuracy: 0.9364 - val_loss: 0.1533 - val_accuracy: 0.9384 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1569 - accuracy: 0.9373 - val_loss: 0.1652 - val_accuracy: 0.9298 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1559 - accuracy: 0.9376 - val_loss: 0.1540 - val_accuracy: 0.9427 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1560 - accuracy: 0.9378 - val_loss: 0.1640 - val_accuracy: 0.9287 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1551 - accuracy: 0.9378 - val_loss: 0.1502 - val_accuracy: 0.9417 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.15020566682677228\n",
      "accuracy: 0.941651\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9417  \u001b[0m | \u001b[0m 2.251   \u001b[0m | \u001b[0m 72.31   \u001b[0m | \u001b[0m 1.244e-0\u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.4434 - accuracy: 0.8358 - val_loss: 0.3190 - val_accuracy: 0.8753 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2927 - accuracy: 0.8827 - val_loss: 0.2756 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2731 - accuracy: 0.8907 - val_loss: 0.2530 - val_accuracy: 0.9052 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2514 - accuracy: 0.9031 - val_loss: 0.2375 - val_accuracy: 0.9144 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2268 - accuracy: 0.9135 - val_loss: 0.2596 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2162 - accuracy: 0.9179 - val_loss: 0.2120 - val_accuracy: 0.9181 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2143 - accuracy: 0.9187 - val_loss: 0.2055 - val_accuracy: 0.9212 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1993 - accuracy: 0.9228 - val_loss: 0.1944 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1914 - accuracy: 0.9243 - val_loss: 0.1890 - val_accuracy: 0.9247 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1913 - accuracy: 0.9244 - val_loss: 0.1896 - val_accuracy: 0.9254 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2140 - accuracy: 0.9200 - val_loss: 0.1898 - val_accuracy: 0.9253 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1890 - accuracy: 0.9250 - val_loss: 0.1870 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2010 - accuracy: 0.9236 - val_loss: 0.1924 - val_accuracy: 0.9238 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1877 - accuracy: 0.9254 - val_loss: 0.1888 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1857 - accuracy: 0.9257 - val_loss: 0.1830 - val_accuracy: 0.9270 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1973 - accuracy: 0.9242 - val_loss: 0.2007 - val_accuracy: 0.9228 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1872 - accuracy: 0.9259 - val_loss: 0.1832 - val_accuracy: 0.9265 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1836 - accuracy: 0.9264 - val_loss: 0.1828 - val_accuracy: 0.9285 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1826 - accuracy: 0.9266 - val_loss: 0.1816 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1819 - accuracy: 0.9268 - val_loss: 0.1814 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1812 - accuracy: 0.9269 - val_loss: 0.1824 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1895 - accuracy: 0.9264 - val_loss: 0.1861 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1808 - accuracy: 0.9278 - val_loss: 0.1790 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1791 - accuracy: 0.9281 - val_loss: 0.1772 - val_accuracy: 0.9280 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1776 - accuracy: 0.9286 - val_loss: 0.1739 - val_accuracy: 0.9295 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1771 - accuracy: 0.9288 - val_loss: 0.1746 - val_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1760 - accuracy: 0.9291 - val_loss: 0.1760 - val_accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1753 - accuracy: 0.9296 - val_loss: 0.1738 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1739 - accuracy: 0.9302 - val_loss: 0.1746 - val_accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1729 - accuracy: 0.9307 - val_loss: 0.1727 - val_accuracy: 0.9346 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1722 - accuracy: 0.9309 - val_loss: 0.1723 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1706 - accuracy: 0.9317 - val_loss: 0.1666 - val_accuracy: 0.9326 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1701 - accuracy: 0.9320 - val_loss: 0.1642 - val_accuracy: 0.9350 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1688 - accuracy: 0.9325 - val_loss: 0.1620 - val_accuracy: 0.9399 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1678 - accuracy: 0.9332 - val_loss: 0.1786 - val_accuracy: 0.9273 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1666 - accuracy: 0.9337 - val_loss: 0.1615 - val_accuracy: 0.9357 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1652 - accuracy: 0.9345 - val_loss: 0.1660 - val_accuracy: 0.9374 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1644 - accuracy: 0.9349 - val_loss: 0.1724 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1636 - accuracy: 0.9351 - val_loss: 0.1581 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1626 - accuracy: 0.9354 - val_loss: 0.1677 - val_accuracy: 0.9299 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1600 - accuracy: 0.9369 - val_loss: 0.1534 - val_accuracy: 0.9425 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1611 - accuracy: 0.9367 - val_loss: 0.1743 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1592 - accuracy: 0.9371 - val_loss: 0.1679 - val_accuracy: 0.9302 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1575 - accuracy: 0.9380 - val_loss: 0.1511 - val_accuracy: 0.9401 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1568 - accuracy: 0.9380 - val_loss: 0.1714 - val_accuracy: 0.9264 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1559 - accuracy: 0.9382 - val_loss: 0.1510 - val_accuracy: 0.9435 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1560 - accuracy: 0.9383 - val_loss: 0.1531 - val_accuracy: 0.9395 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1535 - accuracy: 0.9395 - val_loss: 0.1507 - val_accuracy: 0.9438 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1542 - accuracy: 0.9394 - val_loss: 0.1465 - val_accuracy: 0.9434 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1524 - accuracy: 0.9401 - val_loss: 0.1458 - val_accuracy: 0.9446 - lr: 0.0010\n",
      "loss: 0.1458194933238936\n",
      "accuracy: 0.94463587\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9446  \u001b[0m | \u001b[95m 1.907   \u001b[0m | \u001b[95m 15.53   \u001b[0m | \u001b[95m 0.009235\u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.4140 - accuracy: 0.8466 - val_loss: 0.3020 - val_accuracy: 0.8813 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2905 - accuracy: 0.8840 - val_loss: 0.2751 - val_accuracy: 0.8926 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2671 - accuracy: 0.8948 - val_loss: 0.2407 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2628 - accuracy: 0.9023 - val_loss: 0.2400 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2231 - accuracy: 0.9154 - val_loss: 0.2068 - val_accuracy: 0.9214 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2078 - accuracy: 0.9205 - val_loss: 0.1985 - val_accuracy: 0.9226 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2153 - accuracy: 0.9183 - val_loss: 0.2019 - val_accuracy: 0.9234 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1991 - accuracy: 0.9228 - val_loss: 0.1990 - val_accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1967 - accuracy: 0.9234 - val_loss: 0.1901 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1901 - accuracy: 0.9248 - val_loss: 0.1968 - val_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1887 - accuracy: 0.9251 - val_loss: 0.1849 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1955 - accuracy: 0.9240 - val_loss: 0.1870 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1870 - accuracy: 0.9252 - val_loss: 0.1848 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2005 - accuracy: 0.9229 - val_loss: 0.1859 - val_accuracy: 0.9263 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1976 - accuracy: 0.9231 - val_loss: 0.2012 - val_accuracy: 0.9240 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1904 - accuracy: 0.9250 - val_loss: 0.1860 - val_accuracy: 0.9263 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1855 - accuracy: 0.9260 - val_loss: 0.1825 - val_accuracy: 0.9270 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1838 - accuracy: 0.9264 - val_loss: 0.1845 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1834 - accuracy: 0.9262 - val_loss: 0.1846 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1886 - accuracy: 0.9256 - val_loss: 0.1814 - val_accuracy: 0.9276 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1817 - accuracy: 0.9271 - val_loss: 0.1799 - val_accuracy: 0.9278 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1810 - accuracy: 0.9269 - val_loss: 0.1809 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1802 - accuracy: 0.9276 - val_loss: 0.1800 - val_accuracy: 0.9278 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1794 - accuracy: 0.9276 - val_loss: 0.1768 - val_accuracy: 0.9302 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1787 - accuracy: 0.9280 - val_loss: 0.1793 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1778 - accuracy: 0.9283 - val_loss: 0.1815 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1777 - accuracy: 0.9282 - val_loss: 0.1744 - val_accuracy: 0.9317 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1765 - accuracy: 0.9288 - val_loss: 0.1749 - val_accuracy: 0.9298 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1756 - accuracy: 0.9292 - val_loss: 0.1879 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1751 - accuracy: 0.9296 - val_loss: 0.1731 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1746 - accuracy: 0.9297 - val_loss: 0.1717 - val_accuracy: 0.9311 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1736 - accuracy: 0.9301 - val_loss: 0.1702 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1732 - accuracy: 0.9304 - val_loss: 0.1687 - val_accuracy: 0.9326 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1722 - accuracy: 0.9307 - val_loss: 0.1688 - val_accuracy: 0.9331 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1707 - accuracy: 0.9314 - val_loss: 0.1670 - val_accuracy: 0.9344 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1702 - accuracy: 0.9321 - val_loss: 0.1712 - val_accuracy: 0.9326 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1694 - accuracy: 0.9321 - val_loss: 0.1638 - val_accuracy: 0.9401 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1683 - accuracy: 0.9326 - val_loss: 0.1816 - val_accuracy: 0.9236 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1676 - accuracy: 0.9330 - val_loss: 0.1639 - val_accuracy: 0.9332 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1667 - accuracy: 0.9334 - val_loss: 0.1654 - val_accuracy: 0.9331 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1657 - accuracy: 0.9341 - val_loss: 0.1601 - val_accuracy: 0.9404 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1646 - accuracy: 0.9343 - val_loss: 0.1610 - val_accuracy: 0.9360 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1642 - accuracy: 0.9344 - val_loss: 0.1618 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1631 - accuracy: 0.9349 - val_loss: 0.1593 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1616 - accuracy: 0.9356 - val_loss: 0.1556 - val_accuracy: 0.9376 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1618 - accuracy: 0.9356 - val_loss: 0.1695 - val_accuracy: 0.9336 - lr: 0.0010\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1608 - accuracy: 0.9359 - val_loss: 0.1662 - val_accuracy: 0.9332 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1596 - accuracy: 0.9362 - val_loss: 0.1740 - val_accuracy: 0.9229 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1590 - accuracy: 0.9368 - val_loss: 0.1556 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1583 - accuracy: 0.9369 - val_loss: 0.1855 - val_accuracy: 0.9168 - lr: 0.0010\n",
      "loss: 0.18547919576048458\n",
      "accuracy: 0.9168059\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9168  \u001b[0m | \u001b[0m 1.559   \u001b[0m | \u001b[0m 35.21   \u001b[0m | \u001b[0m 0.03968 \u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.4182 - accuracy: 0.8449 - val_loss: 0.2927 - val_accuracy: 0.8830 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2875 - accuracy: 0.8853 - val_loss: 0.2731 - val_accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2627 - accuracy: 0.8970 - val_loss: 0.2320 - val_accuracy: 0.9139 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2325 - accuracy: 0.9115 - val_loss: 0.2088 - val_accuracy: 0.9231 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2133 - accuracy: 0.9188 - val_loss: 0.4390 - val_accuracy: 0.8109 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2050 - accuracy: 0.9214 - val_loss: 0.1943 - val_accuracy: 0.9244 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2055 - accuracy: 0.9214 - val_loss: 0.1947 - val_accuracy: 0.9243 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2083 - accuracy: 0.9198 - val_loss: 0.2007 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1978 - accuracy: 0.9233 - val_loss: 0.1893 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2095 - accuracy: 0.9204 - val_loss: 0.1963 - val_accuracy: 0.9241 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1949 - accuracy: 0.9239 - val_loss: 0.1938 - val_accuracy: 0.9252 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1885 - accuracy: 0.9251 - val_loss: 0.1909 - val_accuracy: 0.9247 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1911 - accuracy: 0.9248 - val_loss: 0.1853 - val_accuracy: 0.9258 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1854 - accuracy: 0.9258 - val_loss: 0.1925 - val_accuracy: 0.9232 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1849 - accuracy: 0.9260 - val_loss: 0.1884 - val_accuracy: 0.9247 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1918 - accuracy: 0.9250 - val_loss: 0.1853 - val_accuracy: 0.9264 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1844 - accuracy: 0.9261 - val_loss: 0.1819 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1830 - accuracy: 0.9263 - val_loss: 0.1893 - val_accuracy: 0.9252 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1821 - accuracy: 0.9266 - val_loss: 0.1779 - val_accuracy: 0.9284 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1815 - accuracy: 0.9270 - val_loss: 0.1790 - val_accuracy: 0.9290 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1805 - accuracy: 0.9271 - val_loss: 0.1785 - val_accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1830 - accuracy: 0.9269 - val_loss: 0.1775 - val_accuracy: 0.9300 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1787 - accuracy: 0.9279 - val_loss: 0.1780 - val_accuracy: 0.9288 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1782 - accuracy: 0.9281 - val_loss: 0.1755 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1769 - accuracy: 0.9287 - val_loss: 0.1729 - val_accuracy: 0.9314 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1759 - accuracy: 0.9290 - val_loss: 0.1727 - val_accuracy: 0.9321 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1752 - accuracy: 0.9296 - val_loss: 0.2182 - val_accuracy: 0.9028 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1736 - accuracy: 0.9301 - val_loss: 0.1701 - val_accuracy: 0.9332 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1730 - accuracy: 0.9304 - val_loss: 0.1692 - val_accuracy: 0.9348 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1717 - accuracy: 0.9311 - val_loss: 0.1661 - val_accuracy: 0.9379 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1707 - accuracy: 0.9317 - val_loss: 0.1663 - val_accuracy: 0.9355 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1693 - accuracy: 0.9323 - val_loss: 0.1700 - val_accuracy: 0.9314 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1681 - accuracy: 0.9329 - val_loss: 0.1628 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1669 - accuracy: 0.9333 - val_loss: 0.1598 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1652 - accuracy: 0.9342 - val_loss: 0.1646 - val_accuracy: 0.9354 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1651 - accuracy: 0.9339 - val_loss: 0.1712 - val_accuracy: 0.9306 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1636 - accuracy: 0.9347 - val_loss: 0.1577 - val_accuracy: 0.9386 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1623 - accuracy: 0.9355 - val_loss: 0.1593 - val_accuracy: 0.9350 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1606 - accuracy: 0.9361 - val_loss: 0.1547 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1603 - accuracy: 0.9363 - val_loss: 0.1528 - val_accuracy: 0.9426 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1589 - accuracy: 0.9371 - val_loss: 0.1601 - val_accuracy: 0.9362 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1583 - accuracy: 0.9374 - val_loss: 0.1527 - val_accuracy: 0.9406 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1577 - accuracy: 0.9376 - val_loss: 0.1788 - val_accuracy: 0.9310 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1571 - accuracy: 0.9379 - val_loss: 0.1621 - val_accuracy: 0.9306 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1551 - accuracy: 0.9383 - val_loss: 0.1539 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1549 - accuracy: 0.9386 - val_loss: 0.1473 - val_accuracy: 0.9408 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1527 - accuracy: 0.9397 - val_loss: 0.1447 - val_accuracy: 0.9433 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1530 - accuracy: 0.9397 - val_loss: 0.1462 - val_accuracy: 0.9440 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1523 - accuracy: 0.9399 - val_loss: 0.1512 - val_accuracy: 0.9416 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1509 - accuracy: 0.9406 - val_loss: 0.1420 - val_accuracy: 0.9450 - lr: 0.0010\n",
      "loss: 0.1420079332427593\n",
      "accuracy: 0.94497526\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.945   \u001b[0m | \u001b[95m 2.617   \u001b[0m | \u001b[95m 42.5    \u001b[0m | \u001b[95m 0.06852 \u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.4228 - accuracy: 0.8452 - val_loss: 0.2954 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2885 - accuracy: 0.8845 - val_loss: 0.2744 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2663 - accuracy: 0.8951 - val_loss: 0.2442 - val_accuracy: 0.9008 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2372 - accuracy: 0.9088 - val_loss: 0.2106 - val_accuracy: 0.9222 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2223 - accuracy: 0.9167 - val_loss: 0.2066 - val_accuracy: 0.9205 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2080 - accuracy: 0.9204 - val_loss: 0.1991 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1985 - accuracy: 0.9230 - val_loss: 0.1929 - val_accuracy: 0.9248 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1919 - accuracy: 0.9242 - val_loss: 0.1874 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1946 - accuracy: 0.9239 - val_loss: 0.1881 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1996 - accuracy: 0.9224 - val_loss: 0.2081 - val_accuracy: 0.9236 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1908 - accuracy: 0.9249 - val_loss: 0.1861 - val_accuracy: 0.9263 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1862 - accuracy: 0.9256 - val_loss: 0.1869 - val_accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1851 - accuracy: 0.9258 - val_loss: 0.1858 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1924 - accuracy: 0.9248 - val_loss: 0.1841 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1842 - accuracy: 0.9261 - val_loss: 0.1827 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1831 - accuracy: 0.9263 - val_loss: 0.1805 - val_accuracy: 0.9282 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1826 - accuracy: 0.9263 - val_loss: 0.1811 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1968 - accuracy: 0.9242 - val_loss: 0.1907 - val_accuracy: 0.9254 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1827 - accuracy: 0.9264 - val_loss: 0.1792 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1811 - accuracy: 0.9268 - val_loss: 0.1780 - val_accuracy: 0.9277 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1799 - accuracy: 0.9272 - val_loss: 0.1937 - val_accuracy: 0.9152 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1793 - accuracy: 0.9275 - val_loss: 0.1774 - val_accuracy: 0.9306 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1786 - accuracy: 0.9280 - val_loss: 0.1769 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1780 - accuracy: 0.9281 - val_loss: 0.1763 - val_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1771 - accuracy: 0.9285 - val_loss: 0.1757 - val_accuracy: 0.9318 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1817 - accuracy: 0.9278 - val_loss: 0.1767 - val_accuracy: 0.9308 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1761 - accuracy: 0.9292 - val_loss: 0.1783 - val_accuracy: 0.9331 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1744 - accuracy: 0.9298 - val_loss: 0.1696 - val_accuracy: 0.9339 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1737 - accuracy: 0.9298 - val_loss: 0.1737 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1725 - accuracy: 0.9306 - val_loss: 0.1765 - val_accuracy: 0.9271 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1716 - accuracy: 0.9313 - val_loss: 0.1778 - val_accuracy: 0.9232 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1712 - accuracy: 0.9311 - val_loss: 0.1687 - val_accuracy: 0.9351 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1701 - accuracy: 0.9315 - val_loss: 0.1734 - val_accuracy: 0.9323 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1685 - accuracy: 0.9322 - val_loss: 0.1641 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1674 - accuracy: 0.9326 - val_loss: 0.1878 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1668 - accuracy: 0.9331 - val_loss: 0.1646 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1658 - accuracy: 0.9334 - val_loss: 0.1600 - val_accuracy: 0.9396 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1640 - accuracy: 0.9340 - val_loss: 0.1589 - val_accuracy: 0.9397 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1636 - accuracy: 0.9343 - val_loss: 0.1566 - val_accuracy: 0.9411 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1620 - accuracy: 0.9350 - val_loss: 0.1796 - val_accuracy: 0.9205 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1612 - accuracy: 0.9351 - val_loss: 0.1613 - val_accuracy: 0.9356 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1600 - accuracy: 0.9358 - val_loss: 0.1528 - val_accuracy: 0.9388 - lr: 0.0010\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1592 - accuracy: 0.9361 - val_loss: 0.1545 - val_accuracy: 0.9432 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1582 - accuracy: 0.9363 - val_loss: 0.1514 - val_accuracy: 0.9421 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1572 - accuracy: 0.9367 - val_loss: 0.1563 - val_accuracy: 0.9377 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1566 - accuracy: 0.9376 - val_loss: 0.1532 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1549 - accuracy: 0.9377 - val_loss: 0.1495 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1547 - accuracy: 0.9379 - val_loss: 0.1507 - val_accuracy: 0.9434 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1540 - accuracy: 0.9383 - val_loss: 0.1892 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1525 - accuracy: 0.9388 - val_loss: 0.1973 - val_accuracy: 0.9117 - lr: 0.0010\n",
      "loss: 0.19733254885155915\n",
      "accuracy: 0.9116976\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9117  \u001b[0m | \u001b[0m 1.614   \u001b[0m | \u001b[0m 87.93   \u001b[0m | \u001b[0m 0.00274 \u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "533504/536269 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.4291 - accuracy: 0.8412 - val_loss: 0.3103 - val_accuracy: 0.8780 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2928 - accuracy: 0.8831 - val_loss: 0.2727 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2671 - accuracy: 0.8953 - val_loss: 0.2418 - val_accuracy: 0.9129 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2375 - accuracy: 0.9091 - val_loss: 0.2888 - val_accuracy: 0.8495 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2135 - accuracy: 0.9187 - val_loss: 0.2006 - val_accuracy: 0.9221 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1983 - accuracy: 0.9233 - val_loss: 0.2007 - val_accuracy: 0.9147 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2271 - accuracy: 0.9160 - val_loss: 0.1991 - val_accuracy: 0.9222 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1959 - accuracy: 0.9239 - val_loss: 0.1933 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1979 - accuracy: 0.9235 - val_loss: 0.1915 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1913 - accuracy: 0.9247 - val_loss: 0.1898 - val_accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1884 - accuracy: 0.9254 - val_loss: 0.1873 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2026 - accuracy: 0.9234 - val_loss: 0.1880 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1874 - accuracy: 0.9255 - val_loss: 0.1896 - val_accuracy: 0.9254 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1994 - accuracy: 0.9235 - val_loss: 0.2070 - val_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1905 - accuracy: 0.9251 - val_loss: 0.1901 - val_accuracy: 0.9248 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1858 - accuracy: 0.9258 - val_loss: 0.1827 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1878 - accuracy: 0.9256 - val_loss: 0.1839 - val_accuracy: 0.9271 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1837 - accuracy: 0.9263 - val_loss: 0.1862 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1956 - accuracy: 0.9254 - val_loss: 0.1860 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1833 - accuracy: 0.9266 - val_loss: 0.1809 - val_accuracy: 0.9274 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1819 - accuracy: 0.9270 - val_loss: 0.1831 - val_accuracy: 0.9264 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1811 - accuracy: 0.9270 - val_loss: 0.1805 - val_accuracy: 0.9279 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1807 - accuracy: 0.9272 - val_loss: 0.1784 - val_accuracy: 0.9280 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1802 - accuracy: 0.9273 - val_loss: 0.1783 - val_accuracy: 0.9291 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1915 - accuracy: 0.9264 - val_loss: 0.1799 - val_accuracy: 0.9290 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1797 - accuracy: 0.9280 - val_loss: 0.1766 - val_accuracy: 0.9288 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1780 - accuracy: 0.9285 - val_loss: 0.1755 - val_accuracy: 0.9302 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1777 - accuracy: 0.9284 - val_loss: 0.1772 - val_accuracy: 0.9287 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1769 - accuracy: 0.9287 - val_loss: 0.1747 - val_accuracy: 0.9312 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1755 - accuracy: 0.9295 - val_loss: 0.1749 - val_accuracy: 0.9315 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1754 - accuracy: 0.9296 - val_loss: 0.1719 - val_accuracy: 0.9312 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1740 - accuracy: 0.9302 - val_loss: 0.1786 - val_accuracy: 0.9261 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1733 - accuracy: 0.9304 - val_loss: 0.1761 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1724 - accuracy: 0.9305 - val_loss: 0.1763 - val_accuracy: 0.9327 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1716 - accuracy: 0.9312 - val_loss: 0.1752 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1710 - accuracy: 0.9313 - val_loss: 0.1661 - val_accuracy: 0.9336 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1689 - accuracy: 0.9326 - val_loss: 0.1761 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1689 - accuracy: 0.9326 - val_loss: 0.1734 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1682 - accuracy: 0.9326 - val_loss: 0.1684 - val_accuracy: 0.9317 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1667 - accuracy: 0.9336 - val_loss: 0.1599 - val_accuracy: 0.9388 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1656 - accuracy: 0.9340 - val_loss: 0.1621 - val_accuracy: 0.9398 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1647 - accuracy: 0.9342 - val_loss: 0.1672 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1634 - accuracy: 0.9349 - val_loss: 0.1610 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1631 - accuracy: 0.9346 - val_loss: 0.1605 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1621 - accuracy: 0.9351 - val_loss: 0.1616 - val_accuracy: 0.9318 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1611 - accuracy: 0.9359 - val_loss: 0.1544 - val_accuracy: 0.9387 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.1606 - accuracy: 0.9360 - val_loss: 0.1583 - val_accuracy: 0.9361 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1583 - accuracy: 0.9369 - val_loss: 0.1540 - val_accuracy: 0.9368 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1591 - accuracy: 0.9367 - val_loss: 0.1629 - val_accuracy: 0.9375 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1586 - accuracy: 0.9369 - val_loss: 0.1598 - val_accuracy: 0.9390 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1598135893814263\n",
      "accuracy: 0.939049\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.939   \u001b[0m | \u001b[0m 2.451   \u001b[0m | \u001b[0m 42.38   \u001b[0m | \u001b[0m 0.06578 \u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "533504/536269 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.8439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.4279 - accuracy: 0.8440 - val_loss: 0.3141 - val_accuracy: 0.8778 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2919 - accuracy: 0.8841 - val_loss: 0.3006 - val_accuracy: 0.8798 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2685 - accuracy: 0.8944 - val_loss: 0.2467 - val_accuracy: 0.9109 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2402 - accuracy: 0.9083 - val_loss: 0.2151 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2142 - accuracy: 0.9183 - val_loss: 0.2036 - val_accuracy: 0.9224 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2068 - accuracy: 0.9208 - val_loss: 0.1967 - val_accuracy: 0.9230 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2181 - accuracy: 0.9194 - val_loss: 0.2334 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2160 - accuracy: 0.9187 - val_loss: 0.2046 - val_accuracy: 0.9245 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1947 - accuracy: 0.9241 - val_loss: 0.1906 - val_accuracy: 0.9257 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1921 - accuracy: 0.9245 - val_loss: 0.1908 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2031 - accuracy: 0.9223 - val_loss: 0.1934 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1897 - accuracy: 0.9252 - val_loss: 0.1892 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1863 - accuracy: 0.9256 - val_loss: 0.1861 - val_accuracy: 0.9263 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1979 - accuracy: 0.9237 - val_loss: 0.2294 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1934 - accuracy: 0.9246 - val_loss: 0.1897 - val_accuracy: 0.9254 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1847 - accuracy: 0.9265 - val_loss: 0.1838 - val_accuracy: 0.9265 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1832 - accuracy: 0.9265 - val_loss: 0.1826 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1822 - accuracy: 0.9267 - val_loss: 0.1822 - val_accuracy: 0.9273 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1815 - accuracy: 0.9268 - val_loss: 0.1823 - val_accuracy: 0.9274 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1998 - accuracy: 0.9245 - val_loss: 0.1779 - val_accuracy: 0.9298 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1804 - accuracy: 0.9276 - val_loss: 0.1862 - val_accuracy: 0.9243 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1792 - accuracy: 0.9276 - val_loss: 0.1759 - val_accuracy: 0.9304 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1780 - accuracy: 0.9284 - val_loss: 0.1796 - val_accuracy: 0.9279 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1905 - accuracy: 0.9267 - val_loss: 0.2091 - val_accuracy: 0.9230 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1817 - accuracy: 0.9282 - val_loss: 0.1761 - val_accuracy: 0.9320 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1764 - accuracy: 0.9290 - val_loss: 0.1772 - val_accuracy: 0.9316 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1747 - accuracy: 0.9298 - val_loss: 0.1755 - val_accuracy: 0.9292 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1740 - accuracy: 0.9301 - val_loss: 0.1733 - val_accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1724 - accuracy: 0.9310 - val_loss: 0.1674 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1714 - accuracy: 0.9311 - val_loss: 0.1888 - val_accuracy: 0.9081 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1704 - accuracy: 0.9316 - val_loss: 0.1714 - val_accuracy: 0.9324 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1693 - accuracy: 0.9321 - val_loss: 0.1664 - val_accuracy: 0.9321 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1677 - accuracy: 0.9332 - val_loss: 0.1629 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1669 - accuracy: 0.9334 - val_loss: 0.1716 - val_accuracy: 0.9314 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1657 - accuracy: 0.9339 - val_loss: 0.1659 - val_accuracy: 0.9350 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1644 - accuracy: 0.9346 - val_loss: 0.1608 - val_accuracy: 0.9401 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1632 - accuracy: 0.9349 - val_loss: 0.1635 - val_accuracy: 0.9323 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1615 - accuracy: 0.9355 - val_loss: 0.1597 - val_accuracy: 0.9379 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1611 - accuracy: 0.9359 - val_loss: 0.1749 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1597 - accuracy: 0.9363 - val_loss: 0.1542 - val_accuracy: 0.9388 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1590 - accuracy: 0.9370 - val_loss: 0.1712 - val_accuracy: 0.9280 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1563 - accuracy: 0.9379 - val_loss: 0.1493 - val_accuracy: 0.9425 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1564 - accuracy: 0.9381 - val_loss: 0.1483 - val_accuracy: 0.9410 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1552 - accuracy: 0.9380 - val_loss: 0.1476 - val_accuracy: 0.9450 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1553 - accuracy: 0.9383 - val_loss: 0.1470 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1532 - accuracy: 0.9392 - val_loss: 0.1884 - val_accuracy: 0.9204 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1541 - accuracy: 0.9387 - val_loss: 0.1755 - val_accuracy: 0.9285 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1512 - accuracy: 0.9400 - val_loss: 0.1572 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1516 - accuracy: 0.9399 - val_loss: 0.1442 - val_accuracy: 0.9439 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1508 - accuracy: 0.9395 - val_loss: 0.1464 - val_accuracy: 0.9389 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14643203827394718\n",
      "accuracy: 0.93889236\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9389  \u001b[0m | \u001b[0m 3.232   \u001b[0m | \u001b[0m 42.95   \u001b[0m | \u001b[0m 0.07655 \u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "533504/536269 [============================>.] - ETA: 0s - loss: 0.4206 - accuracy: 0.8457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - 9s 17us/sample - loss: 0.4201 - accuracy: 0.8459 - val_loss: 0.3345 - val_accuracy: 0.8658 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2883 - accuracy: 0.8862 - val_loss: 0.2697 - val_accuracy: 0.9002 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.2614 - accuracy: 0.8988 - val_loss: 0.2589 - val_accuracy: 0.9065 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 8s 16us/sample - loss: 0.2330 - accuracy: 0.9115 - val_loss: 0.2254 - val_accuracy: 0.9216 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.2229 - accuracy: 0.9151 - val_loss: 0.2014 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.2058 - accuracy: 0.9213 - val_loss: 0.2107 - val_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 8s 14us/sample - loss: 0.2039 - accuracy: 0.9220 - val_loss: 0.2696 - val_accuracy: 0.8882 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.2158 - accuracy: 0.9180 - val_loss: 0.1973 - val_accuracy: 0.9239 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1931 - accuracy: 0.9244 - val_loss: 0.1904 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1922 - accuracy: 0.9245 - val_loss: 0.1906 - val_accuracy: 0.9244 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.2098 - accuracy: 0.9195 - val_loss: 0.2136 - val_accuracy: 0.9151 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1950 - accuracy: 0.9237 - val_loss: 0.1890 - val_accuracy: 0.9248 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1879 - accuracy: 0.9251 - val_loss: 0.1894 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1884 - accuracy: 0.9253 - val_loss: 0.1847 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.2045 - accuracy: 0.9222 - val_loss: 0.1879 - val_accuracy: 0.9258 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1856 - accuracy: 0.9262 - val_loss: 0.1819 - val_accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1834 - accuracy: 0.9265 - val_loss: 0.1848 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1825 - accuracy: 0.9266 - val_loss: 0.1975 - val_accuracy: 0.9189 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1890 - accuracy: 0.9263 - val_loss: 0.1791 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1804 - accuracy: 0.9273 - val_loss: 0.1827 - val_accuracy: 0.9314 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1795 - accuracy: 0.9276 - val_loss: 0.1762 - val_accuracy: 0.9285 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1788 - accuracy: 0.9280 - val_loss: 0.1744 - val_accuracy: 0.9294 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1775 - accuracy: 0.9285 - val_loss: 0.1750 - val_accuracy: 0.9306 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1893 - accuracy: 0.9271 - val_loss: 0.1846 - val_accuracy: 0.9309 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1781 - accuracy: 0.9289 - val_loss: 0.1802 - val_accuracy: 0.9291 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1758 - accuracy: 0.9293 - val_loss: 0.1824 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1737 - accuracy: 0.9303 - val_loss: 0.1967 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1727 - accuracy: 0.9305 - val_loss: 0.1701 - val_accuracy: 0.9308 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 7s 14us/sample - loss: 0.1715 - accuracy: 0.9311 - val_loss: 0.1678 - val_accuracy: 0.9312 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 7s 13us/sample - loss: 0.1709 - accuracy: 0.9315 - val_loss: 0.1692 - val_accuracy: 0.9301 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 6s 12us/sample - loss: 0.1698 - accuracy: 0.9320 - val_loss: 0.1676 - val_accuracy: 0.9316 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1686 - accuracy: 0.9326 - val_loss: 0.1635 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1674 - accuracy: 0.9332 - val_loss: 0.1657 - val_accuracy: 0.9374 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1667 - accuracy: 0.9333 - val_loss: 0.2286 - val_accuracy: 0.9216 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1656 - accuracy: 0.9339 - val_loss: 0.1597 - val_accuracy: 0.9380 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1646 - accuracy: 0.9342 - val_loss: 0.1921 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1640 - accuracy: 0.9347 - val_loss: 0.1602 - val_accuracy: 0.9334 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1620 - accuracy: 0.9357 - val_loss: 0.1584 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 6s 12us/sample - loss: 0.1613 - accuracy: 0.9359 - val_loss: 0.1613 - val_accuracy: 0.9380 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 6s 12us/sample - loss: 0.1606 - accuracy: 0.9360 - val_loss: 0.1689 - val_accuracy: 0.9301 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 6s 12us/sample - loss: 0.1587 - accuracy: 0.9370 - val_loss: 0.2070 - val_accuracy: 0.9194 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 6s 12us/sample - loss: 0.1589 - accuracy: 0.9368 - val_loss: 0.1510 - val_accuracy: 0.9404 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 6s 11us/sample - loss: 0.1573 - accuracy: 0.9375 - val_loss: 0.1514 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 6s 12us/sample - loss: 0.1567 - accuracy: 0.9381 - val_loss: 0.1517 - val_accuracy: 0.9408 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 8s 14us/sample - loss: 0.1555 - accuracy: 0.9384 - val_loss: 0.1493 - val_accuracy: 0.9420 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1551 - accuracy: 0.9385 - val_loss: 0.1563 - val_accuracy: 0.9342 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1544 - accuracy: 0.9391 - val_loss: 0.1522 - val_accuracy: 0.9376 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1526 - accuracy: 0.9394 - val_loss: 0.1545 - val_accuracy: 0.9388 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1523 - accuracy: 0.9395 - val_loss: 0.1484 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1528 - accuracy: 0.9394 - val_loss: 0.1416 - val_accuracy: 0.9445 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14157594304476998\n",
      "accuracy: 0.9444531\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9445  \u001b[0m | \u001b[0m 3.297   \u001b[0m | \u001b[0m 41.94   \u001b[0m | \u001b[0m 0.01859 \u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "536269/536269 [==============================] - ETA: 0s - loss: 0.4160 - accuracy: 0.8479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - 8s 14us/sample - loss: 0.4160 - accuracy: 0.8479 - val_loss: 0.2974 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 8s 14us/sample - loss: 0.2867 - accuracy: 0.8861 - val_loss: 0.2654 - val_accuracy: 0.8977 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.2543 - accuracy: 0.9021 - val_loss: 0.2403 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.2215 - accuracy: 0.9155 - val_loss: 0.2035 - val_accuracy: 0.9231 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.2263 - accuracy: 0.9144 - val_loss: 0.2121 - val_accuracy: 0.9179 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.2026 - accuracy: 0.9218 - val_loss: 0.1993 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.2084 - accuracy: 0.9207 - val_loss: 0.1932 - val_accuracy: 0.9246 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1943 - accuracy: 0.9238 - val_loss: 0.1913 - val_accuracy: 0.9241 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1896 - accuracy: 0.9247 - val_loss: 0.1890 - val_accuracy: 0.9253 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.2074 - accuracy: 0.9213 - val_loss: 0.2078 - val_accuracy: 0.9207 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1972 - accuracy: 0.9236 - val_loss: 0.1878 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1873 - accuracy: 0.9254 - val_loss: 0.1875 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 8s 15us/sample - loss: 0.1858 - accuracy: 0.9257 - val_loss: 0.1837 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 9s 16us/sample - loss: 0.1846 - accuracy: 0.9258 - val_loss: 0.1868 - val_accuracy: 0.9265 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 10s 18us/sample - loss: 0.1836 - accuracy: 0.9264 - val_loss: 0.1832 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 10s 18us/sample - loss: 0.1931 - accuracy: 0.9253 - val_loss: 0.1805 - val_accuracy: 0.9278 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 10s 19us/sample - loss: 0.1821 - accuracy: 0.9267 - val_loss: 0.1988 - val_accuracy: 0.9232 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 10s 19us/sample - loss: 0.1834 - accuracy: 0.9269 - val_loss: 0.1792 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 10s 19us/sample - loss: 0.1803 - accuracy: 0.9274 - val_loss: 0.1822 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 10s 19us/sample - loss: 0.1790 - accuracy: 0.9280 - val_loss: 0.1907 - val_accuracy: 0.9229 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 11s 20us/sample - loss: 0.1785 - accuracy: 0.9283 - val_loss: 0.1744 - val_accuracy: 0.9319 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 12s 22us/sample - loss: 0.1775 - accuracy: 0.9286 - val_loss: 0.1727 - val_accuracy: 0.9313 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 12s 22us/sample - loss: 0.1765 - accuracy: 0.9290 - val_loss: 0.1767 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 12s 23us/sample - loss: 0.1752 - accuracy: 0.9299 - val_loss: 0.1781 - val_accuracy: 0.9284 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 11s 21us/sample - loss: 0.1744 - accuracy: 0.9297 - val_loss: 0.1785 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 11s 21us/sample - loss: 0.1789 - accuracy: 0.9301 - val_loss: 0.1681 - val_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 12s 23us/sample - loss: 0.1715 - accuracy: 0.9317 - val_loss: 0.1673 - val_accuracy: 0.9338 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 12s 23us/sample - loss: 0.1704 - accuracy: 0.9318 - val_loss: 0.1675 - val_accuracy: 0.9329 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 12s 23us/sample - loss: 0.1696 - accuracy: 0.9322 - val_loss: 0.1666 - val_accuracy: 0.9324 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 14s 27us/sample - loss: 0.1682 - accuracy: 0.9330 - val_loss: 0.1618 - val_accuracy: 0.9372 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 14s 26us/sample - loss: 0.1667 - accuracy: 0.9340 - val_loss: 0.1672 - val_accuracy: 0.9309 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 14s 26us/sample - loss: 0.1659 - accuracy: 0.9340 - val_loss: 0.1668 - val_accuracy: 0.9325 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 14s 27us/sample - loss: 0.1643 - accuracy: 0.9348 - val_loss: 0.1585 - val_accuracy: 0.9386 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 14s 27us/sample - loss: 0.1636 - accuracy: 0.9348 - val_loss: 0.1591 - val_accuracy: 0.9410 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 15s 28us/sample - loss: 0.1620 - accuracy: 0.9358 - val_loss: 0.1559 - val_accuracy: 0.9426 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1609 - accuracy: 0.9362 - val_loss: 0.1535 - val_accuracy: 0.9434 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 17s 31us/sample - loss: 0.1593 - accuracy: 0.9367 - val_loss: 0.1653 - val_accuracy: 0.9356 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 16s 30us/sample - loss: 0.1587 - accuracy: 0.9371 - val_loss: 0.1946 - val_accuracy: 0.9280 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 17s 31us/sample - loss: 0.1583 - accuracy: 0.9376 - val_loss: 0.1575 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1562 - accuracy: 0.9381 - val_loss: 0.1540 - val_accuracy: 0.9432 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 19s 35us/sample - loss: 0.1554 - accuracy: 0.9383 - val_loss: 0.1517 - val_accuracy: 0.9436 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1526 - accuracy: 0.9394 - val_loss: 0.1481 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1546 - accuracy: 0.9389 - val_loss: 0.1819 - val_accuracy: 0.9272 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1527 - accuracy: 0.9393 - val_loss: 0.1499 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1501 - accuracy: 0.9405 - val_loss: 0.1426 - val_accuracy: 0.9435 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 19s 35us/sample - loss: 0.1511 - accuracy: 0.9404 - val_loss: 0.1688 - val_accuracy: 0.9327 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1505 - accuracy: 0.9406 - val_loss: 0.1445 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 18s 33us/sample - loss: 0.1485 - accuracy: 0.9412 - val_loss: 0.1446 - val_accuracy: 0.9450 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1480 - accuracy: 0.9414 - val_loss: 0.1415 - val_accuracy: 0.9452 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 15s 28us/sample - loss: 0.1483 - accuracy: 0.9407 - val_loss: 0.1437 - val_accuracy: 0.9401 - lr: 0.0010\n",
      "loss: 0.14374221804212958\n",
      "accuracy: 0.940102\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9401  \u001b[0m | \u001b[0m 1.683   \u001b[0m | \u001b[0m 16.4    \u001b[0m | \u001b[0m 0.09473 \u001b[0m |\n",
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/50\n",
      "536269/536269 [==============================] - ETA: 0s - loss: 0.4111 - accuracy: 0.8491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536269/536269 [==============================] - 20s 37us/sample - loss: 0.4111 - accuracy: 0.8491 - val_loss: 0.2948 - val_accuracy: 0.8823 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "536269/536269 [==============================] - 19s 35us/sample - loss: 0.2873 - accuracy: 0.8853 - val_loss: 0.2653 - val_accuracy: 0.8913 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.2641 - accuracy: 0.8966 - val_loss: 0.2681 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "536269/536269 [==============================] - 19s 35us/sample - loss: 0.2356 - accuracy: 0.9099 - val_loss: 0.2124 - val_accuracy: 0.9154 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "536269/536269 [==============================] - 16s 31us/sample - loss: 0.2143 - accuracy: 0.9182 - val_loss: 0.1984 - val_accuracy: 0.9232 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.2287 - accuracy: 0.9164 - val_loss: 0.2049 - val_accuracy: 0.9205 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.2015 - accuracy: 0.9227 - val_loss: 0.1948 - val_accuracy: 0.9243 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "536269/536269 [==============================] - 16s 30us/sample - loss: 0.1947 - accuracy: 0.9239 - val_loss: 0.1998 - val_accuracy: 0.9220 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.2197 - accuracy: 0.9169 - val_loss: 0.1971 - val_accuracy: 0.9248 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "536269/536269 [==============================] - 19s 35us/sample - loss: 0.1954 - accuracy: 0.9239 - val_loss: 0.1904 - val_accuracy: 0.9242 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "536269/536269 [==============================] - 18s 33us/sample - loss: 0.1986 - accuracy: 0.9238 - val_loss: 0.1924 - val_accuracy: 0.9236 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1891 - accuracy: 0.9250 - val_loss: 0.1875 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1875 - accuracy: 0.9254 - val_loss: 0.1923 - val_accuracy: 0.9250 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1981 - accuracy: 0.9242 - val_loss: 0.1861 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1866 - accuracy: 0.9257 - val_loss: 0.1879 - val_accuracy: 0.9248 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "536269/536269 [==============================] - 19s 35us/sample - loss: 0.1929 - accuracy: 0.9251 - val_loss: 0.1862 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1851 - accuracy: 0.9261 - val_loss: 0.1833 - val_accuracy: 0.9273 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1839 - accuracy: 0.9263 - val_loss: 0.1879 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1830 - accuracy: 0.9266 - val_loss: 0.1853 - val_accuracy: 0.9252 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1825 - accuracy: 0.9268 - val_loss: 0.1840 - val_accuracy: 0.9262 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1853 - accuracy: 0.9264 - val_loss: 0.1813 - val_accuracy: 0.9278 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1812 - accuracy: 0.9273 - val_loss: 0.1801 - val_accuracy: 0.9276 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1804 - accuracy: 0.9277 - val_loss: 0.1850 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "536269/536269 [==============================] - 16s 30us/sample - loss: 0.1796 - accuracy: 0.9278 - val_loss: 0.1788 - val_accuracy: 0.9292 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "536269/536269 [==============================] - 18s 33us/sample - loss: 0.1789 - accuracy: 0.9282 - val_loss: 0.1850 - val_accuracy: 0.9263 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "536269/536269 [==============================] - 18s 34us/sample - loss: 0.1780 - accuracy: 0.9284 - val_loss: 0.1756 - val_accuracy: 0.9290 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "536269/536269 [==============================] - 19s 35us/sample - loss: 0.1770 - accuracy: 0.9288 - val_loss: 0.1777 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "536269/536269 [==============================] - 17s 31us/sample - loss: 0.1764 - accuracy: 0.9293 - val_loss: 0.1993 - val_accuracy: 0.9225 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "536269/536269 [==============================] - 19s 35us/sample - loss: 0.1751 - accuracy: 0.9299 - val_loss: 0.1742 - val_accuracy: 0.9309 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1743 - accuracy: 0.9301 - val_loss: 0.1809 - val_accuracy: 0.9252 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1733 - accuracy: 0.9304 - val_loss: 0.1727 - val_accuracy: 0.9323 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1722 - accuracy: 0.9312 - val_loss: 0.1699 - val_accuracy: 0.9316 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "536269/536269 [==============================] - 14s 27us/sample - loss: 0.1808 - accuracy: 0.9305 - val_loss: 0.1726 - val_accuracy: 0.9284 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1709 - accuracy: 0.9317 - val_loss: 0.1725 - val_accuracy: 0.9290 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1689 - accuracy: 0.9326 - val_loss: 0.1648 - val_accuracy: 0.9345 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1682 - accuracy: 0.9326 - val_loss: 0.1671 - val_accuracy: 0.9369 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1678 - accuracy: 0.9330 - val_loss: 0.1834 - val_accuracy: 0.9244 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1660 - accuracy: 0.9338 - val_loss: 0.1622 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1649 - accuracy: 0.9344 - val_loss: 0.1695 - val_accuracy: 0.9308 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1646 - accuracy: 0.9344 - val_loss: 0.1805 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1632 - accuracy: 0.9351 - val_loss: 0.1558 - val_accuracy: 0.9383 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "536269/536269 [==============================] - 17s 31us/sample - loss: 0.1618 - accuracy: 0.9359 - val_loss: 0.1603 - val_accuracy: 0.9334 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1612 - accuracy: 0.9358 - val_loss: 0.1615 - val_accuracy: 0.9331 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1607 - accuracy: 0.9361 - val_loss: 0.1528 - val_accuracy: 0.9407 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1590 - accuracy: 0.9368 - val_loss: 0.1527 - val_accuracy: 0.9413 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "536269/536269 [==============================] - 16s 30us/sample - loss: 0.1575 - accuracy: 0.9374 - val_loss: 0.1527 - val_accuracy: 0.9380 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "536269/536269 [==============================] - 16s 31us/sample - loss: 0.1567 - accuracy: 0.9377 - val_loss: 0.1498 - val_accuracy: 0.9417 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "536269/536269 [==============================] - 17s 32us/sample - loss: 0.1577 - accuracy: 0.9375 - val_loss: 0.1480 - val_accuracy: 0.9413 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "536269/536269 [==============================] - 16s 30us/sample - loss: 0.1553 - accuracy: 0.9380 - val_loss: 0.1469 - val_accuracy: 0.9420 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "536269/536269 [==============================] - 16s 30us/sample - loss: 0.1541 - accuracy: 0.9388 - val_loss: 0.1505 - val_accuracy: 0.9435 - lr: 0.0010\n",
      "loss: 0.15046839901468317\n",
      "accuracy: 0.9435046\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9435  \u001b[0m | \u001b[0m 3.179   \u001b[0m | \u001b[0m 73.13   \u001b[0m | \u001b[0m 0.01947 \u001b[0m |\n",
      "=============================================================\n",
      "Training time: 4890.773204088211\n",
      "{'target': 0.9449752569198608, 'params': {'batch_size': 2.616989018744074, 'epochs': 42.50025692592619, 'learning_rate': 0.06852226482017555}}\n"
     ]
    }
   ],
   "source": [
    "# Bayesian optimization to choose the best hyperparameters\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f = training,\n",
    "    pbounds = pbounds,\n",
    "    verbose = 2, \n",
    "    random_state = 1,\n",
    ")\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 5)\n",
    "\n",
    "train_end = time.time()\n",
    "train_time = train_end - train_start\n",
    "print(\"Training time:\", train_time)\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad037209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 536269 samples, validate on 114912 samples\n",
      "Epoch 1/42\n",
      "536269/536269 [==============================] - 68s 127us/sample - loss: 0.2679 - accuracy: 0.8951 - val_loss: 0.2097 - val_accuracy: 0.9157 - lr: 0.0010\n",
      "Epoch 2/42\n",
      "536269/536269 [==============================] - 65s 121us/sample - loss: 0.1998 - accuracy: 0.9214 - val_loss: 0.2339 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 3/42\n",
      "536269/536269 [==============================] - 66s 123us/sample - loss: 0.1950 - accuracy: 0.9226 - val_loss: 0.1907 - val_accuracy: 0.9244 - lr: 0.0010\n",
      "Epoch 4/42\n",
      "536269/536269 [==============================] - 73s 136us/sample - loss: 0.1925 - accuracy: 0.9232 - val_loss: 0.1888 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 5/42\n",
      "536269/536269 [==============================] - 74s 139us/sample - loss: 0.1907 - accuracy: 0.9235 - val_loss: 0.1933 - val_accuracy: 0.9231 - lr: 0.0010\n",
      "Epoch 6/42\n",
      "536269/536269 [==============================] - 68s 127us/sample - loss: 0.1892 - accuracy: 0.9241 - val_loss: 0.2004 - val_accuracy: 0.9209 - lr: 0.0010\n",
      "Epoch 7/42\n",
      "536269/536269 [==============================] - 70s 131us/sample - loss: 0.1882 - accuracy: 0.9242 - val_loss: 0.1859 - val_accuracy: 0.9242 - lr: 0.0010\n",
      "Epoch 8/42\n",
      "536269/536269 [==============================] - 63s 118us/sample - loss: 0.1870 - accuracy: 0.9247 - val_loss: 0.1855 - val_accuracy: 0.9244 - lr: 0.0010\n",
      "Epoch 9/42\n",
      "536269/536269 [==============================] - 62s 116us/sample - loss: 0.1859 - accuracy: 0.9249 - val_loss: 0.1828 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 10/42\n",
      "536269/536269 [==============================] - 65s 121us/sample - loss: 0.1850 - accuracy: 0.9249 - val_loss: 0.1861 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 11/42\n",
      "536269/536269 [==============================] - 63s 118us/sample - loss: 0.1840 - accuracy: 0.9254 - val_loss: 0.1830 - val_accuracy: 0.9258 - lr: 0.0010\n",
      "Epoch 12/42\n",
      "536269/536269 [==============================] - 63s 118us/sample - loss: 0.1831 - accuracy: 0.9258 - val_loss: 0.1853 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 13/42\n",
      "536269/536269 [==============================] - 61s 114us/sample - loss: 0.1823 - accuracy: 0.9259 - val_loss: 0.1775 - val_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 14/42\n",
      "536269/536269 [==============================] - 65s 121us/sample - loss: 0.1813 - accuracy: 0.9263 - val_loss: 0.1803 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 15/42\n",
      "536269/536269 [==============================] - 63s 118us/sample - loss: 0.1794 - accuracy: 0.9271 - val_loss: 0.1759 - val_accuracy: 0.9284 - lr: 0.0010\n",
      "Epoch 16/42\n",
      "536269/536269 [==============================] - 64s 119us/sample - loss: 0.1758 - accuracy: 0.9286 - val_loss: 0.1817 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 17/42\n",
      "536269/536269 [==============================] - 65s 121us/sample - loss: 0.1691 - accuracy: 0.9318 - val_loss: 0.1573 - val_accuracy: 0.9378 - lr: 0.0010\n",
      "Epoch 18/42\n",
      "536269/536269 [==============================] - 63s 117us/sample - loss: 0.1618 - accuracy: 0.9350 - val_loss: 0.1809 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 19/42\n",
      "536269/536269 [==============================] - 63s 117us/sample - loss: 0.1557 - accuracy: 0.9376 - val_loss: 0.2493 - val_accuracy: 0.9190 - lr: 0.0010\n",
      "Epoch 20/42\n",
      "536269/536269 [==============================] - 63s 118us/sample - loss: 0.1534 - accuracy: 0.9387 - val_loss: 0.1748 - val_accuracy: 0.9287 - lr: 0.0010\n",
      "Epoch 21/42\n",
      "536269/536269 [==============================] - 65s 121us/sample - loss: 0.1493 - accuracy: 0.9400 - val_loss: 0.2258 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Epoch 22/42\n",
      "536269/536269 [==============================] - 60s 112us/sample - loss: 0.1481 - accuracy: 0.9406 - val_loss: 0.1814 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 23/42\n",
      "536269/536269 [==============================] - 65s 120us/sample - loss: 0.1473 - accuracy: 0.9411 - val_loss: 0.1442 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 24/42\n",
      "536269/536269 [==============================] - 58s 108us/sample - loss: 0.1456 - accuracy: 0.9417 - val_loss: 0.1443 - val_accuracy: 0.9433 - lr: 0.0010\n",
      "Epoch 25/42\n",
      "536269/536269 [==============================] - 56s 105us/sample - loss: 0.1440 - accuracy: 0.9423 - val_loss: 0.1472 - val_accuracy: 0.9405 - lr: 0.0010\n",
      "Epoch 26/42\n",
      "536269/536269 [==============================] - 57s 106us/sample - loss: 0.1441 - accuracy: 0.9425 - val_loss: 0.1564 - val_accuracy: 0.9360 - lr: 0.0010\n",
      "Epoch 27/42\n",
      "536269/536269 [==============================] - 57s 107us/sample - loss: 0.1420 - accuracy: 0.9432 - val_loss: 0.1399 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 28/42\n",
      "536269/536269 [==============================] - 58s 108us/sample - loss: 0.1408 - accuracy: 0.9435 - val_loss: 0.1604 - val_accuracy: 0.9328 - lr: 0.0010\n",
      "Epoch 29/42\n",
      "536269/536269 [==============================] - 55s 103us/sample - loss: 0.1404 - accuracy: 0.9438 - val_loss: 0.1333 - val_accuracy: 0.9478 - lr: 0.0010\n",
      "Epoch 30/42\n",
      "536269/536269 [==============================] - 57s 105us/sample - loss: 0.1388 - accuracy: 0.9443 - val_loss: 0.1535 - val_accuracy: 0.9367 - lr: 0.0010\n",
      "Epoch 31/42\n",
      "536269/536269 [==============================] - 56s 105us/sample - loss: 0.1387 - accuracy: 0.9444 - val_loss: 0.2872 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Epoch 32/42\n",
      "536269/536269 [==============================] - 58s 108us/sample - loss: 0.1385 - accuracy: 0.9444 - val_loss: 0.1763 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 33/42\n",
      "536269/536269 [==============================] - 56s 105us/sample - loss: 0.1372 - accuracy: 0.9449 - val_loss: 0.1348 - val_accuracy: 0.9477 - lr: 0.0010\n",
      "Epoch 34/42\n",
      "536269/536269 [==============================] - 57s 106us/sample - loss: 0.1362 - accuracy: 0.9453 - val_loss: 0.1340 - val_accuracy: 0.9476 - lr: 0.0010\n",
      "Epoch 35/42\n",
      "536269/536269 [==============================] - 56s 104us/sample - loss: 0.1353 - accuracy: 0.9455 - val_loss: 0.1867 - val_accuracy: 0.9301 - lr: 0.0010\n",
      "Epoch 36/42\n",
      "536269/536269 [==============================] - 58s 108us/sample - loss: 0.1361 - accuracy: 0.9455 - val_loss: 0.1355 - val_accuracy: 0.9445 - lr: 0.0010\n",
      "Epoch 37/42\n",
      "536269/536269 [==============================] - 54s 101us/sample - loss: 0.1355 - accuracy: 0.9458 - val_loss: 0.1359 - val_accuracy: 0.9474 - lr: 0.0010\n",
      "Epoch 38/42\n",
      "536269/536269 [==============================] - 57s 107us/sample - loss: 0.1345 - accuracy: 0.9460 - val_loss: 0.1741 - val_accuracy: 0.9295 - lr: 0.0010\n",
      "Epoch 39/42\n",
      "536269/536269 [==============================] - 58s 109us/sample - loss: 0.1347 - accuracy: 0.9459 - val_loss: 0.1355 - val_accuracy: 0.9477 - lr: 0.0010\n",
      "Epoch 40/42\n",
      "536269/536269 [==============================] - 58s 108us/sample - loss: 0.1166 - accuracy: 0.9530 - val_loss: 0.1182 - val_accuracy: 0.9535 - lr: 1.0000e-04\n",
      "Epoch 41/42\n",
      "536269/536269 [==============================] - 56s 104us/sample - loss: 0.1142 - accuracy: 0.9538 - val_loss: 0.1176 - val_accuracy: 0.9542 - lr: 1.0000e-04\n",
      "Epoch 42/42\n",
      "536269/536269 [==============================] - 56s 104us/sample - loss: 0.1133 - accuracy: 0.9539 - val_loss: 0.1178 - val_accuracy: 0.9540 - lr: 1.0000e-04\n",
      "Training time: 2578.701924800873\n"
     ]
    }
   ],
   "source": [
    "# Training step with the best hyperparameters\n",
    "\n",
    "nadam = optimizers.Nadam(learning_rate = optimizer.max['params']['learning_rate'], beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, schedule_decay = 0.004)\n",
    "\n",
    "model = CNN()\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"nadam\", metrics = [\"accuracy\"])\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "history = model.fit(X_train_CNN, Y_train_CNN, \n",
    "                    epochs = int(optimizer.max['params']['epochs']), \n",
    "                    batch_size = int(32 * optimizer.max['params']['batch_size']), \n",
    "                    validation_data = (X_val_CNN, Y_val_CNN),\n",
    "                    callbacks = [reduce_lr])\n",
    "\n",
    "train_end = time.time()\n",
    "train_time = train_end - train_start\n",
    "print(\"Training time:\", train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc56ac36",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7028c826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.7/site-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time: 13.101388931274414\n"
     ]
    }
   ],
   "source": [
    "# Testing step\n",
    "\n",
    "test_start = time.time()\n",
    "\n",
    "Y_pred = model.predict(X_test_CNN)\n",
    "\n",
    "test_end = time.time()\n",
    "test_time = test_end - test_start\n",
    "print(\"Testing time:\", test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e15bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_CNN = np.argmax(Y_pred, axis = 1)\n",
    "Y_true_CNN = Y_test_CNN.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c1efe",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf0b59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Mirai_Ack','Mirai_Scan','Mirai_Syn','Mirai_Udp','Mirai_Udpplain',\n",
    "          'Bashlite_Combo','Bashlite_Junk','Bashlite_Scan','Bashlite_Udp', 'Bashlite_Tcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13eecafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi classification metrics\n",
    "\n",
    "acc = accuracy_score(Y_true_CNN, Y_pred_CNN) \n",
    "f1 = f1_score(Y_true_CNN, Y_pred_CNN, average = 'weighted')\n",
    "pre = precision_score(Y_true_CNN, Y_pred_CNN, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall = recall_score(Y_true_CNN, Y_pred_CNN, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56caa768",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = open(\"../Results/P737_camera_cnn.txt\", \"a\")\n",
    "\n",
    "print(\" ==== Test \" + str(number_features) + \" features \" + str(learning_rate) + \"====\")\n",
    "print(\"Training time:\" + str(train_time))\n",
    "print(\"Testing time:\" + str(test_time))\n",
    "print(\"Accuracy:\" + str(acc))\n",
    "print(\"F1-score:\" + str(f1))\n",
    "print(\"Precision:\" + str(pre))\n",
    "print(\"Recall:\" + str(recall))\n",
    "print(\"Hyper-parameters:\" + str(optimizer.max))\n",
    "print(classification_report(Y_true_CNN,Y_pred_CNN, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3e5da",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf44eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train\n",
    "train_nb_start = time.time()\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "train_nb_end = time.time()\n",
    "train_nb_time = train_nb_end - train_nb_start\n",
    "\n",
    "# Test\n",
    "test_nb_start = time.time()\n",
    "\n",
    "Y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "test_nb_end = time.time()\n",
    "test_nb_time = test_nb_end - test_nb_start\n",
    "\n",
    "# Metrics\n",
    "acc_nb = accuracy_score(Y_test, Y_pred_nb) \n",
    "f1_nb = f1_score(Y_test, Y_pred_nb, average = 'weighted')\n",
    "pre_nb = precision_score(Y_test, Y_pred_nb, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall_nb = recall_score(Y_test, Y_pred_nb, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)\n",
    "\n",
    "print()\n",
    "print(\" ==== Naive Bayes \" + str(number_features) + \" features ====\")\n",
    "print(\"Training time:\" + str(train_nb_time))\n",
    "print(\"Testing time:\" + str(test_nb_time))\n",
    "print(\"Accuracy:\" + str(acc_nb))\n",
    "print(\"F1-score:\" + str(f1_nb))\n",
    "print(\"Precision:\" + str(pre_nb))\n",
    "print(\"Recall:\" + str(recall_nb))\n",
    "print(classification_report(Y_test, Y_pred_nb, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71b29f",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4ed84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "knn = KNeighborsClassifier(n_neighbors = 50)\n",
    "\n",
    "# Train\n",
    "train_knn_start = time.time()\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "train_knn_end = time.time()\n",
    "train_knn_time = train_knn_end - train_knn_start\n",
    "\n",
    "# Test\n",
    "test_knn_start = time.time()\n",
    "\n",
    "Y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "test_knn_end = time.time()\n",
    "test_knn_time = test_knn_end - test_knn_start\n",
    "\n",
    "# Metrics\n",
    "acc_knn = accuracy_score(Y_test, Y_pred_knn) \n",
    "f1_knn = f1_score(Y_test, Y_pred_knn, average = 'weighted')\n",
    "pre_knn = precision_score(Y_test, Y_pred_knn, labels = None, pos_label = 1, average = 'weighted')\n",
    "recall_knn = recall_score(Y_test, Y_pred_knn, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)\n",
    "\n",
    "print()\n",
    "print(\" ==== KNN \" + str(number_features) + \" features ====\")\n",
    "print(\"Training time:\" + str(train_knn_time))\n",
    "print(\"Testing time:\" + str(test_knn_time))\n",
    "print(\"Accuracy:\" + str(acc_knn))\n",
    "print(\"F1-score:\" + str(f1_knn))\n",
    "print(\"Precision:\" + str(pre_knn))\n",
    "print(\"Recall:\" + str(recall_knn))\n",
    "print(classification_report(Y_test, Y_pred_knn, target_names = labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
