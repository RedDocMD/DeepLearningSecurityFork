{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aad9456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.8/site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/andressa.amaral/.local/lib/python3.8/site-packages (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from seaborn) (1.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (65.5.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (22.10.26)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (14.0.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.23.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.50.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.27.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (4.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorflow-gpu) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.14.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: import-ipynb in /home/andressa.amaral/.local/lib/python3.8/site-packages (0.1.4)\n",
      "Requirement already satisfied: nbformat in /home/andressa.amaral/.local/lib/python3.8/site-packages (from import-ipynb) (5.7.0)\n",
      "Requirement already satisfied: IPython in /home/andressa.amaral/.local/lib/python3.8/site-packages (from import-ipynb) (8.6.0)\n",
      "Requirement already satisfied: backcall in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (2.13.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (5.5.0)\n",
      "Requirement already satisfied: pickleshare in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.7.5)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from IPython->import-ipynb) (4.1.2)\n",
      "Requirement already satisfied: stack-data in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.6.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (3.0.32)\n",
      "Requirement already satisfied: matplotlib-inline in /home/andressa.amaral/.local/lib/python3.8/site-packages (from IPython->import-ipynb) (0.1.6)\n",
      "Requirement already satisfied: jupyter-core in /home/andressa.amaral/.local/lib/python3.8/site-packages (from nbformat->import-ipynb) (5.0.0)\n",
      "Requirement already satisfied: fastjsonschema in /home/andressa.amaral/.local/lib/python3.8/site-packages (from nbformat->import-ipynb) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from nbformat->import-ipynb) (4.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/andressa.amaral/.local/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>3.0.1->IPython->import-ipynb) (0.2.5)\n",
      "Requirement already satisfied: platformdirs in /home/andressa.amaral/.local/lib/python3.8/site-packages (from jupyter-core->nbformat->import-ipynb) (2.5.4)\n",
      "Requirement already satisfied: pure-eval in /home/andressa.amaral/.local/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (2.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from stack-data->IPython->import-ipynb) (1.2.0)\n",
      "Requirement already satisfied: six in /home/andressa.amaral/.local/lib/python3.8/site-packages (from asttokens>=2.1.0->stack-data->IPython->import-ipynb) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/andressa.amaral/.local/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.10.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cuda-python in /home/andressa.amaral/.local/lib/python3.8/site-packages (11.8.1)\n",
      "Requirement already satisfied: cython in /home/andressa.amaral/.local/lib/python3.8/site-packages (from cuda-python) (0.29.32)\n",
      "importing Jupyter notebook from AttackDetectionModel.ipynb\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install seaborn\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "!pip3 install import-ipynb\n",
    "!pip3 install cuda-python\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import import_ipynb\n",
    "import AttackDetectionModel\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3358dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.333)\n",
    "sess = tf.compat.v1.Session(config = tf.compat.v1.ConfigProto(gpu_options = gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04791b",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ff3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_features = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392f5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign, df_attack = AttackDetectionModel.get_files_botiot(\"../../botiot\")\n",
    "\n",
    "df_benign = np.concatenate([df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, \n",
    "                            df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, \n",
    "                            df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, \n",
    "                            df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign,\n",
    "                            df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign, df_benign])\n",
    "df_benign = shuffle(df_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb0bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize with the min-max scaler\n",
    "scaler = MinMaxScaler()\n",
    "df_benign_norm = scaler.fit_transform(df_benign)\n",
    "df_attack_norm = scaler.fit_transform(df_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f03749",
   "metadata": {},
   "source": [
    "# Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3237bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "len_benign_train = int(0.7 * len(df_benign_norm))\n",
    "X_train = df_benign_norm[:len_benign_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26ae71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test_benign = df_benign_norm[len_benign_train:]\n",
    "X_test = np.concatenate([X_test_benign, df_attack_norm])\n",
    "\n",
    "Y_test = np.ones(len(X_test))\n",
    "Y_test[:len(X_test_benign)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ee87d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a8a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "original_dim = X_train.shape[1]\n",
    "input_shape = (original_dim,)\n",
    "intermediate_dim = int(original_dim / 2)\n",
    "latent_dim = int(original_dim / 3)\n",
    "\n",
    "# Initial values\n",
    "epochs = 5\n",
    "learning_rate = 0.0001\n",
    "batch_size = 10\n",
    "anomaly_threshold = 0.05\n",
    "\n",
    "# Dictionary\n",
    "dict_params = { 'learning_rate': learning_rate, 'batch_size': round(batch_size), 'epochs': round(epochs)}\n",
    "pbounds = { 'learning_rate': (0.000001, 0.001), 'batch_size': (10, 100), 'epochs': (50, 1000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c66ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL Loss function\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    # Compute the average MSE error, then scale it up (sum on all axes)\n",
    "    \n",
    "    reconstruction_loss = K.sum(K.square(x - x_decoded_mean))\n",
    "    \n",
    "    # Compute the KL loss\n",
    "    \n",
    "    kl_loss = - 0.5 * K.sum(1 + z_var - K.square(z_mean) - K.square(K.exp(z_var)), axis=-1)\n",
    "    \n",
    "    # Return the average loss over all \n",
    "    \n",
    "    total_loss = K.mean(reconstruction_loss + kl_loss) # Total_loss = reconstruction_loss + kl_loss \n",
    "    return total_loss\n",
    "\n",
    "# (1) Reconstruction Loss - Forces the encoder to generate latent features that minimize the reconstruction error, or else is\n",
    "# penalized\n",
    "# (2) KL Loss - Forces the distribution generated by the encoder to be similar to the prior probability of the input vector, \n",
    "# pushing latent feature space to normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72309d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 35)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 17)           612         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 11)           198         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_var (Dense)                  (None, 11)           198         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 11)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_var[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,008\n",
      "Trainable params: 1,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "inputs, encoder, z_var, z_mean = AttackDetectionModel.vae_encoder(input_shape, \n",
    "                                                                  intermediate_dim, \n",
    "                                                                  latent_dim, \n",
    "                                                                  AttackDetectionModel.reparametrization)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cf7f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 11)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                204       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 35)                630       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 834\n",
      "Trainable params: 834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "decoder = AttackDetectionModel.vae_decoder(intermediate_dim, latent_dim, original_dim)\n",
    "outputs = decoder(encoder(inputs))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5dee9",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee3147d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_training(X_train = X_train, \n",
    "                      X_test = X_test, \n",
    "                      Y_test = Y_test, \n",
    "                      inputs = inputs, \n",
    "                      outputs = outputs, \n",
    "                      vae_loss = vae_loss,\n",
    "                      learning_rate = learning_rate,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = epochs,\n",
    "                      anomaly_threshold = anomaly_threshold):    \n",
    "    \n",
    "    # Create model\n",
    "    opt_adam = optimizers.Adam(learning_rate = dict_params['learning_rate'], clipvalue = 0.5)\n",
    "    model = Model(inputs, outputs, name = 'vae_mlp')\n",
    "    model.compile(optimizer = opt_adam, loss = vae_loss)\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(X_train, \n",
    "                        X_train, \n",
    "                        shuffle = True, \n",
    "                        verbose = 0,\n",
    "                        epochs = dict_params['epochs'], \n",
    "                        batch_size = dict_params['batch_size'])\n",
    "    \n",
    "    # Maximize the f1-score\n",
    "    X_pred_opt = model.predict(X_test)\n",
    "    error_vector_opt = AttackDetectionModel.get_error_term(X_pred_opt, X_test, _rmse = False)\n",
    "    Y_pred_opt = (error_vector_opt > anomaly_threshold)\n",
    "    f1 = f1_score(Y_test, Y_pred_opt)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63435bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Apply Bayesian optimization to choose the best hyperparameters\\n\\nopt = BayesianOptimization(f = maximize_training,\\n                           pbounds = pbounds,\\n                           verbose = 2, \\n                           random_state = 1)\\n\\nopt_start = time.time()\\n\\nopt.maximize(init_points = 5, n_iter = 5)\\n\\nopt_end = time.time()\\nopt_time = opt_end - opt_start\\nprint(\"Optimization time:\", opt_time)\\n\\nlearning_rate = opt.max[\\'params\\'][\\'learning_rate\\']\\nepochs = round(opt.max[\\'params\\'][\\'epochs\\'])\\nbatch_size = round(opt.max[\\'params\\'][\\'batch_size\\'])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Apply Bayesian optimization to choose the best hyperparameters\n",
    "\n",
    "opt = BayesianOptimization(f = maximize_training,\n",
    "                           pbounds = pbounds,\n",
    "                           verbose = 2, \n",
    "                           random_state = 1)\n",
    "\n",
    "opt_start = time.time()\n",
    "\n",
    "opt.maximize(init_points = 5, n_iter = 5)\n",
    "\n",
    "opt_end = time.time()\n",
    "opt_time = opt_end - opt_start\n",
    "print(\"Optimization time:\", opt_time)\n",
    "\n",
    "learning_rate = opt.max['params']['learning_rate']\n",
    "epochs = round(opt.max['params']['epochs'])\n",
    "batch_size = round(opt.max['params']['batch_size'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82a597",
   "metadata": {},
   "source": [
    "# Predict Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "703c2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step with the best hyperparameters\n",
    "learning_rate = 0.0005007978127917845\n",
    "epochs = 550\n",
    "batch_size = 19\n",
    "opt_time = 1151.2620151042938\n",
    "anomaly_threshold = 0.043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d064a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Train on 15025 samples\n",
      "Epoch 1/550\n",
      "15025/15025 [==============================] - 2s 108us/sample - loss: 40.4601\n",
      "Epoch 2/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 13.9272\n",
      "Epoch 3/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 11.8458\n",
      "Epoch 4/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 10.9079\n",
      "Epoch 5/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 10.2121\n",
      "Epoch 6/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 9.7020\n",
      "Epoch 7/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 9.2272\n",
      "Epoch 8/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 8.8683\n",
      "Epoch 9/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 8.6321\n",
      "Epoch 10/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 8.4310\n",
      "Epoch 11/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 8.2323\n",
      "Epoch 12/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 8.0238\n",
      "Epoch 13/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 7.8345\n",
      "Epoch 14/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 7.6344\n",
      "Epoch 15/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 7.5011\n",
      "Epoch 16/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 7.4058\n",
      "Epoch 17/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 7.2552\n",
      "Epoch 18/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 7.1566\n",
      "Epoch 19/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 7.0396\n",
      "Epoch 20/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 7.0121\n",
      "Epoch 21/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.8686\n",
      "Epoch 22/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 6.8066\n",
      "Epoch 23/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 6.7708\n",
      "Epoch 24/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 6.7351\n",
      "Epoch 25/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.6492\n",
      "Epoch 26/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 6.6311\n",
      "Epoch 27/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 6.5398\n",
      "Epoch 28/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.5041\n",
      "Epoch 29/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 6.4798\n",
      "Epoch 30/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.5076\n",
      "Epoch 31/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 6.4152\n",
      "Epoch 32/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.3989\n",
      "Epoch 33/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.3897\n",
      "Epoch 34/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 6.3450\n",
      "Epoch 35/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 6.3076\n",
      "Epoch 36/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 6.2830\n",
      "Epoch 37/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 6.2485\n",
      "Epoch 38/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.2377\n",
      "Epoch 39/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.2558\n",
      "Epoch 40/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.1986\n",
      "Epoch 41/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 6.2029\n",
      "Epoch 42/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.1522\n",
      "Epoch 43/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 6.1604\n",
      "Epoch 44/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.1158\n",
      "Epoch 45/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 6.0962\n",
      "Epoch 46/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 6.0977\n",
      "Epoch 47/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.0817\n",
      "Epoch 48/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 6.0585\n",
      "Epoch 49/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 6.0436\n",
      "Epoch 50/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 6.0227\n",
      "Epoch 51/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 6.0199\n",
      "Epoch 52/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 6.0097\n",
      "Epoch 53/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.9631\n",
      "Epoch 54/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 5.9530\n",
      "Epoch 55/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.9573\n",
      "Epoch 56/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 5.9647\n",
      "Epoch 57/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.9454\n",
      "Epoch 58/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.9231\n",
      "Epoch 59/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.8932\n",
      "Epoch 60/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 5.8702\n",
      "Epoch 61/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 5.9088\n",
      "Epoch 62/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 5.9026\n",
      "Epoch 63/550\n",
      "15025/15025 [==============================] - 1s 84us/sample - loss: 5.8441\n",
      "Epoch 64/550\n",
      "15025/15025 [==============================] - 1s 85us/sample - loss: 5.8620\n",
      "Epoch 65/550\n",
      "15025/15025 [==============================] - 1s 86us/sample - loss: 5.8565\n",
      "Epoch 66/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 5.8391\n",
      "Epoch 67/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 5.8135\n",
      "Epoch 68/550\n",
      "15025/15025 [==============================] - 1s 83us/sample - loss: 5.7950\n",
      "Epoch 69/550\n",
      "15025/15025 [==============================] - 1s 83us/sample - loss: 5.8207\n",
      "Epoch 70/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 5.7892\n",
      "Epoch 71/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.8359\n",
      "Epoch 72/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.8055\n",
      "Epoch 73/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7901\n",
      "Epoch 74/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7856\n",
      "Epoch 75/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7956\n",
      "Epoch 76/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7960\n",
      "Epoch 77/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 5.7988\n",
      "Epoch 78/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 5.7873\n",
      "Epoch 79/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7543\n",
      "Epoch 80/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7531\n",
      "Epoch 81/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 5.7559\n",
      "Epoch 82/550\n",
      "15025/15025 [==============================] - 1s 83us/sample - loss: 5.7476\n",
      "Epoch 83/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7342\n",
      "Epoch 84/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7510\n",
      "Epoch 85/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.7617\n",
      "Epoch 86/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7179\n",
      "Epoch 87/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.7476\n",
      "Epoch 88/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7394\n",
      "Epoch 89/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.7312\n",
      "Epoch 90/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7249\n",
      "Epoch 91/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7271\n",
      "Epoch 92/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.7163\n",
      "Epoch 93/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7330\n",
      "Epoch 94/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7200\n",
      "Epoch 95/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7258\n",
      "Epoch 96/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7194\n",
      "Epoch 97/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7499\n",
      "Epoch 98/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7018\n",
      "Epoch 99/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 5.7326\n",
      "Epoch 100/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7236\n",
      "Epoch 101/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.7051\n",
      "Epoch 102/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7335\n",
      "Epoch 103/550\n",
      "15025/15025 [==============================] - 1s 81us/sample - loss: 5.7228\n",
      "Epoch 104/550\n",
      "15025/15025 [==============================] - 1s 86us/sample - loss: 5.7195\n",
      "Epoch 105/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7374\n",
      "Epoch 106/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7227\n",
      "Epoch 107/550\n",
      "15025/15025 [==============================] - 2s 104us/sample - loss: 5.7004\n",
      "Epoch 108/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.6949\n",
      "Epoch 109/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.7440\n",
      "Epoch 110/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7387\n",
      "Epoch 111/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.7027\n",
      "Epoch 112/550\n",
      "15025/15025 [==============================] - 1s 83us/sample - loss: 5.7009\n",
      "Epoch 113/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.7053\n",
      "Epoch 114/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7104\n",
      "Epoch 115/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7151\n",
      "Epoch 116/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 5.6878\n",
      "Epoch 117/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.6602\n",
      "Epoch 118/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 5.7050\n",
      "Epoch 119/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.7138\n",
      "Epoch 120/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 5.7012\n",
      "Epoch 121/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 5.7033\n",
      "Epoch 122/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7214\n",
      "Epoch 123/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.6927\n",
      "Epoch 124/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 5.7570\n",
      "Epoch 125/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 5.7004\n",
      "Epoch 126/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7085\n",
      "Epoch 127/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7038\n",
      "Epoch 128/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.7157\n",
      "Epoch 129/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.7284\n",
      "Epoch 130/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.6971\n",
      "Epoch 131/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7535\n",
      "Epoch 132/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 5.7065\n",
      "Epoch 133/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 5.7347\n",
      "Epoch 134/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 5.7609\n",
      "Epoch 135/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7562\n",
      "Epoch 136/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.7875\n",
      "Epoch 137/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.7459\n",
      "Epoch 138/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.7568\n",
      "Epoch 139/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.7470\n",
      "Epoch 140/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.7956\n",
      "Epoch 141/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7602\n",
      "Epoch 142/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.7621\n",
      "Epoch 143/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.8082\n",
      "Epoch 144/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.7879\n",
      "Epoch 145/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.8039\n",
      "Epoch 146/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 5.8155\n",
      "Epoch 147/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 5.7950\n",
      "Epoch 148/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 5.8061\n",
      "Epoch 149/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 5.8366\n",
      "Epoch 150/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.7937\n",
      "Epoch 151/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.8658\n",
      "Epoch 152/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 5.8038\n",
      "Epoch 153/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 5.8419\n",
      "Epoch 154/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.8470\n",
      "Epoch 155/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.8258\n",
      "Epoch 156/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.7955\n",
      "Epoch 157/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 5.7806\n",
      "Epoch 158/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 5.7987\n",
      "Epoch 159/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 5.8073\n",
      "Epoch 160/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 5.8243\n",
      "Epoch 161/550\n",
      "15025/15025 [==============================] - 1s 79us/sample - loss: 5.8168\n",
      "Epoch 162/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 5.8135\n",
      "Epoch 163/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 5.7805\n",
      "Epoch 164/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.8154\n",
      "Epoch 165/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.8360\n",
      "Epoch 166/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 5.7603\n",
      "Epoch 167/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.8143\n",
      "Epoch 168/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.8242\n",
      "Epoch 169/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.7786\n",
      "Epoch 170/550\n",
      "15025/15025 [==============================] - 1s 82us/sample - loss: 5.8550\n",
      "Epoch 171/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.8499\n",
      "Epoch 172/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.8283\n",
      "Epoch 173/550\n",
      "15025/15025 [==============================] - 1s 80us/sample - loss: 5.8374\n",
      "Epoch 174/550\n",
      "15025/15025 [==============================] - 1s 85us/sample - loss: 5.8223\n",
      "Epoch 175/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.8032\n",
      "Epoch 176/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.8268\n",
      "Epoch 177/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.8757\n",
      "Epoch 178/550\n",
      "15025/15025 [==============================] - 1s 78us/sample - loss: 5.8300\n",
      "Epoch 179/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.8664\n",
      "Epoch 180/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.8426\n",
      "Epoch 181/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.8496\n",
      "Epoch 182/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 5.8376\n",
      "Epoch 183/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.8746\n",
      "Epoch 184/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.8387\n",
      "Epoch 185/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 5.8746\n",
      "Epoch 186/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.8424\n",
      "Epoch 187/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 5.8676\n",
      "Epoch 188/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.8531\n",
      "Epoch 189/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.8633\n",
      "Epoch 190/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.8888\n",
      "Epoch 191/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.8841\n",
      "Epoch 192/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.8970\n",
      "Epoch 193/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 5.9426\n",
      "Epoch 194/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.9106\n",
      "Epoch 195/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 5.8920\n",
      "Epoch 196/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 5.9451\n",
      "Epoch 197/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.8560\n",
      "Epoch 198/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 5.9002\n",
      "Epoch 199/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.9912\n",
      "Epoch 200/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 6.0414\n",
      "Epoch 201/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.0256\n",
      "Epoch 202/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 5.9744\n",
      "Epoch 203/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 6.0077\n",
      "Epoch 204/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.0024\n",
      "Epoch 205/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 6.0136\n",
      "Epoch 206/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.0587\n",
      "Epoch 207/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 6.0352\n",
      "Epoch 208/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 6.0992\n",
      "Epoch 209/550\n",
      "15025/15025 [==============================] - 1s 77us/sample - loss: 6.1287\n",
      "Epoch 210/550\n",
      "15025/15025 [==============================] - 1s 76us/sample - loss: 6.1007\n",
      "Epoch 211/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.1381\n",
      "Epoch 212/550\n",
      "15025/15025 [==============================] - 2s 119us/sample - loss: 6.1323\n",
      "Epoch 213/550\n",
      "15025/15025 [==============================] - 2s 140us/sample - loss: 6.1432\n",
      "Epoch 214/550\n",
      "15025/15025 [==============================] - 1s 88us/sample - loss: 6.0947\n",
      "Epoch 215/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.0917\n",
      "Epoch 216/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.0899\n",
      "Epoch 217/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.1095\n",
      "Epoch 218/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.1023\n",
      "Epoch 219/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.1366\n",
      "Epoch 220/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.1694\n",
      "Epoch 221/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.2063\n",
      "Epoch 222/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.2635\n",
      "Epoch 223/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3114\n",
      "Epoch 224/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3236\n",
      "Epoch 225/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.2814\n",
      "Epoch 226/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.2698\n",
      "Epoch 227/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3078\n",
      "Epoch 228/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.2791\n",
      "Epoch 229/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.2626\n",
      "Epoch 230/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.2749\n",
      "Epoch 231/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.2855\n",
      "Epoch 232/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.2907\n",
      "Epoch 233/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3256\n",
      "Epoch 234/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.2991\n",
      "Epoch 235/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3548\n",
      "Epoch 236/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3467\n",
      "Epoch 237/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3202\n",
      "Epoch 238/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.2739\n",
      "Epoch 239/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3521\n",
      "Epoch 240/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3259\n",
      "Epoch 241/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 6.2870\n",
      "Epoch 242/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.4195\n",
      "Epoch 243/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3258\n",
      "Epoch 244/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3214\n",
      "Epoch 245/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3435\n",
      "Epoch 246/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.2848\n",
      "Epoch 247/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.2943\n",
      "Epoch 248/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3213\n",
      "Epoch 249/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3323\n",
      "Epoch 250/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3469\n",
      "Epoch 251/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3747\n",
      "Epoch 252/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.3668\n",
      "Epoch 253/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.4249\n",
      "Epoch 254/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3256\n",
      "Epoch 255/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.3644\n",
      "Epoch 256/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3956\n",
      "Epoch 257/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3843\n",
      "Epoch 258/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3340\n",
      "Epoch 259/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3661\n",
      "Epoch 260/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3605\n",
      "Epoch 261/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3817\n",
      "Epoch 262/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.4519\n",
      "Epoch 263/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.4436\n",
      "Epoch 264/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3860\n",
      "Epoch 265/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.4140\n",
      "Epoch 266/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3351\n",
      "Epoch 267/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3837\n",
      "Epoch 268/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3394\n",
      "Epoch 269/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3779\n",
      "Epoch 270/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3243\n",
      "Epoch 271/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3307\n",
      "Epoch 272/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3398\n",
      "Epoch 273/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 6.3427\n",
      "Epoch 274/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3353\n",
      "Epoch 275/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4159\n",
      "Epoch 276/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3465\n",
      "Epoch 277/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.4037\n",
      "Epoch 278/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3685\n",
      "Epoch 279/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3969\n",
      "Epoch 280/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3490\n",
      "Epoch 281/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3773\n",
      "Epoch 282/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.4221\n",
      "Epoch 283/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3826\n",
      "Epoch 284/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3611\n",
      "Epoch 285/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3778\n",
      "Epoch 286/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.4037\n",
      "Epoch 287/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3772\n",
      "Epoch 288/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4127\n",
      "Epoch 289/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.4293\n",
      "Epoch 290/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.4233\n",
      "Epoch 291/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4025\n",
      "Epoch 292/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3616\n",
      "Epoch 293/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4700\n",
      "Epoch 294/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3988\n",
      "Epoch 295/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3620\n",
      "Epoch 296/550\n",
      "15025/15025 [==============================] - 1s 63us/sample - loss: 6.3908\n",
      "Epoch 297/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3558\n",
      "Epoch 298/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4132\n",
      "Epoch 299/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.4102\n",
      "Epoch 300/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3986\n",
      "Epoch 301/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3940\n",
      "Epoch 302/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3503\n",
      "Epoch 303/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3977\n",
      "Epoch 304/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3549\n",
      "Epoch 305/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3744\n",
      "Epoch 306/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3278\n",
      "Epoch 307/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3700\n",
      "Epoch 308/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3911\n",
      "Epoch 309/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3479\n",
      "Epoch 310/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.3568\n",
      "Epoch 311/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3612\n",
      "Epoch 312/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3683\n",
      "Epoch 313/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.3445\n",
      "Epoch 314/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3474\n",
      "Epoch 315/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3592\n",
      "Epoch 316/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3631\n",
      "Epoch 317/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3688\n",
      "Epoch 318/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3491\n",
      "Epoch 319/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3389\n",
      "Epoch 320/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3690\n",
      "Epoch 321/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.4007\n",
      "Epoch 322/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3573\n",
      "Epoch 323/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3878\n",
      "Epoch 324/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3626\n",
      "Epoch 325/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3374\n",
      "Epoch 326/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3176\n",
      "Epoch 327/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3843\n",
      "Epoch 328/550\n",
      "15025/15025 [==============================] - 1s 60us/sample - loss: 6.3051\n",
      "Epoch 329/550\n",
      "15025/15025 [==============================] - 1s 58us/sample - loss: 6.3185\n",
      "Epoch 330/550\n",
      "15025/15025 [==============================] - 1s 61us/sample - loss: 6.2732\n",
      "Epoch 331/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.3519\n",
      "Epoch 332/550\n",
      "15025/15025 [==============================] - 1s 62us/sample - loss: 6.3112\n",
      "Epoch 333/550\n",
      "15025/15025 [==============================] - 1s 60us/sample - loss: 6.2969\n",
      "Epoch 334/550\n",
      "15025/15025 [==============================] - 1s 61us/sample - loss: 6.3992\n",
      "Epoch 335/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.3281\n",
      "Epoch 336/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3534\n",
      "Epoch 337/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3714\n",
      "Epoch 338/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3598\n",
      "Epoch 339/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3531\n",
      "Epoch 340/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.3927\n",
      "Epoch 341/550\n",
      "15025/15025 [==============================] - 1s 63us/sample - loss: 6.4126\n",
      "Epoch 342/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4009\n",
      "Epoch 343/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.4546\n",
      "Epoch 344/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.4072\n",
      "Epoch 345/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.4588\n",
      "Epoch 346/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.4782\n",
      "Epoch 347/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.4574\n",
      "Epoch 348/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.4589\n",
      "Epoch 349/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.5047\n",
      "Epoch 350/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5241\n",
      "Epoch 351/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.5675\n",
      "Epoch 352/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.5372\n",
      "Epoch 353/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.5701\n",
      "Epoch 354/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 6.5236\n",
      "Epoch 355/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.5578\n",
      "Epoch 356/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5163\n",
      "Epoch 357/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.5825\n",
      "Epoch 358/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.6726\n",
      "Epoch 359/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.5616\n",
      "Epoch 360/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.6020\n",
      "Epoch 361/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.5301\n",
      "Epoch 362/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.5774\n",
      "Epoch 363/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.5197\n",
      "Epoch 364/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.5140\n",
      "Epoch 365/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.4939\n",
      "Epoch 366/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.5278\n",
      "Epoch 367/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.5149\n",
      "Epoch 368/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5450\n",
      "Epoch 369/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.5480\n",
      "Epoch 370/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.6285\n",
      "Epoch 371/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.6142\n",
      "Epoch 372/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.5983\n",
      "Epoch 373/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5788\n",
      "Epoch 374/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.6239\n",
      "Epoch 375/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.6608\n",
      "Epoch 376/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.7124\n",
      "Epoch 377/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.7584\n",
      "Epoch 378/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.7681\n",
      "Epoch 379/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.7981\n",
      "Epoch 380/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.7536\n",
      "Epoch 381/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.7888\n",
      "Epoch 382/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.7878\n",
      "Epoch 383/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.8207\n",
      "Epoch 384/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.9336\n",
      "Epoch 385/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.9577\n",
      "Epoch 386/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.9400\n",
      "Epoch 387/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.7737\n",
      "Epoch 388/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.7859\n",
      "Epoch 389/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.7363\n",
      "Epoch 390/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.8122\n",
      "Epoch 391/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.6658\n",
      "Epoch 392/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.7157\n",
      "Epoch 393/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.6715\n",
      "Epoch 394/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.6790\n",
      "Epoch 395/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.5927\n",
      "Epoch 396/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.5675\n",
      "Epoch 397/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.5316\n",
      "Epoch 398/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.4771\n",
      "Epoch 399/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4686\n",
      "Epoch 400/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5021\n",
      "Epoch 401/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.4623\n",
      "Epoch 402/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4525\n",
      "Epoch 403/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.4132\n",
      "Epoch 404/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.4150\n",
      "Epoch 405/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.4561\n",
      "Epoch 406/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.4414\n",
      "Epoch 407/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.4441\n",
      "Epoch 408/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.4497\n",
      "Epoch 409/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.4666\n",
      "Epoch 410/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3864\n",
      "Epoch 411/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3818\n",
      "Epoch 412/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3835\n",
      "Epoch 413/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3695\n",
      "Epoch 414/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.3177\n",
      "Epoch 415/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3716\n",
      "Epoch 416/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3611\n",
      "Epoch 417/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3527\n",
      "Epoch 418/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.4050\n",
      "Epoch 419/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3165\n",
      "Epoch 420/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3692\n",
      "Epoch 421/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.4467\n",
      "Epoch 422/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3523\n",
      "Epoch 423/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3748\n",
      "Epoch 424/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3972\n",
      "Epoch 425/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3199\n",
      "Epoch 426/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3432\n",
      "Epoch 427/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3280\n",
      "Epoch 428/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.3878\n",
      "Epoch 429/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.4185\n",
      "Epoch 430/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3409\n",
      "Epoch 431/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3365\n",
      "Epoch 432/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3236\n",
      "Epoch 433/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3373\n",
      "Epoch 434/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3342\n",
      "Epoch 435/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.3233\n",
      "Epoch 436/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3355\n",
      "Epoch 437/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.2945\n",
      "Epoch 438/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.3012\n",
      "Epoch 439/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3029\n",
      "Epoch 440/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.2877\n",
      "Epoch 441/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3593\n",
      "Epoch 442/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3260\n",
      "Epoch 443/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3981\n",
      "Epoch 444/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.2889\n",
      "Epoch 445/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3380\n",
      "Epoch 446/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3161\n",
      "Epoch 447/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3563\n",
      "Epoch 448/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.3100\n",
      "Epoch 449/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.3522\n",
      "Epoch 450/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3142\n",
      "Epoch 451/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.2741\n",
      "Epoch 452/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3265\n",
      "Epoch 453/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3182\n",
      "Epoch 454/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.2965\n",
      "Epoch 455/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3418\n",
      "Epoch 456/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3867\n",
      "Epoch 457/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.3097\n",
      "Epoch 458/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.3252\n",
      "Epoch 459/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.4039\n",
      "Epoch 460/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3570\n",
      "Epoch 461/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.3988\n",
      "Epoch 462/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3632\n",
      "Epoch 463/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.3751\n",
      "Epoch 464/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3979\n",
      "Epoch 465/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3414\n",
      "Epoch 466/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4014\n",
      "Epoch 467/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.3537\n",
      "Epoch 468/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.4060\n",
      "Epoch 469/550\n",
      "15025/15025 [==============================] - 1s 74us/sample - loss: 6.4405\n",
      "Epoch 470/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.3715\n",
      "Epoch 471/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.4907\n",
      "Epoch 472/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.4679\n",
      "Epoch 473/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.4511\n",
      "Epoch 474/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.5262\n",
      "Epoch 475/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.4751\n",
      "Epoch 476/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.4646\n",
      "Epoch 477/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.4896\n",
      "Epoch 478/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5468\n",
      "Epoch 479/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.5180\n",
      "Epoch 480/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5139\n",
      "Epoch 481/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.5333\n",
      "Epoch 482/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5823\n",
      "Epoch 483/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.5461\n",
      "Epoch 484/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.5402\n",
      "Epoch 485/550\n",
      "15025/15025 [==============================] - 1s 73us/sample - loss: 6.6089\n",
      "Epoch 486/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.6336\n",
      "Epoch 487/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.5472\n",
      "Epoch 488/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.6137\n",
      "Epoch 489/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.6179\n",
      "Epoch 490/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.5511\n",
      "Epoch 491/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.5710\n",
      "Epoch 492/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.6555\n",
      "Epoch 493/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.7909\n",
      "Epoch 494/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.6510\n",
      "Epoch 495/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.7528\n",
      "Epoch 496/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.7414\n",
      "Epoch 497/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.7258\n",
      "Epoch 498/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.7195\n",
      "Epoch 499/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.7767\n",
      "Epoch 500/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.7095\n",
      "Epoch 501/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.6979\n",
      "Epoch 502/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 6.7339\n",
      "Epoch 503/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 6.8082\n",
      "Epoch 504/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.7859\n",
      "Epoch 505/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.7730\n",
      "Epoch 506/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.7896\n",
      "Epoch 507/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.9213\n",
      "Epoch 508/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.7800\n",
      "Epoch 509/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.8463\n",
      "Epoch 510/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 6.8982\n",
      "Epoch 511/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.9070\n",
      "Epoch 512/550\n",
      "15025/15025 [==============================] - 1s 63us/sample - loss: 7.0230\n",
      "Epoch 513/550\n",
      "15025/15025 [==============================] - 1s 62us/sample - loss: 6.8798\n",
      "Epoch 514/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.9508\n",
      "Epoch 515/550\n",
      "15025/15025 [==============================] - 1s 62us/sample - loss: 6.9270\n",
      "Epoch 516/550\n",
      "15025/15025 [==============================] - 1s 60us/sample - loss: 6.9345\n",
      "Epoch 517/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.9256\n",
      "Epoch 518/550\n",
      "15025/15025 [==============================] - 1s 62us/sample - loss: 6.9206\n",
      "Epoch 519/550\n",
      "15025/15025 [==============================] - 1s 61us/sample - loss: 6.9101\n",
      "Epoch 520/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.9098\n",
      "Epoch 521/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.8434\n",
      "Epoch 522/550\n",
      "15025/15025 [==============================] - 1s 64us/sample - loss: 6.7955\n",
      "Epoch 523/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.9228\n",
      "Epoch 524/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 6.9696\n",
      "Epoch 525/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.9547\n",
      "Epoch 526/550\n",
      "15025/15025 [==============================] - 1s 66us/sample - loss: 6.9937\n",
      "Epoch 527/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.9347\n",
      "Epoch 528/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.9879\n",
      "Epoch 529/550\n",
      "15025/15025 [==============================] - 1s 65us/sample - loss: 7.0908\n",
      "Epoch 530/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 7.0515\n",
      "Epoch 531/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 6.9225\n",
      "Epoch 532/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 6.9485\n",
      "Epoch 533/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 7.0145\n",
      "Epoch 534/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 6.9815\n",
      "Epoch 535/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 7.0573\n",
      "Epoch 536/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 7.0640\n",
      "Epoch 537/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 7.0054\n",
      "Epoch 538/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 7.0591\n",
      "Epoch 539/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 7.0924\n",
      "Epoch 540/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 7.1196\n",
      "Epoch 541/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15025/15025 [==============================] - 1s 71us/sample - loss: 7.0530\n",
      "Epoch 542/550\n",
      "15025/15025 [==============================] - 1s 72us/sample - loss: 7.0305\n",
      "Epoch 543/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 7.0458\n",
      "Epoch 544/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 7.0106\n",
      "Epoch 545/550\n",
      "15025/15025 [==============================] - 1s 69us/sample - loss: 7.0042\n",
      "Epoch 546/550\n",
      "15025/15025 [==============================] - 1s 70us/sample - loss: 7.0839\n",
      "Epoch 547/550\n",
      "15025/15025 [==============================] - 1s 75us/sample - loss: 7.0824\n",
      "Epoch 548/550\n",
      "15025/15025 [==============================] - 1s 71us/sample - loss: 7.0176\n",
      "Epoch 549/550\n",
      "15025/15025 [==============================] - 1s 68us/sample - loss: 7.1890\n",
      "Epoch 550/550\n",
      "15025/15025 [==============================] - 1s 67us/sample - loss: 7.1837\n",
      "Training time: 599.3318450450897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing time: 55.19785165786743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(\"Iteration \" + str(i))\n",
    "    \n",
    "    # Train\n",
    "    vae_model, train_time = AttackDetectionModel.train(X_train, inputs, outputs, vae_loss, learning_rate, epochs, batch_size)\n",
    "    \n",
    "    # Set the optimized anomaly threshold\n",
    "    #anomaly_threshold = AttackDetectionModel.get_anomaly_threshold(X_train, vae_model)\n",
    "    \n",
    "    # Test\n",
    "    X_pred, test_time = AttackDetectionModel.test(X_test, vae_model)\n",
    "    Y_test, Y_pred = AttackDetectionModel.get_prediction(Y_test, X_pred, X_test, anomaly_threshold, vae_model)\n",
    "    \n",
    "    # Metrics\n",
    "    acc, f1, pre, rec = AttackDetectionModel.get_scores(Y_test, Y_pred)\n",
    "    \n",
    "    # Print results\n",
    "    AttackDetectionModel.print_results(number_features,\n",
    "                                       learning_rate,\n",
    "                                       epochs,\n",
    "                                       batch_size,\n",
    "                                       anomaly_threshold,\n",
    "                                       X_train,\n",
    "                                       X_test,\n",
    "                                       opt_time,\n",
    "                                       train_time,\n",
    "                                       test_time,\n",
    "                                       acc,\n",
    "                                       f1,\n",
    "                                       pre,\n",
    "                                       rec,\n",
    "                                       Y_test,\n",
    "                                       Y_pred,\n",
    "                                       \"Results/botiot.txt\")\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84108b",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c5c3ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andressa.amaral/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "# Examinig the latent space generated by the encoder\n",
    "X_encoded = encoder.predict(X_test)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_analysis = pca.fit_transform(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4518c113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(x = X_analysis[:, 0], y = X_analysis[:, 1], s = 20, hue = Y_pred)\n",
    "plt.grid()\n",
    "plt.savefig(\"Results/PCA/Botiot\")\n",
    "plt.show()\n",
    "\n",
    "# Orange ones are anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "360d1451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "sns.scatterplot(x = X_analysis[:, 0], y = X_analysis[:, 1], s = 20, hue = Y_test)\n",
    "plt.grid()\n",
    "plt.savefig(\"Results/PCA Groundtruth/Botiot\")\n",
    "plt.show()\n",
    "\n",
    "# Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9b7783c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (5, 5))\n",
    "ax.matshow(conf_matrix, cmap = plt.cm.Blues, alpha = 0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x = j, y = i,s = conf_matrix[i, j], va = 'center', ha = 'center', size = 'large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=12)\n",
    "plt.ylabel('Actuals', fontsize=12)\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.savefig(\"Results/Confusion Matrix/Botiot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6750e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
