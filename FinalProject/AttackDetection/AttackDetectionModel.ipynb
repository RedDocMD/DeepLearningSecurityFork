{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a902b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.44.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (60.10.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (13.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.24.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: cached-property in /home/andressa.amaral/.local/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from packaging->tensorflow-gpu) (3.0.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.11.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd71b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_features(df, number_features):\n",
    "    \n",
    "    columns = list(df.columns)\n",
    "    chosen_columns = []\n",
    "    \n",
    "    if number_features == 92:\n",
    "        for column in columns:\n",
    "            if column.find('L5') != -1 or column.find('L3') != -1 or column.find('L1') != -1 or column.find('L=0.1') != -1:\n",
    "                chosen_columns.append(column)\n",
    "        df = pd.DataFrame(df, columns = chosen_columns)\n",
    "        return df\n",
    "    elif number_features == 69:\n",
    "        for column in columns:\n",
    "            if column.find('L5') != -1 or column.find('L3') != -1 or column.find('L1') != -1:\n",
    "                chosen_columns.append(column)\n",
    "        df = pd.DataFrame(df, columns = chosen_columns)\n",
    "        return df\n",
    "    elif number_features == 46:\n",
    "        for column in columns:\n",
    "            if column.find('L5') != -1 or column.find('L3') != -1:\n",
    "                chosen_columns.append(column)\n",
    "        df = pd.DataFrame(df, columns = chosen_columns)\n",
    "        return df\n",
    "    elif number_features == 23:\n",
    "        for column in columns:\n",
    "            if column.find('L5') != -1:\n",
    "                chosen_columns.append(column)\n",
    "        df = pd.DataFrame(df, columns = chosen_columns)\n",
    "        return df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ffcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path, number_features):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "    df = get_number_features(df, number_features)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93dd375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_botiot(path):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "    \n",
    "    # Drop irrelevant information\n",
    "    df = df.drop(columns=['pkSeqID', 'stime', 'flgs', 'flgs_number', 'saddr', 'sport', 'daddr', 'dport', 'subcategory', 'category'])\n",
    "    \n",
    "    # Categorical to numerical\n",
    "    df['proto'] = df['proto'].map({'tcp': 1, 'arp': 2, 'udp': 3, 'icmp': 4, 'ipv6-icmp': 5})\n",
    "    df['state'] = df['state'].map({'REQ': 1, 'RST': 2, 'ACC': 3, 'CON': 4, 'INT': 5, 'URP': 6, 'FIN': 7, 'NRS': 8, 'ECO': 9, 'TST': 10, 'MAS': 11})\n",
    "    \n",
    "    df_benign = df\n",
    "    df_attack = df\n",
    "    \n",
    "    # Get only benign data\n",
    "    df_benign = df_benign.query('attack == 0')\n",
    "    df_benign = df_benign.drop(columns=['attack'])\n",
    "    \n",
    "    # Get only the attacks\n",
    "    df_attack = df_attack.query('attack == 1')\n",
    "    df_attack = df_attack.drop(columns=['attack'])\n",
    "        \n",
    "    return df_benign, df_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbee863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick\n",
    "# Sample the normally distributed z - mean + sigma * epsilon. The epsilon ensures the continuity of latent space and helps\n",
    "# the network to keep correcting its parameters through backpropagation\n",
    "\n",
    "def reparametrization(args):\n",
    "    \n",
    "    z_mean, z_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape = (batch, dim))\n",
    "    \n",
    "    return z_mean + K.exp(0.5 * z_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653c453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get error term\n",
    "# Calculates the error between the original vector and the predicted one\n",
    "\n",
    "def get_error_term(v1, v2, _rmse = True):\n",
    "    \n",
    "    if _rmse:\n",
    "        return np.sqrt(np.mean((v1 - v2) ** 2, axis = 1))\n",
    "    \n",
    "    return np.mean(abs(v1 - v2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37d78bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Model\n",
    "# The encoder learns a function that takes an input array of size n and can generate two vectors that represents the\n",
    "# parameters (mean and variance) of a distribution from which the latent vector is sampled.\n",
    "\n",
    "# encoder(input_vector[]) => latent_v_mu[], latent_v_lvar[]\n",
    "# So that - latent_v[0] ~  N(latent_v_mu[0], latent_v_lvar[0])\n",
    "# and latent_v[1] ~  N(latent_v_mu[1], latent_v_lvar[1])\n",
    "\n",
    "def vae_encoder(input_shape, intermediate_dim, latent_dim, reparametrization):\n",
    "    \n",
    "    inputs = Input(shape = input_shape, name = 'encoder_input')\n",
    "    x = Dense(intermediate_dim, activation = 'relu')(inputs)\n",
    "\n",
    "    z_mean = Dense(latent_dim, name = 'z_mean')(x)\n",
    "    z_var = Dense(latent_dim, name = 'z_var')(x)\n",
    "    z = Lambda(reparametrization, output_shape = (latent_dim,), name = 'z')([z_mean, z_var])\n",
    "\n",
    "    encoder = Model(inputs, z, name = 'encoder')\n",
    "    return inputs, encoder, z_var, z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d811f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "# Transforms the latent feature space composed by distributions of mean and variance back to the original input vector\n",
    "\n",
    "def vae_decoder(intermediate_dim, latent_dim, original_dim):\n",
    "    \n",
    "    latent_inputs = Input(shape = (latent_dim,), name = 'z_sampling')\n",
    "    x = Dense(intermediate_dim, activation = 'relu')(latent_inputs)\n",
    "    outputs = Dense(original_dim, activation = 'sigmoid')(x)\n",
    "\n",
    "    # Instantiate the decoder model\n",
    "\n",
    "    decoder = Model(latent_inputs, outputs, name = 'decoder')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354d8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train, inputs, outputs, vae_loss, learning_rate, epochs, batch_size):\n",
    "    \n",
    "    # Create model\n",
    "    adam_opt = optimizers.Adam(learning_rate = learning_rate, clipvalue = 0.5)\n",
    "    model = Model(inputs, outputs, name = 'vae_mlp')\n",
    "    model.compile(optimizer = adam_opt, loss = vae_loss)\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(X_train, X_train, shuffle = True, epochs = epochs, batch_size = batch_size, verbose = 1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2150fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, inputs, outputs, vae_loss, learning_rate, epochs, batch_size):\n",
    "    \n",
    "    train_start = time.time()\n",
    "\n",
    "    model = fit_model(X_train, inputs, outputs, vae_loss, learning_rate, epochs, batch_size)\n",
    "\n",
    "    train_end = time.time()\n",
    "    train_time = train_end - train_start\n",
    "    print(\"Training time:\", train_time)\n",
    "    \n",
    "    return model, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9146b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test, model):\n",
    "    \n",
    "    test_start = time.time()\n",
    "\n",
    "    X_pred = model.predict(X_test)\n",
    "\n",
    "    test_end = time.time()\n",
    "    test_time = test_end - test_start\n",
    "    print(\"Testing time:\", test_time)\n",
    "    \n",
    "    return X_pred, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f26047e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the anomaly threshold based on the error termo between the predicted train set and the real one\n",
    "\n",
    "def get_anomaly_threshold(X_train, model):\n",
    "    \n",
    "    X_pred = model.predict(X_train)\n",
    "    error_vector = get_error_term(X_pred, X_train, _rmse = False)\n",
    "    anomaly_threshold = np.quantile(error_vector, 0.99)\n",
    "    \n",
    "    return anomaly_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d56eadd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the error of the vector is higher than the defined threshold it detects an attack, generating the prediction vector\n",
    "\n",
    "def get_prediction(Y_test, X_pred, X_test, anomaly_threshold, model):\n",
    "    \n",
    "    error_vector = get_error_term(X_pred, X_test, _rmse = False)\n",
    "    Y_pred = (error_vector > anomaly_threshold)\n",
    "    Y_pred = Y_pred.astype(int)\n",
    "    Y_test = Y_test.astype(int)\n",
    "        \n",
    "    return Y_test, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e307cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(Y_test, Y_pred):\n",
    "    \n",
    "    acc = accuracy_score(Y_test, Y_pred) \n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "    pre = precision_score(Y_test, Y_pred)\n",
    "    rec = recall_score(Y_test, Y_pred)\n",
    "    \n",
    "    return acc, f1, pre, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145d7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(number_features,\n",
    "                  learning_rate,\n",
    "                  epochs,\n",
    "                  batch_size,\n",
    "                  anomaly_threshold,\n",
    "                  X_train,\n",
    "                  X_test,\n",
    "                  opt_time,\n",
    "                  train_time,\n",
    "                  test_time,\n",
    "                  acc,\n",
    "                  f1,\n",
    "                  pre,\n",
    "                  rec,\n",
    "                  Y_test,\n",
    "                  Y_pred,\n",
    "                  path):\n",
    "    \n",
    "    stdout_obj = sys.stdout\n",
    "    sys.stdout = open(path, \"a\")\n",
    "\n",
    "    print(\"==== Experiment with \" + str(number_features) + \" features ====\")\n",
    "    print(\"Learning rate:\" + str(learning_rate) + \" - Epochs:\" + str(epochs) + \" - Batch size:\" + str(batch_size) + \" - Anomaly threshold:\" + str(anomaly_threshold))\n",
    "    print(\"Training size:\" + str(len(X_train)) + \" - Testing size:\" + str(len(X_test)))\n",
    "    print(\"Optimization time:\" + str(opt_time) + \" - Training time:\" + str(train_time) + \" - Testing time:\" + str(test_time))\n",
    "    print(\"Accuracy:\" + str(acc))\n",
    "    print(\"F1-score:\" + str(f1))\n",
    "    print(\"Precision:\" + str(pre))\n",
    "    print(\"Recall:\" + str(rec))\n",
    "    print(classification_report(Y_test, Y_pred, digits = 5))\n",
    "    print(\"=================================================================\")\n",
    "\n",
    "    sys.stdout = stdout_obj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
