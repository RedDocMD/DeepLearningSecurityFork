{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd6b254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/andressa.amaral/.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-gpu in /home/andressa.amaral/.local/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (13.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.19.4)\n",
      "Requirement already satisfied: packaging in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: setuptools in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (60.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (0.24.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorflow-gpu) (1.44.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.30.0)\n",
      "Requirement already satisfied: cached-property in /home/andressa.amaral/.local/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from packaging->tensorflow-gpu) (3.0.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.11.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2018.1.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.12)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andressa.amaral/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install --upgrade tensorflow-gpu\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97acbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "    \n",
    "    # Get only the attacks\n",
    "    df = df.query('attack == 1')\n",
    "    df = df.drop(columns=['attack'])\n",
    "    \n",
    "    # Drop irrelevant information\n",
    "    df = df.drop(columns=['pkSeqID', 'stime', 'flgs', 'flgs_number', 'saddr', 'sport', 'daddr', 'dport', 'subcategory'])\n",
    "    \n",
    "    # Categorical to numerical\n",
    "    df['proto'] = df['proto'].map({'tcp': 1, 'arp': 2, 'udp': 3, 'icmp': 4, 'ipv6-icmp': 5})\n",
    "    df['state'] = df['state'].map({'REQ': 1, 'RST': 2, 'ACC': 3, 'CON': 4, 'INT': 5, 'URP': 6, 'FIN': 7, 'NRS': 8, 'ECO': 9, 'TST': 10, 'MAS': 11})\n",
    "    df['category'] = df['category'].map({'DDoS': 0, 'DoS': 1, 'Reconnaissance': 2, 'Theft': 3})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ca5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_nbaiot_mirai(path):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        if ('ack' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 0\n",
    "        elif ('scan' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 1\n",
    "        elif ('syn' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 2\n",
    "        elif ('udp' in file and 'udpplain' not in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 3\n",
    "        elif ('udpplain' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 4\n",
    "            \n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8defca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_nbaiot_gafgyt(path):\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(path , '*.csv'))\n",
    "\n",
    "    files_list = []\n",
    "    for file in all_files:\n",
    "        if ('combo' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 5\n",
    "        elif ('junk' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 6\n",
    "        elif ('scan' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 7\n",
    "        elif ('tcp' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 8\n",
    "        elif ('udp' in file):\n",
    "            df = pd.read_csv(file, index_col = None, encoding = 'utf-8', sep = ',', low_memory = False)\n",
    "            df['category'] = 9\n",
    "            \n",
    "        files_list.append(df)\n",
    "        \n",
    "    df = pd.concat(files_list, axis = 0, ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac6a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attack(attack_type, df):\n",
    "    \n",
    "    df = df.query('category==' + str(attack_type))\n",
    "    label = df.pop('category')\n",
    "    \n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d3c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with 1D convolutional layer for botiot dataset\n",
    "\n",
    "def CNN_botiot(feature, depth):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform', input_shape = (feature, depth)))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(2, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe47af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with 1D convolutional layer for nbaiot dataset\n",
    "\n",
    "def CNN_nbaiot(feature, depth):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_uniform', input_shape = (feature, depth)))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    model.add(layers.MaxPooling1D(pool_size = 2, strides = 2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu', padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(10, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fdf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, Y_train, X_val, Y_val, epochs, batch_size, reduce_lr, model):\n",
    "    \n",
    "    train_start = time.time()\n",
    "\n",
    "    history = model.fit(X_train, Y_train, \n",
    "                        epochs = epochs, \n",
    "                        batch_size = batch_size, \n",
    "                        validation_data = (X_val, Y_val),\n",
    "                        callbacks = [reduce_lr])\n",
    "\n",
    "    train_end = time.time()\n",
    "    train_time = train_end - train_start\n",
    "    print(\"Training time:\", train_time)\n",
    "    \n",
    "    return model, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb72c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test, model):\n",
    "    \n",
    "    test_start = time.time()\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    test_end = time.time()\n",
    "    test_time = test_end - test_start\n",
    "    print(\"Testing time:\", test_time)\n",
    "    \n",
    "    pred = []\n",
    "    for idx, x in enumerate(Y_pred):\n",
    "        aux = []\n",
    "        for i in x:\n",
    "            if i < 0.09:\n",
    "                aux.append(False)\n",
    "            else:\n",
    "                aux.append(True)\n",
    " \n",
    "        if True in aux:\n",
    "            pred.append(np.argmax(np.asarray(x)))\n",
    "        else:\n",
    "            pred.append(2)\n",
    "        \n",
    "    pred = np.asarray(pred)\n",
    "    \n",
    "    return pred, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe3af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(Y_test, Y_pred, labels):\n",
    "    \n",
    "    acc = accuracy_score(Y_test, Y_pred) \n",
    "    f1 = f1_score(Y_test, Y_pred, average = 'weighted')\n",
    "    pre = precision_score(Y_test, Y_pred, labels = None, pos_label = 1, average = 'weighted')\n",
    "    rec = recall_score(Y_test, Y_pred, labels = None, pos_label = 1, average = 'weighted', sample_weight = None)\n",
    "    \n",
    "    return acc, f1, pre, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a9e27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(learning_rate,\n",
    "                  epochs,\n",
    "                  batch_size,\n",
    "                  X_train,\n",
    "                  X_val,\n",
    "                  X_test,\n",
    "                  opt_time,\n",
    "                  train_time,\n",
    "                  test_time,\n",
    "                  acc,\n",
    "                  f1,\n",
    "                  pre,\n",
    "                  rec,\n",
    "                  Y_test,\n",
    "                  Y_pred,\n",
    "                  model_type,\n",
    "                  path):\n",
    "    \n",
    "    stdout_obj = sys.stdout\n",
    "    sys.stdout = open(path, \"a\")\n",
    "\n",
    "    print(\"==== Experiment \" + model_type + \" ====\")\n",
    "    print(\"Learning rate:\" + str(learning_rate) + \" - Epochs:\" + str(epochs) + \" - Batch size:\" + str(batch_size) + \" - Anomaly threshold:\" + str(anomaly_threshold))\n",
    "    print(\"Training size:\" + str(len(X_train)) + \" - Testing size:\" + str(len(X_test)))\n",
    "    print(\"Optimization time:\" + str(opt_time) + \" - Training time:\" + str(train_time) + \" - Testing time:\" + str(test_time))\n",
    "    print(\"Accuracy:\" + str(acc))\n",
    "    print(\"F1-score:\" + str(f1))\n",
    "    print(\"Precision:\" + str(pre))\n",
    "    print(\"Recall:\" + str(rec))\n",
    "    print(classification_report(Y_test, Y_pred, digits = 5))\n",
    "    print(\"=================================================================\")\n",
    "\n",
    "    sys.stdout = stdout_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f284af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb_knn(X_train, Y_train, model):\n",
    "    \n",
    "    train_start = time.time()\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    train_end = time.time()\n",
    "    train_knn_time = train_end - train_start\n",
    "    \n",
    "    return model, train_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
